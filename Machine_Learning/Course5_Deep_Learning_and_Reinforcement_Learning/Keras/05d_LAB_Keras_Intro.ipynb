{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from tensorflow.keras.models  import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Practice\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "# from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('data/diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "0               6                     148              72              35   \n",
       "1               1                      85              66              29   \n",
       "2               8                     183              64               0   \n",
       "3               1                      89              66              23   \n",
       "4               0                     137              40              35   \n",
       "\n",
       "   insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "0        0  33.6              0.627   50             1  \n",
       "1        0  26.6              0.351   31             0  \n",
       "2        0  23.3              0.672   32             1  \n",
       "3       94  28.1              0.167   21             0  \n",
       "4      168  43.1              2.288   33             1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>64</td>\n",
       "      <td>37</td>\n",
       "      <td>64</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>78</td>\n",
       "      <td>29</td>\n",
       "      <td>76</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.365</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>70</td>\n",
       "      <td>38</td>\n",
       "      <td>360</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.337</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>76</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>0.378</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.6</td>\n",
       "      <td>0.368</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "448               0                     104              64              37   \n",
       "544               1                      88              78              29   \n",
       "296               2                     146              70              38   \n",
       "719               5                      97              76              27   \n",
       "366               6                     124              72               0   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "448       64  33.6              0.510   22             1  \n",
       "544       76  32.0              0.365   29             0  \n",
       "296      360  28.0              0.337   29             1  \n",
       "719        0  35.6              0.378   52             1  \n",
       "366        0  27.6              0.368   29             1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.651042\n",
       "1    0.348958\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.786\n",
      "roc-auc is 0.831\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8310357016613644"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,y_pred_prob_rf[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.766\n",
      "roc-auc is 0.824\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(accuracy_score(y_test,y_pred_class_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.01449275, 0.04347826, 0.10144928, 0.13043478,\n",
       "       0.15942029, 0.20289855, 0.23188406, 0.26086957, 0.26086957,\n",
       "       0.28985507, 0.28985507, 0.30434783, 0.33333333, 0.33333333,\n",
       "       0.34782609, 0.37681159, 0.37681159, 0.39130435, 0.4057971 ,\n",
       "       0.42028986, 0.44927536, 0.46376812, 0.50724638, 0.50724638,\n",
       "       0.52173913, 0.53623188, 0.53623188, 0.56521739, 0.5942029 ,\n",
       "       0.60869565, 0.60869565, 0.62318841, 0.62318841, 0.62318841,\n",
       "       0.62318841, 0.63768116, 0.63768116, 0.65217391, 0.65217391,\n",
       "       0.68115942, 0.69565217, 0.69565217, 0.72463768, 0.73913043,\n",
       "       0.76811594, 0.7826087 , 0.7826087 , 0.79710145, 0.79710145,\n",
       "       0.8115942 , 0.8115942 , 0.8115942 , 0.8115942 , 0.82608696,\n",
       "       0.82608696, 0.84057971, 0.84057971, 0.85507246, 0.85507246,\n",
       "       0.86956522, 0.86956522, 0.88405797, 0.88405797, 0.88405797,\n",
       "       0.91304348, 0.92753623, 0.92753623, 0.94202899, 0.94202899,\n",
       "       0.97101449, 0.97101449, 0.97101449, 0.97101449, 0.97101449,\n",
       "       0.97101449, 0.97101449, 0.97101449, 0.98550725, 0.98550725,\n",
       "       0.98550725, 0.98550725, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thr = roc_curve(y_test, y_pred_prob_rf[:, 1])\n",
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>576.0</td>\n",
       "      <td>4.625929e-18</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>-1.105597</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.216592</td>\n",
       "      <td>0.672413</td>\n",
       "      <td>3.932097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>576.0</td>\n",
       "      <td>9.406056e-17</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>-3.819562</td>\n",
       "      <td>-0.675618</td>\n",
       "      <td>-0.116169</td>\n",
       "      <td>0.624510</td>\n",
       "      <td>2.452568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>576.0</td>\n",
       "      <td>1.603655e-16</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>-3.393556</td>\n",
       "      <td>-0.312803</td>\n",
       "      <td>0.084714</td>\n",
       "      <td>0.581609</td>\n",
       "      <td>2.668571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576.0</td>\n",
       "      <td>-1.063964e-16</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>-1.312452</td>\n",
       "      <td>-1.312452</td>\n",
       "      <td>0.152734</td>\n",
       "      <td>0.726068</td>\n",
       "      <td>2.700884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>576.0</td>\n",
       "      <td>3.700743e-17</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>-0.713038</td>\n",
       "      <td>-0.713038</td>\n",
       "      <td>-0.361185</td>\n",
       "      <td>0.430486</td>\n",
       "      <td>6.728669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>576.0</td>\n",
       "      <td>1.023872e-15</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>-4.106147</td>\n",
       "      <td>-0.603208</td>\n",
       "      <td>0.021397</td>\n",
       "      <td>0.568731</td>\n",
       "      <td>4.535295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>576.0</td>\n",
       "      <td>1.531183e-15</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>-1.182175</td>\n",
       "      <td>-0.695967</td>\n",
       "      <td>-0.273210</td>\n",
       "      <td>0.480818</td>\n",
       "      <td>5.711795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>576.0</td>\n",
       "      <td>2.097088e-16</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>-1.023736</td>\n",
       "      <td>-0.767022</td>\n",
       "      <td>-0.339165</td>\n",
       "      <td>0.602119</td>\n",
       "      <td>4.110542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count          mean       std       min       25%       50%       75%  \\\n",
       "0  576.0  4.625929e-18  1.000869 -1.105597 -0.809262 -0.216592  0.672413   \n",
       "1  576.0  9.406056e-17  1.000869 -3.819562 -0.675618 -0.116169  0.624510   \n",
       "2  576.0  1.603655e-16  1.000869 -3.393556 -0.312803  0.084714  0.581609   \n",
       "3  576.0 -1.063964e-16  1.000869 -1.312452 -1.312452  0.152734  0.726068   \n",
       "4  576.0  3.700743e-17  1.000869 -0.713038 -0.713038 -0.361185  0.430486   \n",
       "5  576.0  1.023872e-15  1.000869 -4.106147 -0.603208  0.021397  0.568731   \n",
       "6  576.0  1.531183e-15  1.000869 -1.182175 -0.695967 -0.273210  0.480818   \n",
       "7  576.0  2.097088e-16  1.000869 -1.023736 -0.767022 -0.339165  0.602119   \n",
       "\n",
       "        max  \n",
       "0  3.932097  \n",
       "1  2.452568  \n",
       "2  2.668571  \n",
       "3  2.700884  \n",
       "4  6.728669  \n",
       "5  4.535295  \n",
       "6  5.711795  \n",
       "7  4.110542  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_norm).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Practice\n",
    "# normalizer = StandardScaler()\n",
    "# X_train_norm = normalizer.fit_transform(X_train)\n",
    "# X_test_norm = normalizer.fit_transform(X_test)\n",
    "\n",
    "# model_1 = Sequential()\n",
    "# model_1.add(Dense(12, input_shape = (8,), activation = 'sigmoid'))\n",
    "# model_1.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6342 - accuracy: 0.6684 - val_loss: 0.6262 - val_accuracy: 0.6875\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.6753 - val_loss: 0.6229 - val_accuracy: 0.6979\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6875 - val_loss: 0.6200 - val_accuracy: 0.7031\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6875 - val_loss: 0.6174 - val_accuracy: 0.7031\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6771 - val_loss: 0.6149 - val_accuracy: 0.7031\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6840 - val_loss: 0.6127 - val_accuracy: 0.7031\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6875 - val_loss: 0.6107 - val_accuracy: 0.7031\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.6962 - val_loss: 0.6088 - val_accuracy: 0.6875\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.6927 - val_loss: 0.6070 - val_accuracy: 0.6979\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6962 - val_loss: 0.6054 - val_accuracy: 0.6927\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.6979 - val_loss: 0.6040 - val_accuracy: 0.6927\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.7031 - val_loss: 0.6026 - val_accuracy: 0.7031\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.6927 - val_loss: 0.6013 - val_accuracy: 0.6979\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.6944 - val_loss: 0.6001 - val_accuracy: 0.7031\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.6910 - val_loss: 0.5990 - val_accuracy: 0.7135\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.6892 - val_loss: 0.5980 - val_accuracy: 0.7135\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.6910 - val_loss: 0.5970 - val_accuracy: 0.7188\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.6910 - val_loss: 0.5960 - val_accuracy: 0.7188\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.6910 - val_loss: 0.5952 - val_accuracy: 0.7135\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.6962 - val_loss: 0.5943 - val_accuracy: 0.7135\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.6944 - val_loss: 0.5935 - val_accuracy: 0.7083\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6979 - val_loss: 0.5928 - val_accuracy: 0.7083\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.6997 - val_loss: 0.5920 - val_accuracy: 0.7083\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.6979 - val_loss: 0.5913 - val_accuracy: 0.7083\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.6979 - val_loss: 0.5906 - val_accuracy: 0.7083\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.6979 - val_loss: 0.5900 - val_accuracy: 0.7083\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.6962 - val_loss: 0.5894 - val_accuracy: 0.7083\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.6979 - val_loss: 0.5887 - val_accuracy: 0.7083\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.6962 - val_loss: 0.5882 - val_accuracy: 0.7031\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.6962 - val_loss: 0.5876 - val_accuracy: 0.7031\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.6962 - val_loss: 0.5870 - val_accuracy: 0.7031\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.6962 - val_loss: 0.5864 - val_accuracy: 0.7031\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.6979 - val_loss: 0.5859 - val_accuracy: 0.7083\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.6979 - val_loss: 0.5854 - val_accuracy: 0.7083\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.6979 - val_loss: 0.5848 - val_accuracy: 0.7083\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.6997 - val_loss: 0.5843 - val_accuracy: 0.7083\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.6997 - val_loss: 0.5838 - val_accuracy: 0.7083\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.6997 - val_loss: 0.5833 - val_accuracy: 0.7083\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.6997 - val_loss: 0.5828 - val_accuracy: 0.7083\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.6997 - val_loss: 0.5823 - val_accuracy: 0.7083\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.7014 - val_loss: 0.5818 - val_accuracy: 0.7083\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.7014 - val_loss: 0.5814 - val_accuracy: 0.7083\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7014 - val_loss: 0.5809 - val_accuracy: 0.7083\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.7031 - val_loss: 0.5804 - val_accuracy: 0.7083\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7031 - val_loss: 0.5799 - val_accuracy: 0.7083\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7031 - val_loss: 0.5795 - val_accuracy: 0.7135\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7031 - val_loss: 0.5790 - val_accuracy: 0.7135\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.7049 - val_loss: 0.5786 - val_accuracy: 0.7135\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.7049 - val_loss: 0.5781 - val_accuracy: 0.7135\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.7031 - val_loss: 0.5776 - val_accuracy: 0.7135\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7031 - val_loss: 0.5772 - val_accuracy: 0.7135\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.7031 - val_loss: 0.5767 - val_accuracy: 0.7135\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.7031 - val_loss: 0.5763 - val_accuracy: 0.7135\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7031 - val_loss: 0.5759 - val_accuracy: 0.7135\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.7014 - val_loss: 0.5754 - val_accuracy: 0.7135\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7014 - val_loss: 0.5750 - val_accuracy: 0.7135\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.7014 - val_loss: 0.5745 - val_accuracy: 0.7135\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7049 - val_loss: 0.5741 - val_accuracy: 0.7135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7031 - val_loss: 0.5737 - val_accuracy: 0.7135\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7031 - val_loss: 0.5732 - val_accuracy: 0.7135\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7031 - val_loss: 0.5728 - val_accuracy: 0.7135\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7031 - val_loss: 0.5724 - val_accuracy: 0.7135\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7031 - val_loss: 0.5720 - val_accuracy: 0.7135\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7049 - val_loss: 0.5715 - val_accuracy: 0.7135\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7066 - val_loss: 0.5711 - val_accuracy: 0.7188\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7066 - val_loss: 0.5707 - val_accuracy: 0.7188\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7049 - val_loss: 0.5703 - val_accuracy: 0.7240\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7049 - val_loss: 0.5699 - val_accuracy: 0.7240\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7066 - val_loss: 0.5695 - val_accuracy: 0.7240\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7066 - val_loss: 0.5690 - val_accuracy: 0.7240\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7066 - val_loss: 0.5686 - val_accuracy: 0.7240\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7066 - val_loss: 0.5682 - val_accuracy: 0.7240\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7083 - val_loss: 0.5678 - val_accuracy: 0.7240\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7083 - val_loss: 0.5674 - val_accuracy: 0.7240\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5636 - accuracy: 0.7083 - val_loss: 0.5670 - val_accuracy: 0.7240\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7083 - val_loss: 0.5666 - val_accuracy: 0.7240\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7083 - val_loss: 0.5662 - val_accuracy: 0.7240\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7083 - val_loss: 0.5658 - val_accuracy: 0.7240\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7101 - val_loss: 0.5654 - val_accuracy: 0.7292\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7101 - val_loss: 0.5650 - val_accuracy: 0.7292\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7101 - val_loss: 0.5646 - val_accuracy: 0.7292\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7101 - val_loss: 0.5642 - val_accuracy: 0.7292\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7135 - val_loss: 0.5638 - val_accuracy: 0.7344\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7135 - val_loss: 0.5634 - val_accuracy: 0.7344\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7153 - val_loss: 0.5630 - val_accuracy: 0.7344\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7153 - val_loss: 0.5627 - val_accuracy: 0.7344\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7153 - val_loss: 0.5623 - val_accuracy: 0.7344\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7153 - val_loss: 0.5619 - val_accuracy: 0.7344\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7153 - val_loss: 0.5615 - val_accuracy: 0.7344\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7170 - val_loss: 0.5611 - val_accuracy: 0.7344\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7170 - val_loss: 0.5607 - val_accuracy: 0.7344\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7170 - val_loss: 0.5604 - val_accuracy: 0.7396\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7188 - val_loss: 0.5600 - val_accuracy: 0.7396\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7205 - val_loss: 0.5596 - val_accuracy: 0.7396\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7205 - val_loss: 0.5592 - val_accuracy: 0.7396\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7188 - val_loss: 0.5589 - val_accuracy: 0.7396\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7205 - val_loss: 0.5585 - val_accuracy: 0.7396\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7222 - val_loss: 0.5581 - val_accuracy: 0.7396\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7205 - val_loss: 0.5578 - val_accuracy: 0.7396\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7205 - val_loss: 0.5574 - val_accuracy: 0.7396\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7205 - val_loss: 0.5570 - val_accuracy: 0.7396\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.7205 - val_loss: 0.5567 - val_accuracy: 0.7396\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7222 - val_loss: 0.5563 - val_accuracy: 0.7396\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7257 - val_loss: 0.5560 - val_accuracy: 0.7396\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7257 - val_loss: 0.5556 - val_accuracy: 0.7448\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7274 - val_loss: 0.5553 - val_accuracy: 0.7448\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7274 - val_loss: 0.5549 - val_accuracy: 0.7448\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7257 - val_loss: 0.5546 - val_accuracy: 0.7448\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7292 - val_loss: 0.5542 - val_accuracy: 0.7448\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7292 - val_loss: 0.5539 - val_accuracy: 0.7448\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7292 - val_loss: 0.5535 - val_accuracy: 0.7448\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7292 - val_loss: 0.5532 - val_accuracy: 0.7448\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7292 - val_loss: 0.5528 - val_accuracy: 0.7448\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7292 - val_loss: 0.5525 - val_accuracy: 0.7448\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7292 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.7292 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7292 - val_loss: 0.5515 - val_accuracy: 0.7448\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7292 - val_loss: 0.5511 - val_accuracy: 0.7448\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7292 - val_loss: 0.5508 - val_accuracy: 0.7448\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7292 - val_loss: 0.5505 - val_accuracy: 0.7448\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7292 - val_loss: 0.5501 - val_accuracy: 0.7448\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7292 - val_loss: 0.5498 - val_accuracy: 0.7448\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7274 - val_loss: 0.5495 - val_accuracy: 0.7448\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7274 - val_loss: 0.5491 - val_accuracy: 0.7448\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7274 - val_loss: 0.5488 - val_accuracy: 0.7396\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7274 - val_loss: 0.5485 - val_accuracy: 0.7396\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7274 - val_loss: 0.5482 - val_accuracy: 0.7396\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7309 - val_loss: 0.5478 - val_accuracy: 0.7448\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7292 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7274 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7292 - val_loss: 0.5469 - val_accuracy: 0.7448\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7274 - val_loss: 0.5466 - val_accuracy: 0.7448\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7292 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7309 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7292 - val_loss: 0.5456 - val_accuracy: 0.7500\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7309 - val_loss: 0.5453 - val_accuracy: 0.7500\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7309 - val_loss: 0.5450 - val_accuracy: 0.7500\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7309 - val_loss: 0.5447 - val_accuracy: 0.7500\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7309 - val_loss: 0.5444 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7309 - val_loss: 0.5441 - val_accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7309 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7309 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7309 - val_loss: 0.5432 - val_accuracy: 0.7500\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7309 - val_loss: 0.5429 - val_accuracy: 0.7500\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7309 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7309 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7309 - val_loss: 0.5420 - val_accuracy: 0.7500\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7309 - val_loss: 0.5417 - val_accuracy: 0.7500\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7309 - val_loss: 0.5414 - val_accuracy: 0.7500\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7292 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7292 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7309 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7309 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7326 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7309 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7326 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7326 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7326 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7326 - val_loss: 0.5386 - val_accuracy: 0.7500\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7326 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7326 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7326 - val_loss: 0.5378 - val_accuracy: 0.7500\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7326 - val_loss: 0.5375 - val_accuracy: 0.7500\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7326 - val_loss: 0.5373 - val_accuracy: 0.7500\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7326 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7326 - val_loss: 0.5367 - val_accuracy: 0.7500\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7326 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7326 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7326 - val_loss: 0.5359 - val_accuracy: 0.7500\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7326 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7326 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7326 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7326 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7344 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7344 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7378 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7378 - val_loss: 0.5339 - val_accuracy: 0.7552\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7378 - val_loss: 0.5336 - val_accuracy: 0.7552\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7378 - val_loss: 0.5334 - val_accuracy: 0.7552\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7361 - val_loss: 0.5331 - val_accuracy: 0.7552\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7378 - val_loss: 0.5329 - val_accuracy: 0.7552\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7361 - val_loss: 0.5326 - val_accuracy: 0.7552\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7361 - val_loss: 0.5324 - val_accuracy: 0.7552\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7378 - val_loss: 0.5321 - val_accuracy: 0.7552\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7378 - val_loss: 0.5319 - val_accuracy: 0.7552\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7378 - val_loss: 0.5316 - val_accuracy: 0.7552\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7378 - val_loss: 0.5314 - val_accuracy: 0.7552\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7378 - val_loss: 0.5312 - val_accuracy: 0.7552\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7378 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7396 - val_loss: 0.5307 - val_accuracy: 0.7552\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7378 - val_loss: 0.5304 - val_accuracy: 0.7552\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7396 - val_loss: 0.5302 - val_accuracy: 0.7604\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7378 - val_loss: 0.5300 - val_accuracy: 0.7604\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7448 - val_loss: 0.5297 - val_accuracy: 0.7604\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7448 - val_loss: 0.5295 - val_accuracy: 0.7604\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7448 - val_loss: 0.5293 - val_accuracy: 0.7604\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7448 - val_loss: 0.5290 - val_accuracy: 0.7604\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7448 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7448 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7448 - val_loss: 0.5284 - val_accuracy: 0.7604\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4227847 ],\n",
       "       [0.637563  ],\n",
       "       [0.2852093 ],\n",
       "       [0.26319802],\n",
       "       [0.22936916],\n",
       "       [0.5490242 ],\n",
       "       [0.18383697],\n",
       "       [0.34049025],\n",
       "       [0.6217444 ],\n",
       "       [0.3332693 ]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.760\n",
      "roc-auc is 0.811\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6341755390167236,\n",
       "  0.6303138136863708,\n",
       "  0.6268115043640137,\n",
       "  0.6236129403114319,\n",
       "  0.6206603646278381,\n",
       "  0.6179781556129456,\n",
       "  0.6154729127883911,\n",
       "  0.6131836771965027,\n",
       "  0.6110233068466187,\n",
       "  0.6090730428695679,\n",
       "  0.6072262525558472,\n",
       "  0.6055330634117126,\n",
       "  0.6039467453956604,\n",
       "  0.6024807095527649,\n",
       "  0.6010957360267639,\n",
       "  0.5997856855392456,\n",
       "  0.5985662341117859,\n",
       "  0.597402811050415,\n",
       "  0.5963103175163269,\n",
       "  0.5952363014221191,\n",
       "  0.5942342281341553,\n",
       "  0.5933167934417725,\n",
       "  0.5923969745635986,\n",
       "  0.5915281772613525,\n",
       "  0.5906646847724915,\n",
       "  0.5898797512054443,\n",
       "  0.5890949964523315,\n",
       "  0.5883294939994812,\n",
       "  0.587642252445221,\n",
       "  0.5869181156158447,\n",
       "  0.5862325429916382,\n",
       "  0.5855403542518616,\n",
       "  0.5848969221115112,\n",
       "  0.5842614769935608,\n",
       "  0.5836129784584045,\n",
       "  0.5830145478248596,\n",
       "  0.582401692867279,\n",
       "  0.5818077921867371,\n",
       "  0.5812395811080933,\n",
       "  0.5806864500045776,\n",
       "  0.5800901651382446,\n",
       "  0.5795584917068481,\n",
       "  0.5789914727210999,\n",
       "  0.5784467458724976,\n",
       "  0.577895998954773,\n",
       "  0.5773550271987915,\n",
       "  0.5768756866455078,\n",
       "  0.5763417482376099,\n",
       "  0.5758108496665955,\n",
       "  0.5753121972084045,\n",
       "  0.5747840404510498,\n",
       "  0.5742891430854797,\n",
       "  0.5738188624382019,\n",
       "  0.5733280181884766,\n",
       "  0.5728127956390381,\n",
       "  0.5723304152488708,\n",
       "  0.5718463063240051,\n",
       "  0.5713831782341003,\n",
       "  0.5708810687065125,\n",
       "  0.5704073905944824,\n",
       "  0.5699485540390015,\n",
       "  0.5694720149040222,\n",
       "  0.5690049529075623,\n",
       "  0.5685332417488098,\n",
       "  0.5680831670761108,\n",
       "  0.5676208138465881,\n",
       "  0.5671707391738892,\n",
       "  0.566713273525238,\n",
       "  0.566246747970581,\n",
       "  0.5658010840415955,\n",
       "  0.5653614401817322,\n",
       "  0.5649195909500122,\n",
       "  0.5644753575325012,\n",
       "  0.5640252828598022,\n",
       "  0.5635966062545776,\n",
       "  0.5631687641143799,\n",
       "  0.5627272129058838,\n",
       "  0.5622852444648743,\n",
       "  0.5618610382080078,\n",
       "  0.5614365935325623,\n",
       "  0.5610219240188599,\n",
       "  0.5605647563934326,\n",
       "  0.56017005443573,\n",
       "  0.5597334504127502,\n",
       "  0.5592989325523376,\n",
       "  0.5588924884796143,\n",
       "  0.5584679841995239,\n",
       "  0.5580744743347168,\n",
       "  0.5576409101486206,\n",
       "  0.5572453141212463,\n",
       "  0.556835412979126,\n",
       "  0.5564181208610535,\n",
       "  0.5560144186019897,\n",
       "  0.5556207895278931,\n",
       "  0.5552070140838623,\n",
       "  0.5548203587532043,\n",
       "  0.5544214248657227,\n",
       "  0.5540223717689514,\n",
       "  0.5536147952079773,\n",
       "  0.5532535314559937,\n",
       "  0.5528272390365601,\n",
       "  0.5524479150772095,\n",
       "  0.5520784854888916,\n",
       "  0.5516626834869385,\n",
       "  0.5512964129447937,\n",
       "  0.5509183406829834,\n",
       "  0.550523042678833,\n",
       "  0.5501943826675415,\n",
       "  0.5497749447822571,\n",
       "  0.5493764281272888,\n",
       "  0.5490208864212036,\n",
       "  0.5486330986022949,\n",
       "  0.548255205154419,\n",
       "  0.5478914380073547,\n",
       "  0.5475154519081116,\n",
       "  0.5471504926681519,\n",
       "  0.5467869639396667,\n",
       "  0.5463913083076477,\n",
       "  0.5460590124130249,\n",
       "  0.5456879138946533,\n",
       "  0.5453238487243652,\n",
       "  0.5449544191360474,\n",
       "  0.5446161031723022,\n",
       "  0.544241726398468,\n",
       "  0.5438868999481201,\n",
       "  0.5435431599617004,\n",
       "  0.5431833267211914,\n",
       "  0.5428512096405029,\n",
       "  0.5425065159797668,\n",
       "  0.5421420931816101,\n",
       "  0.5417883396148682,\n",
       "  0.541461706161499,\n",
       "  0.5411012768745422,\n",
       "  0.5407636761665344,\n",
       "  0.5404173135757446,\n",
       "  0.5401022434234619,\n",
       "  0.5397508144378662,\n",
       "  0.5394255518913269,\n",
       "  0.5390772223472595,\n",
       "  0.5387586951255798,\n",
       "  0.5384103059768677,\n",
       "  0.5380876064300537,\n",
       "  0.5377385020256042,\n",
       "  0.5374087691307068,\n",
       "  0.5370901823043823,\n",
       "  0.5367835164070129,\n",
       "  0.5364479422569275,\n",
       "  0.5361123085021973,\n",
       "  0.5357896089553833,\n",
       "  0.5354704260826111,\n",
       "  0.5351604223251343,\n",
       "  0.534861147403717,\n",
       "  0.5345255732536316,\n",
       "  0.5342027544975281,\n",
       "  0.5338979363441467,\n",
       "  0.5335895419120789,\n",
       "  0.5332815647125244,\n",
       "  0.5329587459564209,\n",
       "  0.5326554775238037,\n",
       "  0.5323429703712463,\n",
       "  0.5320295691490173,\n",
       "  0.5317254662513733,\n",
       "  0.5314479470252991,\n",
       "  0.5311443209648132,\n",
       "  0.530808687210083,\n",
       "  0.5305236577987671,\n",
       "  0.5302294492721558,\n",
       "  0.5299320220947266,\n",
       "  0.5296376943588257,\n",
       "  0.5293394923210144,\n",
       "  0.5290296673774719,\n",
       "  0.5287404656410217,\n",
       "  0.5284707546234131,\n",
       "  0.5281816720962524,\n",
       "  0.5278863906860352,\n",
       "  0.5275712609291077,\n",
       "  0.5272859334945679,\n",
       "  0.5270130038261414,\n",
       "  0.5267388820648193,\n",
       "  0.5264498591423035,\n",
       "  0.5261613726615906,\n",
       "  0.5258802175521851,\n",
       "  0.5255930423736572,\n",
       "  0.5253117084503174,\n",
       "  0.5250362157821655,\n",
       "  0.5247658491134644,\n",
       "  0.5244863033294678,\n",
       "  0.5242183804512024,\n",
       "  0.5239589214324951,\n",
       "  0.5236804485321045,\n",
       "  0.5234096050262451,\n",
       "  0.5231295824050903,\n",
       "  0.5228778719902039,\n",
       "  0.5226008892059326,\n",
       "  0.522328794002533,\n",
       "  0.5220938920974731,\n",
       "  0.5218052864074707,\n",
       "  0.5215571522712708,\n",
       "  0.5212926864624023,\n",
       "  0.5210213661193848],\n",
       " 'accuracy': [0.6684027910232544,\n",
       "  0.6753472089767456,\n",
       "  0.6875,\n",
       "  0.6875,\n",
       "  0.6770833134651184,\n",
       "  0.6840277910232544,\n",
       "  0.6875,\n",
       "  0.6961805820465088,\n",
       "  0.6927083134651184,\n",
       "  0.6961805820465088,\n",
       "  0.6979166865348816,\n",
       "  0.703125,\n",
       "  0.6927083134651184,\n",
       "  0.6944444179534912,\n",
       "  0.6909722089767456,\n",
       "  0.6892361044883728,\n",
       "  0.6909722089767456,\n",
       "  0.6909722089767456,\n",
       "  0.6909722089767456,\n",
       "  0.6961805820465088,\n",
       "  0.6944444179534912,\n",
       "  0.6979166865348816,\n",
       "  0.6996527910232544,\n",
       "  0.6979166865348816,\n",
       "  0.6979166865348816,\n",
       "  0.6979166865348816,\n",
       "  0.6961805820465088,\n",
       "  0.6979166865348816,\n",
       "  0.6961805820465088,\n",
       "  0.6961805820465088,\n",
       "  0.6961805820465088,\n",
       "  0.6961805820465088,\n",
       "  0.6979166865348816,\n",
       "  0.6979166865348816,\n",
       "  0.6979166865348816,\n",
       "  0.6996527910232544,\n",
       "  0.6996527910232544,\n",
       "  0.6996527910232544,\n",
       "  0.6996527910232544,\n",
       "  0.6996527910232544,\n",
       "  0.7013888955116272,\n",
       "  0.7013888955116272,\n",
       "  0.7013888955116272,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.7048611044883728,\n",
       "  0.7048611044883728,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.7013888955116272,\n",
       "  0.7013888955116272,\n",
       "  0.7013888955116272,\n",
       "  0.7048611044883728,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.7048611044883728,\n",
       "  0.7065972089767456,\n",
       "  0.7065972089767456,\n",
       "  0.7048611044883728,\n",
       "  0.7048611044883728,\n",
       "  0.7065972089767456,\n",
       "  0.7065972089767456,\n",
       "  0.7065972089767456,\n",
       "  0.7065972089767456,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7100694179534912,\n",
       "  0.7100694179534912,\n",
       "  0.7100694179534912,\n",
       "  0.7100694179534912,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7152777910232544,\n",
       "  0.7152777910232544,\n",
       "  0.7152777910232544,\n",
       "  0.7152777910232544,\n",
       "  0.7152777910232544,\n",
       "  0.7170138955116272,\n",
       "  0.7170138955116272,\n",
       "  0.7170138955116272,\n",
       "  0.71875,\n",
       "  0.7204861044883728,\n",
       "  0.7204861044883728,\n",
       "  0.71875,\n",
       "  0.7204861044883728,\n",
       "  0.7222222089767456,\n",
       "  0.7204861044883728,\n",
       "  0.7204861044883728,\n",
       "  0.7204861044883728,\n",
       "  0.7204861044883728,\n",
       "  0.7222222089767456,\n",
       "  0.7256944179534912,\n",
       "  0.7256944179534912,\n",
       "  0.7274305820465088,\n",
       "  0.7274305820465088,\n",
       "  0.7256944179534912,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7274305820465088,\n",
       "  0.7274305820465088,\n",
       "  0.7274305820465088,\n",
       "  0.7274305820465088,\n",
       "  0.7274305820465088,\n",
       "  0.7309027910232544,\n",
       "  0.7291666865348816,\n",
       "  0.7274305820465088,\n",
       "  0.7291666865348816,\n",
       "  0.7274305820465088,\n",
       "  0.7291666865348816,\n",
       "  0.7309027910232544,\n",
       "  0.7291666865348816,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7326388955116272,\n",
       "  0.7309027910232544,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.7378472089767456,\n",
       "  0.7378472089767456,\n",
       "  0.7378472089767456,\n",
       "  0.7378472089767456,\n",
       "  0.7361111044883728,\n",
       "  0.7378472089767456,\n",
       "  0.7361111044883728,\n",
       "  0.7361111044883728,\n",
       "  0.7378472089767456,\n",
       "  0.7378472089767456,\n",
       "  0.7378472089767456,\n",
       "  0.7378472089767456,\n",
       "  0.7378472089767456,\n",
       "  0.7378472089767456,\n",
       "  0.7395833134651184,\n",
       "  0.7378472089767456,\n",
       "  0.7395833134651184,\n",
       "  0.7378472089767456,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816],\n",
       " 'val_loss': [0.6261606812477112,\n",
       "  0.6229429244995117,\n",
       "  0.6200256943702698,\n",
       "  0.6173620820045471,\n",
       "  0.6149211525917053,\n",
       "  0.6126871705055237,\n",
       "  0.6106511950492859,\n",
       "  0.6087638735771179,\n",
       "  0.6070367693901062,\n",
       "  0.6054324507713318,\n",
       "  0.603952944278717,\n",
       "  0.6025863289833069,\n",
       "  0.601311445236206,\n",
       "  0.6001222133636475,\n",
       "  0.5990056395530701,\n",
       "  0.5979605317115784,\n",
       "  0.5969743132591248,\n",
       "  0.596045732498169,\n",
       "  0.5951617360115051,\n",
       "  0.5943240523338318,\n",
       "  0.5935247540473938,\n",
       "  0.5927608609199524,\n",
       "  0.5920297503471375,\n",
       "  0.5913246273994446,\n",
       "  0.5906479358673096,\n",
       "  0.589995265007019,\n",
       "  0.589363157749176,\n",
       "  0.5887491106987,\n",
       "  0.5881530046463013,\n",
       "  0.587570309638977,\n",
       "  0.5870009064674377,\n",
       "  0.586444616317749,\n",
       "  0.5858988761901855,\n",
       "  0.5853634476661682,\n",
       "  0.5848374962806702,\n",
       "  0.5843202471733093,\n",
       "  0.5838103294372559,\n",
       "  0.5833072066307068,\n",
       "  0.5828104615211487,\n",
       "  0.5823194980621338,\n",
       "  0.5818339586257935,\n",
       "  0.5813533663749695,\n",
       "  0.5808774828910828,\n",
       "  0.5804055333137512,\n",
       "  0.579937756061554,\n",
       "  0.5794732570648193,\n",
       "  0.579011857509613,\n",
       "  0.5785536170005798,\n",
       "  0.5780988335609436,\n",
       "  0.5776472687721252,\n",
       "  0.5771974325180054,\n",
       "  0.5767499804496765,\n",
       "  0.5763041377067566,\n",
       "  0.5758615136146545,\n",
       "  0.5754203200340271,\n",
       "  0.5749821066856384,\n",
       "  0.5745459198951721,\n",
       "  0.5741121768951416,\n",
       "  0.5736793875694275,\n",
       "  0.5732479691505432,\n",
       "  0.5728192329406738,\n",
       "  0.5723919868469238,\n",
       "  0.571966826915741,\n",
       "  0.5715441703796387,\n",
       "  0.5711217522621155,\n",
       "  0.5707013607025146,\n",
       "  0.5702840685844421,\n",
       "  0.5698688626289368,\n",
       "  0.5694538354873657,\n",
       "  0.5690411925315857,\n",
       "  0.568631112575531,\n",
       "  0.5682203769683838,\n",
       "  0.5678122043609619,\n",
       "  0.5674061179161072,\n",
       "  0.5670012831687927,\n",
       "  0.5665982365608215,\n",
       "  0.5661973357200623,\n",
       "  0.5657966732978821,\n",
       "  0.5653992295265198,\n",
       "  0.5650026798248291,\n",
       "  0.5646079778671265,\n",
       "  0.5642134547233582,\n",
       "  0.5638229846954346,\n",
       "  0.5634320378303528,\n",
       "  0.5630436539649963,\n",
       "  0.5626575350761414,\n",
       "  0.562272310256958,\n",
       "  0.561889111995697,\n",
       "  0.5615065693855286,\n",
       "  0.5611246824264526,\n",
       "  0.560746967792511,\n",
       "  0.5603687167167664,\n",
       "  0.5599926114082336,\n",
       "  0.5596200823783875,\n",
       "  0.5592464208602905,\n",
       "  0.5588752031326294,\n",
       "  0.55850750207901,\n",
       "  0.5581404566764832,\n",
       "  0.5577744245529175,\n",
       "  0.5574095845222473,\n",
       "  0.5570465922355652,\n",
       "  0.5566840767860413,\n",
       "  0.5563237071037292,\n",
       "  0.555966317653656,\n",
       "  0.5556097626686096,\n",
       "  0.5552546977996826,\n",
       "  0.5549024939537048,\n",
       "  0.5545503497123718,\n",
       "  0.554202139377594,\n",
       "  0.5538544058799744,\n",
       "  0.553508996963501,\n",
       "  0.553163468837738,\n",
       "  0.5528197288513184,\n",
       "  0.5524782538414001,\n",
       "  0.5521370768547058,\n",
       "  0.551798403263092,\n",
       "  0.5514605045318604,\n",
       "  0.5511242747306824,\n",
       "  0.5507900714874268,\n",
       "  0.5504581332206726,\n",
       "  0.5501247048377991,\n",
       "  0.5497943758964539,\n",
       "  0.5494667887687683,\n",
       "  0.5491397976875305,\n",
       "  0.5488152503967285,\n",
       "  0.5484917163848877,\n",
       "  0.548168957233429,\n",
       "  0.5478480458259583,\n",
       "  0.5475285053253174,\n",
       "  0.5472099184989929,\n",
       "  0.5468948483467102,\n",
       "  0.5465803742408752,\n",
       "  0.5462678670883179,\n",
       "  0.5459574460983276,\n",
       "  0.5456447601318359,\n",
       "  0.5453364253044128,\n",
       "  0.545028567314148,\n",
       "  0.5447234511375427,\n",
       "  0.5444192290306091,\n",
       "  0.5441150665283203,\n",
       "  0.5438140630722046,\n",
       "  0.5435124635696411,\n",
       "  0.5432136654853821,\n",
       "  0.5429153442382812,\n",
       "  0.5426185727119446,\n",
       "  0.5423237681388855,\n",
       "  0.5420296788215637,\n",
       "  0.5417371392250061,\n",
       "  0.5414469838142395,\n",
       "  0.5411574244499207,\n",
       "  0.5408701300621033,\n",
       "  0.5405842661857605,\n",
       "  0.540299117565155,\n",
       "  0.5400155186653137,\n",
       "  0.5397323966026306,\n",
       "  0.5394511818885803,\n",
       "  0.539173424243927,\n",
       "  0.5388937592506409,\n",
       "  0.5386162400245667,\n",
       "  0.5383409857749939,\n",
       "  0.5380674004554749,\n",
       "  0.5377952456474304,\n",
       "  0.5375223755836487,\n",
       "  0.5372541546821594,\n",
       "  0.5369861721992493,\n",
       "  0.5367204546928406,\n",
       "  0.5364547967910767,\n",
       "  0.5361902117729187,\n",
       "  0.5359276533126831,\n",
       "  0.5356661677360535,\n",
       "  0.5354045629501343,\n",
       "  0.5351443290710449,\n",
       "  0.5348851680755615,\n",
       "  0.5346289277076721,\n",
       "  0.534371554851532,\n",
       "  0.5341159105300903,\n",
       "  0.5338630080223083,\n",
       "  0.5336107611656189,\n",
       "  0.5333606600761414,\n",
       "  0.5331118702888489,\n",
       "  0.5328611731529236,\n",
       "  0.5326130986213684,\n",
       "  0.5323667526245117,\n",
       "  0.5321211218833923,\n",
       "  0.5318775773048401,\n",
       "  0.5316354036331177,\n",
       "  0.531394362449646,\n",
       "  0.53115314245224,\n",
       "  0.5309135913848877,\n",
       "  0.5306757688522339,\n",
       "  0.5304389595985413,\n",
       "  0.5302031636238098,\n",
       "  0.5299676656723022,\n",
       "  0.5297342538833618,\n",
       "  0.5295008420944214,\n",
       "  0.5292716026306152,\n",
       "  0.529043436050415,\n",
       "  0.5288143754005432,\n",
       "  0.5285873413085938,\n",
       "  0.5283614993095398],\n",
       " 'val_accuracy': [0.6875,\n",
       "  0.6979166865348816,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.6875,\n",
       "  0.6979166865348816,\n",
       "  0.6927083134651184,\n",
       "  0.6927083134651184,\n",
       "  0.703125,\n",
       "  0.6979166865348816,\n",
       "  0.703125,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.71875,\n",
       "  0.71875,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.71875,\n",
       "  0.71875,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7604166865348816,\n",
       "  0.7604166865348816,\n",
       "  0.7604166865348816,\n",
       "  0.7604166865348816,\n",
       "  0.7604166865348816,\n",
       "  0.7604166865348816,\n",
       "  0.7604166865348816,\n",
       "  0.7604166865348816,\n",
       "  0.7604166865348816]}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x241b94d7c70>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "# ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "# ax.legend()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"], 'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"], 'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7448 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7448 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7448 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7465 - val_loss: 0.5275 - val_accuracy: 0.7656\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7465 - val_loss: 0.5272 - val_accuracy: 0.7656\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7465 - val_loss: 0.5270 - val_accuracy: 0.7656\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7465 - val_loss: 0.5268 - val_accuracy: 0.7656\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7465 - val_loss: 0.5266 - val_accuracy: 0.7656\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7465 - val_loss: 0.5264 - val_accuracy: 0.7708\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7465 - val_loss: 0.5262 - val_accuracy: 0.7708\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7483 - val_loss: 0.5259 - val_accuracy: 0.7708\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7483 - val_loss: 0.5257 - val_accuracy: 0.7708\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7483 - val_loss: 0.5255 - val_accuracy: 0.7708\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7483 - val_loss: 0.5253 - val_accuracy: 0.7708\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7465 - val_loss: 0.5251 - val_accuracy: 0.7708\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7483 - val_loss: 0.5249 - val_accuracy: 0.7760\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7483 - val_loss: 0.5247 - val_accuracy: 0.7760\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7465 - val_loss: 0.5245 - val_accuracy: 0.7760\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7465 - val_loss: 0.5243 - val_accuracy: 0.7760\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7483 - val_loss: 0.5241 - val_accuracy: 0.7760\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7465 - val_loss: 0.5239 - val_accuracy: 0.7760\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7448 - val_loss: 0.5237 - val_accuracy: 0.7760\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7448 - val_loss: 0.5235 - val_accuracy: 0.7760\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7448 - val_loss: 0.5233 - val_accuracy: 0.7760\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7448 - val_loss: 0.5231 - val_accuracy: 0.7760\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7448 - val_loss: 0.5229 - val_accuracy: 0.7760\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7483 - val_loss: 0.5227 - val_accuracy: 0.7760\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7448 - val_loss: 0.5225 - val_accuracy: 0.7760\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7465 - val_loss: 0.5223 - val_accuracy: 0.7760\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7465 - val_loss: 0.5221 - val_accuracy: 0.7760\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7483 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7465 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7465 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7483 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7500 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7483 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7500 - val_loss: 0.5207 - val_accuracy: 0.7760\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7517 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7517 - val_loss: 0.5204 - val_accuracy: 0.7760\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7517 - val_loss: 0.5202 - val_accuracy: 0.7760\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7517 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7517 - val_loss: 0.5198 - val_accuracy: 0.7760\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7517 - val_loss: 0.5196 - val_accuracy: 0.7760\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7517 - val_loss: 0.5195 - val_accuracy: 0.7760\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7517 - val_loss: 0.5193 - val_accuracy: 0.7760\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7517 - val_loss: 0.5191 - val_accuracy: 0.7760\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7517 - val_loss: 0.5189 - val_accuracy: 0.7760\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7500 - val_loss: 0.5187 - val_accuracy: 0.7760\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7500 - val_loss: 0.5186 - val_accuracy: 0.7760\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7517 - val_loss: 0.5184 - val_accuracy: 0.7760\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7517 - val_loss: 0.5182 - val_accuracy: 0.7760\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7517 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7517 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7552 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7569 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7569 - val_loss: 0.5173 - val_accuracy: 0.7760\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7569 - val_loss: 0.5172 - val_accuracy: 0.7760\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7569 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7569 - val_loss: 0.5168 - val_accuracy: 0.7656\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7569 - val_loss: 0.5167 - val_accuracy: 0.7656\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7569 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7569 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7587 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7587 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7587 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7587 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7587 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7587 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7587 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7587 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7587 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7587 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7587 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7587 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7622 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7639 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7639 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7639 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7639 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7639 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7656 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7639 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7656 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7656 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7656 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7656 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7656 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7656 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7656 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7656 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7656 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7674 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7656 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7674 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7708 - val_loss: 0.5113 - val_accuracy: 0.7708\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7708 - val_loss: 0.5112 - val_accuracy: 0.7708\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7708 - val_loss: 0.5111 - val_accuracy: 0.7708\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7708 - val_loss: 0.5109 - val_accuracy: 0.7708\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7691 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7708 - val_loss: 0.5107 - val_accuracy: 0.7708\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7708 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7691 - val_loss: 0.5104 - val_accuracy: 0.7708\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7691 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7691 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7691 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7691 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7691 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7691 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7708 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7708 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7691 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7691 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7691 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7674 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7674 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7674 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7674 - val_loss: 0.5085 - val_accuracy: 0.7708\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7674 - val_loss: 0.5083 - val_accuracy: 0.7708\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7691 - val_loss: 0.5082 - val_accuracy: 0.7708\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7691 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7691 - val_loss: 0.5080 - val_accuracy: 0.7708\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7691 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7691 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7691 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7691 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7691 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7691 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7691 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7691 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7708 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7691 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7691 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7708 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7708 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7708 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7708 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7726 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7726 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7726 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7726 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7726 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7726 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7726 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7726 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7726 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7726 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7726 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7726 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7726 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7726 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7726 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7726 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7726 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7726 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7726 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7726 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7726 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7708 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7708 - val_loss: 0.5038 - val_accuracy: 0.7708\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7708 - val_loss: 0.5037 - val_accuracy: 0.7708\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7708 - val_loss: 0.5036 - val_accuracy: 0.7708\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7708 - val_loss: 0.5035 - val_accuracy: 0.7708\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7708 - val_loss: 0.5034 - val_accuracy: 0.7708\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7708 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7708 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7708 - val_loss: 0.5031 - val_accuracy: 0.7760\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7708 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7708 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7708 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7708 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7726 - val_loss: 0.5026 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7726 - val_loss: 0.5026 - val_accuracy: 0.7760\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7726 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7726 - val_loss: 0.5024 - val_accuracy: 0.7760\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7726 - val_loss: 0.5023 - val_accuracy: 0.7760\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7726 - val_loss: 0.5022 - val_accuracy: 0.7760\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7726 - val_loss: 0.5021 - val_accuracy: 0.7760\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7726 - val_loss: 0.5020 - val_accuracy: 0.7760\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7726 - val_loss: 0.5019 - val_accuracy: 0.7760\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7726 - val_loss: 0.5018 - val_accuracy: 0.7760\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7726 - val_loss: 0.5017 - val_accuracy: 0.7760\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7726 - val_loss: 0.5016 - val_accuracy: 0.7760\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7726 - val_loss: 0.5016 - val_accuracy: 0.7760\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7726 - val_loss: 0.5015 - val_accuracy: 0.7760\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7726 - val_loss: 0.5014 - val_accuracy: 0.7760\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7726 - val_loss: 0.5013 - val_accuracy: 0.7760\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7726 - val_loss: 0.5012 - val_accuracy: 0.7760\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7726 - val_loss: 0.5011 - val_accuracy: 0.7760\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7726 - val_loss: 0.5010 - val_accuracy: 0.7760\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7726 - val_loss: 0.5010 - val_accuracy: 0.7760\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7726 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7726 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7726 - val_loss: 0.5007 - val_accuracy: 0.7760\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7726 - val_loss: 0.5006 - val_accuracy: 0.7760\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7726 - val_loss: 0.5005 - val_accuracy: 0.7760\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7726 - val_loss: 0.5005 - val_accuracy: 0.7760\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7726 - val_loss: 0.5004 - val_accuracy: 0.7760\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7726 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7760\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7743 - val_loss: 0.4999 - val_accuracy: 0.7760\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7743 - val_loss: 0.4998 - val_accuracy: 0.7760\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7726 - val_loss: 0.4997 - val_accuracy: 0.7760\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7726 - val_loss: 0.4997 - val_accuracy: 0.7760\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7726 - val_loss: 0.4996 - val_accuracy: 0.7760\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7726 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7726 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7726 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7726 - val_loss: 0.4993 - val_accuracy: 0.7760\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7726 - val_loss: 0.4992 - val_accuracy: 0.7760\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7726 - val_loss: 0.4991 - val_accuracy: 0.7760\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7726 - val_loss: 0.4991 - val_accuracy: 0.7760\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7726 - val_loss: 0.4990 - val_accuracy: 0.7760\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7726 - val_loss: 0.4989 - val_accuracy: 0.7760\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7726 - val_loss: 0.4988 - val_accuracy: 0.7760\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7726 - val_loss: 0.4988 - val_accuracy: 0.7760\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7743 - val_loss: 0.4987 - val_accuracy: 0.7760\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7743 - val_loss: 0.4986 - val_accuracy: 0.7760\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7726 - val_loss: 0.4986 - val_accuracy: 0.7760\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7726 - val_loss: 0.4985 - val_accuracy: 0.7760\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7743 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7726 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7708 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7726 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7726 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7708 - val_loss: 0.4973 - val_accuracy: 0.7604\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7708 - val_loss: 0.4973 - val_accuracy: 0.7604\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7708 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7708 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7708 - val_loss: 0.4970 - val_accuracy: 0.7604\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7708 - val_loss: 0.4970 - val_accuracy: 0.7604\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7708 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7708 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7708 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7708 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7708 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7708 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7708 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7708 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7708 - val_loss: 0.4964 - val_accuracy: 0.7604\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7708 - val_loss: 0.4962 - val_accuracy: 0.7604\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7708 - val_loss: 0.4962 - val_accuracy: 0.7604\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7708 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7708 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7708 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7708 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7708 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7708 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7708 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7708 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7708 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7708 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7708 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7708 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7708 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7708 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7708 - val_loss: 0.4951 - val_accuracy: 0.7604\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7726 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7726 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7726 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7726 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7726 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7726 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7726 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7726 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7743 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7743 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7760 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7760 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7743 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7760 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7760 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7760 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7760 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7760 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7760 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7760 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7760 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7760 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7760 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7760 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7760 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7760 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7760 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7760 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7760 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7760 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7743 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7743 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7743 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7743 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7743 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7760 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7760 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7743 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7743 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7760 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7760 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7760 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7760 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7760 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7743 - val_loss: 0.4922 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7743 - val_loss: 0.4922 - val_accuracy: 0.7708\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7760 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7760 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7743 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7743 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7760 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7760 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7760 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7760 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7760 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7760 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7760 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7760 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7760 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7760 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7760 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7760 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7760 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7760 - val_loss: 0.4904 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7760 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7760 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7760 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7760 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7760 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7760 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7760 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7760 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7760 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7778 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7778 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7778 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7778 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7812 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7812 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7847 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7847 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7847 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7865 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7865 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7865 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7882 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7882 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7865 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7882 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7865 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7865 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7760 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7760 - val_loss: 0.4864 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7760 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7760 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7760 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7795 - val_loss: 0.4865 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x241b935d6d0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.7503 - accuracy: 0.3819 - val_loss: 0.7546 - val_accuracy: 0.4010\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7393 - accuracy: 0.4045 - val_loss: 0.7439 - val_accuracy: 0.4010\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7293 - accuracy: 0.4306 - val_loss: 0.7343 - val_accuracy: 0.4219\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7204 - accuracy: 0.4497 - val_loss: 0.7257 - val_accuracy: 0.4167\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7125 - accuracy: 0.4740 - val_loss: 0.7179 - val_accuracy: 0.4271\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7052 - accuracy: 0.4861 - val_loss: 0.7109 - val_accuracy: 0.4531\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.5191 - val_loss: 0.7045 - val_accuracy: 0.4844\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5260 - val_loss: 0.6987 - val_accuracy: 0.5000\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5590 - val_loss: 0.6934 - val_accuracy: 0.5312\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5781 - val_loss: 0.6885 - val_accuracy: 0.5260\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.6128 - val_loss: 0.6839 - val_accuracy: 0.5469\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6740 - accuracy: 0.6198 - val_loss: 0.6797 - val_accuracy: 0.5625\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6702 - accuracy: 0.6372 - val_loss: 0.6758 - val_accuracy: 0.5781\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.6476 - val_loss: 0.6722 - val_accuracy: 0.5833\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.6528 - val_loss: 0.6687 - val_accuracy: 0.5885\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.6562 - val_loss: 0.6656 - val_accuracy: 0.5938\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6571 - accuracy: 0.6615 - val_loss: 0.6625 - val_accuracy: 0.6146\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.6736 - val_loss: 0.6597 - val_accuracy: 0.6250\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6736 - val_loss: 0.6570 - val_accuracy: 0.6354\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.6753 - val_loss: 0.6545 - val_accuracy: 0.6406\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6840 - val_loss: 0.6522 - val_accuracy: 0.6510\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6447 - accuracy: 0.6806 - val_loss: 0.6500 - val_accuracy: 0.6719\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6788 - val_loss: 0.6478 - val_accuracy: 0.6667\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6788 - val_loss: 0.6458 - val_accuracy: 0.6823\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.6788 - val_loss: 0.6438 - val_accuracy: 0.6615\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6368 - accuracy: 0.6788 - val_loss: 0.6419 - val_accuracy: 0.6615\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6823 - val_loss: 0.6400 - val_accuracy: 0.6615\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6333 - accuracy: 0.6840 - val_loss: 0.6383 - val_accuracy: 0.6615\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.6840 - val_loss: 0.6366 - val_accuracy: 0.6719\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.6840 - val_loss: 0.6349 - val_accuracy: 0.6875\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.6892 - val_loss: 0.6332 - val_accuracy: 0.6719\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6267 - accuracy: 0.6892 - val_loss: 0.6316 - val_accuracy: 0.6823\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6875 - val_loss: 0.6300 - val_accuracy: 0.6823\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6858 - val_loss: 0.6284 - val_accuracy: 0.6823\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.6840 - val_loss: 0.6269 - val_accuracy: 0.6875\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6840 - val_loss: 0.6254 - val_accuracy: 0.6927\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6892 - val_loss: 0.6240 - val_accuracy: 0.6927\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.6858 - val_loss: 0.6225 - val_accuracy: 0.6927\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.6788 - val_loss: 0.6211 - val_accuracy: 0.6875\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.6823 - val_loss: 0.6197 - val_accuracy: 0.6875\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.6806 - val_loss: 0.6183 - val_accuracy: 0.6823\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.6823 - val_loss: 0.6170 - val_accuracy: 0.6875\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.6840 - val_loss: 0.6156 - val_accuracy: 0.6927\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.6840 - val_loss: 0.6143 - val_accuracy: 0.6927\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.6875 - val_loss: 0.6130 - val_accuracy: 0.6927\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.6892 - val_loss: 0.6117 - val_accuracy: 0.6875\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6875 - val_loss: 0.6104 - val_accuracy: 0.6979\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.6875 - val_loss: 0.6091 - val_accuracy: 0.6927\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.6892 - val_loss: 0.6078 - val_accuracy: 0.6927\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6020 - accuracy: 0.6892 - val_loss: 0.6066 - val_accuracy: 0.6927\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.6927 - val_loss: 0.6053 - val_accuracy: 0.6927\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.6910 - val_loss: 0.6041 - val_accuracy: 0.6927\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.6927 - val_loss: 0.6029 - val_accuracy: 0.6927\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.6927 - val_loss: 0.6017 - val_accuracy: 0.6927\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6892 - val_loss: 0.6005 - val_accuracy: 0.6927\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.6910 - val_loss: 0.5993 - val_accuracy: 0.6927\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.6944 - val_loss: 0.5981 - val_accuracy: 0.6927\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.6962 - val_loss: 0.5970 - val_accuracy: 0.6979\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.6962 - val_loss: 0.5958 - val_accuracy: 0.6979\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.6997 - val_loss: 0.5946 - val_accuracy: 0.6979\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.7014 - val_loss: 0.5935 - val_accuracy: 0.6875\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.7031 - val_loss: 0.5924 - val_accuracy: 0.6875\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.7031 - val_loss: 0.5913 - val_accuracy: 0.6927\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7031 - val_loss: 0.5902 - val_accuracy: 0.6927\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7049 - val_loss: 0.5891 - val_accuracy: 0.6927\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7049 - val_loss: 0.5880 - val_accuracy: 0.6927\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7049 - val_loss: 0.5869 - val_accuracy: 0.6927\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7083 - val_loss: 0.5858 - val_accuracy: 0.6927\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7101 - val_loss: 0.5847 - val_accuracy: 0.6927\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7118 - val_loss: 0.5837 - val_accuracy: 0.6979\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7135 - val_loss: 0.5826 - val_accuracy: 0.6979\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7153 - val_loss: 0.5816 - val_accuracy: 0.6979\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.7118 - val_loss: 0.5805 - val_accuracy: 0.6979\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7118 - val_loss: 0.5795 - val_accuracy: 0.6979\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.7118 - val_loss: 0.5785 - val_accuracy: 0.6979\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7118 - val_loss: 0.5775 - val_accuracy: 0.6979\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.7153 - val_loss: 0.5765 - val_accuracy: 0.6979\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7170 - val_loss: 0.5755 - val_accuracy: 0.6979\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7170 - val_loss: 0.5745 - val_accuracy: 0.6979\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7188 - val_loss: 0.5736 - val_accuracy: 0.6979\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7205 - val_loss: 0.5726 - val_accuracy: 0.6979\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7188 - val_loss: 0.5717 - val_accuracy: 0.6979\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7222 - val_loss: 0.5707 - val_accuracy: 0.6979\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7205 - val_loss: 0.5698 - val_accuracy: 0.6979\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7205 - val_loss: 0.5688 - val_accuracy: 0.6979\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7205 - val_loss: 0.5679 - val_accuracy: 0.6979\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7188 - val_loss: 0.5670 - val_accuracy: 0.6979\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7205 - val_loss: 0.5661 - val_accuracy: 0.6979\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7188 - val_loss: 0.5652 - val_accuracy: 0.6979\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7205 - val_loss: 0.5643 - val_accuracy: 0.6979\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7222 - val_loss: 0.5634 - val_accuracy: 0.6927\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7222 - val_loss: 0.5625 - val_accuracy: 0.6927\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7240 - val_loss: 0.5616 - val_accuracy: 0.6875\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7257 - val_loss: 0.5607 - val_accuracy: 0.6927\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7274 - val_loss: 0.5599 - val_accuracy: 0.6927\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7240 - val_loss: 0.5590 - val_accuracy: 0.6927\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7240 - val_loss: 0.5582 - val_accuracy: 0.6875\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7240 - val_loss: 0.5574 - val_accuracy: 0.6875\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7222 - val_loss: 0.5565 - val_accuracy: 0.6875\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7222 - val_loss: 0.5557 - val_accuracy: 0.6875\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7188 - val_loss: 0.5549 - val_accuracy: 0.6875\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7205 - val_loss: 0.5541 - val_accuracy: 0.6875\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7222 - val_loss: 0.5533 - val_accuracy: 0.6979\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7222 - val_loss: 0.5526 - val_accuracy: 0.6979\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7257 - val_loss: 0.5518 - val_accuracy: 0.7031\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5419 - accuracy: 0.7240 - val_loss: 0.5510 - val_accuracy: 0.7031\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.7274 - val_loss: 0.5503 - val_accuracy: 0.7031\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7257 - val_loss: 0.5495 - val_accuracy: 0.7031\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7292 - val_loss: 0.5488 - val_accuracy: 0.7031\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7292 - val_loss: 0.5481 - val_accuracy: 0.7083\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7326 - val_loss: 0.5474 - val_accuracy: 0.7083\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7326 - val_loss: 0.5467 - val_accuracy: 0.7083\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7326 - val_loss: 0.5459 - val_accuracy: 0.7083\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7344 - val_loss: 0.5452 - val_accuracy: 0.7083\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7344 - val_loss: 0.5445 - val_accuracy: 0.7083\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7344 - val_loss: 0.5439 - val_accuracy: 0.7083\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7344 - val_loss: 0.5432 - val_accuracy: 0.7083\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7344 - val_loss: 0.5425 - val_accuracy: 0.7083\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7344 - val_loss: 0.5418 - val_accuracy: 0.7135\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7344 - val_loss: 0.5412 - val_accuracy: 0.7031\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7344 - val_loss: 0.5405 - val_accuracy: 0.7031\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7344 - val_loss: 0.5399 - val_accuracy: 0.7031\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7344 - val_loss: 0.5392 - val_accuracy: 0.7083\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7344 - val_loss: 0.5386 - val_accuracy: 0.7083\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7344 - val_loss: 0.5380 - val_accuracy: 0.7083\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7378 - val_loss: 0.5374 - val_accuracy: 0.7083\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5251 - accuracy: 0.7378 - val_loss: 0.5368 - val_accuracy: 0.7083\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7378 - val_loss: 0.5362 - val_accuracy: 0.7083\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7344 - val_loss: 0.5356 - val_accuracy: 0.7083\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7361 - val_loss: 0.5350 - val_accuracy: 0.7083\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7361 - val_loss: 0.5345 - val_accuracy: 0.7135\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7361 - val_loss: 0.5339 - val_accuracy: 0.7135\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7378 - val_loss: 0.5333 - val_accuracy: 0.7135\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7396 - val_loss: 0.5328 - val_accuracy: 0.7135\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7396 - val_loss: 0.5322 - val_accuracy: 0.7135\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7413 - val_loss: 0.5317 - val_accuracy: 0.7135\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7396 - val_loss: 0.5312 - val_accuracy: 0.7135\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7413 - val_loss: 0.5307 - val_accuracy: 0.7188\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7396 - val_loss: 0.5302 - val_accuracy: 0.7188\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7413 - val_loss: 0.5297 - val_accuracy: 0.7188\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7396 - val_loss: 0.5292 - val_accuracy: 0.7188\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7396 - val_loss: 0.5287 - val_accuracy: 0.7188\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7396 - val_loss: 0.5283 - val_accuracy: 0.7240\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7378 - val_loss: 0.5278 - val_accuracy: 0.7240\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7396 - val_loss: 0.5274 - val_accuracy: 0.7240\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7413 - val_loss: 0.5269 - val_accuracy: 0.7240\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7431 - val_loss: 0.5265 - val_accuracy: 0.7240\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7465 - val_loss: 0.5261 - val_accuracy: 0.7240\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7465 - val_loss: 0.5256 - val_accuracy: 0.7240\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7465 - val_loss: 0.5252 - val_accuracy: 0.7240\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7465 - val_loss: 0.5248 - val_accuracy: 0.7240\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7465 - val_loss: 0.5244 - val_accuracy: 0.7240\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7483 - val_loss: 0.5240 - val_accuracy: 0.7240\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7448 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7465 - val_loss: 0.5232 - val_accuracy: 0.7188\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7483 - val_loss: 0.5229 - val_accuracy: 0.7188\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7483 - val_loss: 0.5225 - val_accuracy: 0.7188\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7465 - val_loss: 0.5221 - val_accuracy: 0.7188\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7483 - val_loss: 0.5218 - val_accuracy: 0.7188\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7483 - val_loss: 0.5214 - val_accuracy: 0.7188\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7535 - val_loss: 0.5208 - val_accuracy: 0.7135\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7535 - val_loss: 0.5204 - val_accuracy: 0.7188\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.7188\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7535 - val_loss: 0.5198 - val_accuracy: 0.7188\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7517 - val_loss: 0.5195 - val_accuracy: 0.7188\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7535 - val_loss: 0.5191 - val_accuracy: 0.7188\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7535 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7188\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7552 - val_loss: 0.5183 - val_accuracy: 0.7188\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7552 - val_loss: 0.5180 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7535 - val_loss: 0.5177 - val_accuracy: 0.7188\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7569 - val_loss: 0.5174 - val_accuracy: 0.7188\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7552 - val_loss: 0.5171 - val_accuracy: 0.7188\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7569 - val_loss: 0.5168 - val_accuracy: 0.7188\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7587 - val_loss: 0.5166 - val_accuracy: 0.7188\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7587 - val_loss: 0.5163 - val_accuracy: 0.7188\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7587 - val_loss: 0.5160 - val_accuracy: 0.7240\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7587 - val_loss: 0.5157 - val_accuracy: 0.7240\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7587 - val_loss: 0.5155 - val_accuracy: 0.7240\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7587 - val_loss: 0.5152 - val_accuracy: 0.7240\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7604 - val_loss: 0.5149 - val_accuracy: 0.7240\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7587 - val_loss: 0.5146 - val_accuracy: 0.7240\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7656 - val_loss: 0.5143 - val_accuracy: 0.7240\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7622 - val_loss: 0.5141 - val_accuracy: 0.7240\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7674 - val_loss: 0.5138 - val_accuracy: 0.7240\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7674 - val_loss: 0.5135 - val_accuracy: 0.7240\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.7674 - val_loss: 0.5133 - val_accuracy: 0.7240\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7674 - val_loss: 0.5130 - val_accuracy: 0.7240\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7674 - val_loss: 0.5127 - val_accuracy: 0.7240\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7674 - val_loss: 0.5125 - val_accuracy: 0.7240\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7691 - val_loss: 0.5123 - val_accuracy: 0.7240\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7691 - val_loss: 0.5120 - val_accuracy: 0.7240\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7674 - val_loss: 0.5118 - val_accuracy: 0.7240\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7674 - val_loss: 0.5116 - val_accuracy: 0.7240\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7691 - val_loss: 0.5113 - val_accuracy: 0.7240\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7674 - val_loss: 0.5111 - val_accuracy: 0.7240\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7691 - val_loss: 0.5109 - val_accuracy: 0.7240\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7691 - val_loss: 0.5107 - val_accuracy: 0.7240\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7691 - val_loss: 0.5104 - val_accuracy: 0.7240\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7674 - val_loss: 0.5102 - val_accuracy: 0.7292\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7691 - val_loss: 0.5100 - val_accuracy: 0.7292\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7674 - val_loss: 0.5098 - val_accuracy: 0.7292\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7674 - val_loss: 0.5096 - val_accuracy: 0.7292\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7674 - val_loss: 0.5094 - val_accuracy: 0.7292\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7674 - val_loss: 0.5092 - val_accuracy: 0.7292\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7674 - val_loss: 0.5090 - val_accuracy: 0.7292\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7674 - val_loss: 0.5088 - val_accuracy: 0.7292\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7674 - val_loss: 0.5086 - val_accuracy: 0.7292\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7674 - val_loss: 0.5085 - val_accuracy: 0.7292\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7674 - val_loss: 0.5083 - val_accuracy: 0.7292\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7691 - val_loss: 0.5081 - val_accuracy: 0.7292\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7691 - val_loss: 0.5079 - val_accuracy: 0.7292\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7691 - val_loss: 0.5077 - val_accuracy: 0.7344\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7691 - val_loss: 0.5076 - val_accuracy: 0.7344\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7691 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7691 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7691 - val_loss: 0.5071 - val_accuracy: 0.7344\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7691 - val_loss: 0.5069 - val_accuracy: 0.7344\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7691 - val_loss: 0.5067 - val_accuracy: 0.7344\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7691 - val_loss: 0.5065 - val_accuracy: 0.7344\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7691 - val_loss: 0.5064 - val_accuracy: 0.7344\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7691 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7691 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7674 - val_loss: 0.5059 - val_accuracy: 0.7344\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7674 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7674 - val_loss: 0.5056 - val_accuracy: 0.7344\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7674 - val_loss: 0.5055 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7674 - val_loss: 0.5053 - val_accuracy: 0.7344\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7674 - val_loss: 0.5052 - val_accuracy: 0.7344\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7674 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7674 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7674 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7691 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7691 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7691 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7691 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7691 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7708 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7708 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7708 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7708 - val_loss: 0.5038 - val_accuracy: 0.7396\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7708 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7691 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7708 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7691 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7691 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7691 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7691 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7691 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7691 - val_loss: 0.5029 - val_accuracy: 0.7396\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7691 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7691 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7691 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7674 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7691 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7691 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7674 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7708 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.7691 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7691 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7691 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7691 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7691 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7691 - val_loss: 0.5017 - val_accuracy: 0.7344\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7691 - val_loss: 0.5016 - val_accuracy: 0.7344\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7691 - val_loss: 0.5015 - val_accuracy: 0.7344\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7691 - val_loss: 0.5015 - val_accuracy: 0.7344\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7691 - val_loss: 0.5014 - val_accuracy: 0.7344\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7691 - val_loss: 0.5013 - val_accuracy: 0.7344\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7691 - val_loss: 0.5013 - val_accuracy: 0.7344\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7691 - val_loss: 0.5012 - val_accuracy: 0.7344\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7691 - val_loss: 0.5011 - val_accuracy: 0.7344\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7691 - val_loss: 0.5010 - val_accuracy: 0.7344\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.5010 - val_accuracy: 0.7448\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7691 - val_loss: 0.5009 - val_accuracy: 0.7448\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7691 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7691 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7691 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7691 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7691 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7691 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7691 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7691 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7691 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7691 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7708 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7691 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7691 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7691 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7691 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7674 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7691 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7708 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7674 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7691 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7708 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7691 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7691 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7691 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7691 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7691 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7674 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7708 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7691 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7708 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7691 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7708 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7708 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7708 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7708 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7708 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7726 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7726 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7726 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7726 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7743 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7743 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7743 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7743 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7726 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7726 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7743 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7726 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7743 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7726 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7760 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7726 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7743 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7743 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7726 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7708 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7708 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7708 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7708 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7726 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7691 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7726 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7726 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7691 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7726 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7726 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7708 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7708 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7691 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7708 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7691 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7691 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7691 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7691 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7691 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7708 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7726 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7726 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7743 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7847 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7847 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7865 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7847 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7847 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7847 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7812 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7847 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7847 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7847 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7847 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7847 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7847 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7830 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7830 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7812 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7847 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7865 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7812 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7847 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7812 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7812 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7847 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7812 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7847 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7812 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7812 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7812 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7865 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7830 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7847 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7899 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7899 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7899 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7882 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.4982 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7917 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7899 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7899 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7917 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4990 - val_accuracy: 0.7396\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4990 - val_accuracy: 0.7396\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7396\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7396\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7899 - val_loss: 0.4990 - val_accuracy: 0.7396\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7934 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7899 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7934 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7934 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7934 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7917 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7934 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1083/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7396\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7396\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7396\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7396\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7396\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7396\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7396\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7396\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7396\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7396\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7396\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7396\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7396\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7396\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7396\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7396\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7396\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7396\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7396\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7396\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7396\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.4999 - val_accuracy: 0.7396\n",
      "Epoch 1139/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.4999 - val_accuracy: 0.7396\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7396\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.4999 - val_accuracy: 0.7396\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.4999 - val_accuracy: 0.7396\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7396\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.5000 - val_accuracy: 0.7396\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7882 - val_loss: 0.5000 - val_accuracy: 0.7396\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7396\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7396\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7396\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7865 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7865 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7865 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7865 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.5003 - val_accuracy: 0.7396\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7865 - val_loss: 0.5003 - val_accuracy: 0.7396\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.5003 - val_accuracy: 0.7396\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.5003 - val_accuracy: 0.7396\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7396\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7396\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7396\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7865 - val_loss: 0.5005 - val_accuracy: 0.7396\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7396\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7396\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7865 - val_loss: 0.5006 - val_accuracy: 0.7396\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7396\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7865 - val_loss: 0.5006 - val_accuracy: 0.7396\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7396\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7396\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7396\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7396\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7396\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7396\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7396\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7396\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7396\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7396\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7396\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7865 - val_loss: 0.5008 - val_accuracy: 0.7396\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7396\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7396\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7396\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7396\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7865 - val_loss: 0.5009 - val_accuracy: 0.7396\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7396\n",
      "Epoch 1195/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7865 - val_loss: 0.5009 - val_accuracy: 0.7396\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7396\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7396\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7396\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7396\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7865 - val_loss: 0.5010 - val_accuracy: 0.7396\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7396\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7865 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7865 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 1251/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7951 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7951 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7934 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1307/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1363/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1419/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7986 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7986 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1475/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 1s 8ms/step - loss: 0.7211 - accuracy: 0.5417 - val_loss: 0.7163 - val_accuracy: 0.5729\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7096 - accuracy: 0.6059 - val_loss: 0.7079 - val_accuracy: 0.5885\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7012 - accuracy: 0.6267 - val_loss: 0.7006 - val_accuracy: 0.5990\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6458 - val_loss: 0.6935 - val_accuracy: 0.6146\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.6580 - val_loss: 0.6865 - val_accuracy: 0.6146\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.6580 - val_loss: 0.6785 - val_accuracy: 0.6146\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.6597 - val_loss: 0.6692 - val_accuracy: 0.6198\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6580 - val_loss: 0.6593 - val_accuracy: 0.6198\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.6562 - val_loss: 0.6476 - val_accuracy: 0.6302\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6304 - accuracy: 0.6580 - val_loss: 0.6368 - val_accuracy: 0.6302\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6597 - val_loss: 0.6259 - val_accuracy: 0.6302\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.6649 - val_loss: 0.6154 - val_accuracy: 0.6354\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.6667 - val_loss: 0.6058 - val_accuracy: 0.6354\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.6684 - val_loss: 0.5973 - val_accuracy: 0.6458\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.6684 - val_loss: 0.5894 - val_accuracy: 0.6458\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.6753 - val_loss: 0.5823 - val_accuracy: 0.6458\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.6771 - val_loss: 0.5763 - val_accuracy: 0.6354\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.6771 - val_loss: 0.5707 - val_accuracy: 0.6354\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.6892 - val_loss: 0.5656 - val_accuracy: 0.6354\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.6962 - val_loss: 0.5609 - val_accuracy: 0.6510\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.7049 - val_loss: 0.5566 - val_accuracy: 0.6719\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7153 - val_loss: 0.5530 - val_accuracy: 0.6875\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7326 - val_loss: 0.5490 - val_accuracy: 0.7031\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7396 - val_loss: 0.5455 - val_accuracy: 0.7135\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7448 - val_loss: 0.5421 - val_accuracy: 0.7083\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7378 - val_loss: 0.5392 - val_accuracy: 0.7031\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7413 - val_loss: 0.5364 - val_accuracy: 0.7031\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7483 - val_loss: 0.5342 - val_accuracy: 0.6979\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7500 - val_loss: 0.5320 - val_accuracy: 0.6927\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7517 - val_loss: 0.5302 - val_accuracy: 0.7292\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7604 - val_loss: 0.5288 - val_accuracy: 0.7292\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7622 - val_loss: 0.5279 - val_accuracy: 0.7240\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7656 - val_loss: 0.5269 - val_accuracy: 0.7344\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7743 - val_loss: 0.5262 - val_accuracy: 0.7344\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7778 - val_loss: 0.5257 - val_accuracy: 0.7396\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7795 - val_loss: 0.5256 - val_accuracy: 0.7344\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7760 - val_loss: 0.5253 - val_accuracy: 0.7344\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.5252 - val_accuracy: 0.7292\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7778 - val_loss: 0.5248 - val_accuracy: 0.7292\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.5244 - val_accuracy: 0.7292\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.5243 - val_accuracy: 0.7240\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7812 - val_loss: 0.5240 - val_accuracy: 0.7240\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7743 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.5237 - val_accuracy: 0.7292\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.5234 - val_accuracy: 0.7240\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.5231 - val_accuracy: 0.7292\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7812 - val_loss: 0.5231 - val_accuracy: 0.7292\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7292\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7292\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7240\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7292\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7292\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.5225 - val_accuracy: 0.7240\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7830 - val_loss: 0.5225 - val_accuracy: 0.7292\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7830 - val_loss: 0.5224 - val_accuracy: 0.7292\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7812 - val_loss: 0.5219 - val_accuracy: 0.7292\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7830 - val_loss: 0.5217 - val_accuracy: 0.7292\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7830 - val_loss: 0.5217 - val_accuracy: 0.7292\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7830 - val_loss: 0.5219 - val_accuracy: 0.7292\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7830 - val_loss: 0.5217 - val_accuracy: 0.7292\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7865 - val_loss: 0.5216 - val_accuracy: 0.7292\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7847 - val_loss: 0.5215 - val_accuracy: 0.7344\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7865 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7865 - val_loss: 0.5211 - val_accuracy: 0.7344\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7899 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7899 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7882 - val_loss: 0.5210 - val_accuracy: 0.7344\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7882 - val_loss: 0.5212 - val_accuracy: 0.7344\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7899 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7934 - val_loss: 0.5215 - val_accuracy: 0.7396\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.5216 - val_accuracy: 0.7344\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.5220 - val_accuracy: 0.7344\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.5224 - val_accuracy: 0.7344\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.5227 - val_accuracy: 0.7344\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.5233 - val_accuracy: 0.7292\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7899 - val_loss: 0.5236 - val_accuracy: 0.7292\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7934 - val_loss: 0.5241 - val_accuracy: 0.7292\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7934 - val_loss: 0.5245 - val_accuracy: 0.7344\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7934 - val_loss: 0.5250 - val_accuracy: 0.7396\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7934 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.5260 - val_accuracy: 0.7396\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7934 - val_loss: 0.5263 - val_accuracy: 0.7396\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.5267 - val_accuracy: 0.7448\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7951 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7969 - val_loss: 0.5278 - val_accuracy: 0.7396\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7969 - val_loss: 0.5282 - val_accuracy: 0.7396\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7951 - val_loss: 0.5284 - val_accuracy: 0.7396\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7951 - val_loss: 0.5290 - val_accuracy: 0.7396\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7969 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7986 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8003 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7986 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7986 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8021 - val_loss: 0.5324 - val_accuracy: 0.7344\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.8003 - val_loss: 0.5326 - val_accuracy: 0.7344\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8003 - val_loss: 0.5329 - val_accuracy: 0.7344\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.5332 - val_accuracy: 0.7292\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5336 - val_accuracy: 0.7292\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7951 - val_loss: 0.5337 - val_accuracy: 0.7292\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8003 - val_loss: 0.5340 - val_accuracy: 0.7292\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7986 - val_loss: 0.5342 - val_accuracy: 0.7292\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8003 - val_loss: 0.5345 - val_accuracy: 0.7292\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7969 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8003 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8003 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8003 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.8003 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8003 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8003 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.5375 - val_accuracy: 0.7240\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7969 - val_loss: 0.5377 - val_accuracy: 0.7240\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7951 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.5381 - val_accuracy: 0.7240\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7969 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7969 - val_loss: 0.5386 - val_accuracy: 0.7240\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7969 - val_loss: 0.5389 - val_accuracy: 0.7188\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8021 - val_loss: 0.5395 - val_accuracy: 0.7188\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7986 - val_loss: 0.5398 - val_accuracy: 0.7188\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7986 - val_loss: 0.5397 - val_accuracy: 0.7188\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.7934 - val_loss: 0.5399 - val_accuracy: 0.7188\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.5401 - val_accuracy: 0.7188\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8021 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5407 - val_accuracy: 0.7188\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7986 - val_loss: 0.5406 - val_accuracy: 0.7188\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7934 - val_loss: 0.5407 - val_accuracy: 0.7188\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7986 - val_loss: 0.5410 - val_accuracy: 0.7188\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8021 - val_loss: 0.5411 - val_accuracy: 0.7188\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.5415 - val_accuracy: 0.7135\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5415 - val_accuracy: 0.7135\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5415 - val_accuracy: 0.7135\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8003 - val_loss: 0.5418 - val_accuracy: 0.7135\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5419 - val_accuracy: 0.7135\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.8021 - val_loss: 0.5421 - val_accuracy: 0.7135\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8003 - val_loss: 0.5423 - val_accuracy: 0.7135\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8038 - val_loss: 0.5427 - val_accuracy: 0.7135\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.5427 - val_accuracy: 0.7135\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.8021 - val_loss: 0.5427 - val_accuracy: 0.7135\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8056 - val_loss: 0.5431 - val_accuracy: 0.7188\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8073 - val_loss: 0.5432 - val_accuracy: 0.7135\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8038 - val_loss: 0.5432 - val_accuracy: 0.7135\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8038 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8038 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8108 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8090 - val_loss: 0.5438 - val_accuracy: 0.7188\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8073 - val_loss: 0.5442 - val_accuracy: 0.7188\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.8073 - val_loss: 0.5443 - val_accuracy: 0.7188\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.8090 - val_loss: 0.5444 - val_accuracy: 0.7188\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8056 - val_loss: 0.5448 - val_accuracy: 0.7188\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8108 - val_loss: 0.5449 - val_accuracy: 0.7188\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.8073 - val_loss: 0.5449 - val_accuracy: 0.7188\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8108 - val_loss: 0.5452 - val_accuracy: 0.7188\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8073 - val_loss: 0.5452 - val_accuracy: 0.7188\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8090 - val_loss: 0.5452 - val_accuracy: 0.7188\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8038 - val_loss: 0.5450 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8108 - val_loss: 0.5452 - val_accuracy: 0.7188\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8090 - val_loss: 0.5454 - val_accuracy: 0.7188\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8073 - val_loss: 0.5454 - val_accuracy: 0.7188\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8073 - val_loss: 0.5455 - val_accuracy: 0.7188\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8108 - val_loss: 0.5454 - val_accuracy: 0.7188\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8108 - val_loss: 0.5455 - val_accuracy: 0.7188\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8125 - val_loss: 0.5453 - val_accuracy: 0.7188\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8090 - val_loss: 0.5454 - val_accuracy: 0.7188\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8108 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8090 - val_loss: 0.5456 - val_accuracy: 0.7240\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4414 - accuracy: 0.84 - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8108 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8090 - val_loss: 0.5457 - val_accuracy: 0.7188\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8090 - val_loss: 0.5453 - val_accuracy: 0.7188\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8108 - val_loss: 0.5452 - val_accuracy: 0.7188\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8090 - val_loss: 0.5456 - val_accuracy: 0.7188\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8073 - val_loss: 0.5455 - val_accuracy: 0.7188\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8090 - val_loss: 0.5455 - val_accuracy: 0.7188\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8108 - val_loss: 0.5452 - val_accuracy: 0.7188\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8108 - val_loss: 0.5456 - val_accuracy: 0.7240\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8125 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8090 - val_loss: 0.5454 - val_accuracy: 0.7240\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8090 - val_loss: 0.5453 - val_accuracy: 0.7240\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8056 - val_loss: 0.5451 - val_accuracy: 0.7240\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8142 - val_loss: 0.5453 - val_accuracy: 0.7240\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8142 - val_loss: 0.5456 - val_accuracy: 0.7240\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8142 - val_loss: 0.5456 - val_accuracy: 0.7240\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8125 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.8125 - val_loss: 0.5457 - val_accuracy: 0.7188\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8142 - val_loss: 0.5458 - val_accuracy: 0.7188\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8142 - val_loss: 0.5456 - val_accuracy: 0.7188\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8160 - val_loss: 0.5459 - val_accuracy: 0.7188\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8125 - val_loss: 0.5457 - val_accuracy: 0.7188\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8142 - val_loss: 0.5458 - val_accuracy: 0.7188\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8142 - val_loss: 0.5460 - val_accuracy: 0.7188\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8160 - val_loss: 0.5463 - val_accuracy: 0.7188\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8142 - val_loss: 0.5461 - val_accuracy: 0.7188\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8142 - val_loss: 0.5465 - val_accuracy: 0.7188\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8177 - val_loss: 0.5464 - val_accuracy: 0.7188\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8142 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8125 - val_loss: 0.5458 - val_accuracy: 0.7188\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8125 - val_loss: 0.5458 - val_accuracy: 0.7188\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8160 - val_loss: 0.5459 - val_accuracy: 0.7188\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8160 - val_loss: 0.5457 - val_accuracy: 0.7188\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8160 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8160 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8142 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8177 - val_loss: 0.5455 - val_accuracy: 0.7240\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8125 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8142 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8142 - val_loss: 0.5463 - val_accuracy: 0.7240\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8177 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8160 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8160 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8142 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8177 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8160 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 228/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8142 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8177 - val_loss: 0.5456 - val_accuracy: 0.7240\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8160 - val_loss: 0.5456 - val_accuracy: 0.7240\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8142 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8160 - val_loss: 0.5464 - val_accuracy: 0.7240\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8142 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8108 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8160 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8125 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8160 - val_loss: 0.5464 - val_accuracy: 0.7240\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8125 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8125 - val_loss: 0.5468 - val_accuracy: 0.7292\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8125 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8108 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8177 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8090 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8177 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8194 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8142 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8142 - val_loss: 0.5478 - val_accuracy: 0.7240\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8108 - val_loss: 0.5474 - val_accuracy: 0.7240\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.8142 - val_loss: 0.5477 - val_accuracy: 0.7240\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8160 - val_loss: 0.5480 - val_accuracy: 0.7292\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8160 - val_loss: 0.5483 - val_accuracy: 0.7292\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8142 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8177 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8125 - val_loss: 0.5490 - val_accuracy: 0.7292\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8177 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8177 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8160 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8125 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8142 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8194 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8160 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8177 - val_loss: 0.5496 - val_accuracy: 0.7292\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8194 - val_loss: 0.5494 - val_accuracy: 0.7344\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8177 - val_loss: 0.5493 - val_accuracy: 0.7344\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8142 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8160 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8177 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8177 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8177 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8177 - val_loss: 0.5497 - val_accuracy: 0.7240\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8160 - val_loss: 0.5497 - val_accuracy: 0.7240\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8177 - val_loss: 0.5504 - val_accuracy: 0.7240\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8177 - val_loss: 0.5500 - val_accuracy: 0.7240\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8160 - val_loss: 0.5502 - val_accuracy: 0.7240\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8160 - val_loss: 0.5500 - val_accuracy: 0.7344\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8160 - val_loss: 0.5503 - val_accuracy: 0.7292\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8160 - val_loss: 0.5503 - val_accuracy: 0.7344\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8160 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8177 - val_loss: 0.5505 - val_accuracy: 0.7344\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8160 - val_loss: 0.5507 - val_accuracy: 0.7344\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8160 - val_loss: 0.5506 - val_accuracy: 0.7344\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8142 - val_loss: 0.5506 - val_accuracy: 0.7344\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8177 - val_loss: 0.5506 - val_accuracy: 0.7344\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8177 - val_loss: 0.5513 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8194 - val_loss: 0.5509 - val_accuracy: 0.7344\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8177 - val_loss: 0.5511 - val_accuracy: 0.7396\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8212 - val_loss: 0.5516 - val_accuracy: 0.7344\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8212 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8194 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8194 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8177 - val_loss: 0.5519 - val_accuracy: 0.7396\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8194 - val_loss: 0.5520 - val_accuracy: 0.7396\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8212 - val_loss: 0.5523 - val_accuracy: 0.7396\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8194 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8212 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8194 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8212 - val_loss: 0.5522 - val_accuracy: 0.7396\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8212 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8212 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8212 - val_loss: 0.5535 - val_accuracy: 0.7396\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8212 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8212 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8229 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8229 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8247 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8194 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8247 - val_loss: 0.5527 - val_accuracy: 0.7396\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8264 - val_loss: 0.5530 - val_accuracy: 0.7396\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8247 - val_loss: 0.5527 - val_accuracy: 0.7396\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8247 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8247 - val_loss: 0.5536 - val_accuracy: 0.7396\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8247 - val_loss: 0.5541 - val_accuracy: 0.7396\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8247 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8247 - val_loss: 0.5537 - val_accuracy: 0.7396\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8247 - val_loss: 0.5535 - val_accuracy: 0.7396\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8229 - val_loss: 0.5537 - val_accuracy: 0.7396\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8229 - val_loss: 0.5539 - val_accuracy: 0.7396\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8229 - val_loss: 0.5544 - val_accuracy: 0.7396\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8229 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8229 - val_loss: 0.5544 - val_accuracy: 0.7396\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8229 - val_loss: 0.5551 - val_accuracy: 0.7396\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8229 - val_loss: 0.5547 - val_accuracy: 0.7396\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8247 - val_loss: 0.5547 - val_accuracy: 0.7396\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8212 - val_loss: 0.5550 - val_accuracy: 0.7396\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8229 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8212 - val_loss: 0.5550 - val_accuracy: 0.7396\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8229 - val_loss: 0.5552 - val_accuracy: 0.7448\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8229 - val_loss: 0.5554 - val_accuracy: 0.7448\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8229 - val_loss: 0.5558 - val_accuracy: 0.7448\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8212 - val_loss: 0.5560 - val_accuracy: 0.7500\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8229 - val_loss: 0.5561 - val_accuracy: 0.7448\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4047 - accuracy: 0.8229 - val_loss: 0.5559 - val_accuracy: 0.7448\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8229 - val_loss: 0.5559 - val_accuracy: 0.7448\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8212 - val_loss: 0.5561 - val_accuracy: 0.7448\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8229 - val_loss: 0.5556 - val_accuracy: 0.7448\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8264 - val_loss: 0.5559 - val_accuracy: 0.7448\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8247 - val_loss: 0.5563 - val_accuracy: 0.7500\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8229 - val_loss: 0.5568 - val_accuracy: 0.7448\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8264 - val_loss: 0.5571 - val_accuracy: 0.7448\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8229 - val_loss: 0.5564 - val_accuracy: 0.7448\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8247 - val_loss: 0.5566 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8247 - val_loss: 0.5570 - val_accuracy: 0.7448\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8247 - val_loss: 0.5575 - val_accuracy: 0.7448\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8264 - val_loss: 0.5573 - val_accuracy: 0.7500\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8264 - val_loss: 0.5576 - val_accuracy: 0.7448\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8264 - val_loss: 0.5576 - val_accuracy: 0.7448\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8264 - val_loss: 0.5579 - val_accuracy: 0.7448\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8247 - val_loss: 0.5578 - val_accuracy: 0.7448\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8247 - val_loss: 0.5584 - val_accuracy: 0.7500\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8247 - val_loss: 0.5583 - val_accuracy: 0.7500\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8247 - val_loss: 0.5586 - val_accuracy: 0.7448\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8264 - val_loss: 0.5593 - val_accuracy: 0.7448\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8247 - val_loss: 0.5589 - val_accuracy: 0.7448\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8229 - val_loss: 0.5585 - val_accuracy: 0.7448\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8247 - val_loss: 0.5591 - val_accuracy: 0.7396\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8229 - val_loss: 0.5598 - val_accuracy: 0.7396\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8247 - val_loss: 0.5597 - val_accuracy: 0.7448\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8212 - val_loss: 0.5594 - val_accuracy: 0.7396\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8229 - val_loss: 0.5597 - val_accuracy: 0.7396\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8247 - val_loss: 0.5604 - val_accuracy: 0.7344\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8247 - val_loss: 0.5603 - val_accuracy: 0.7344\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8247 - val_loss: 0.5600 - val_accuracy: 0.7396\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8264 - val_loss: 0.5600 - val_accuracy: 0.7344\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8281 - val_loss: 0.5610 - val_accuracy: 0.7344\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8247 - val_loss: 0.5609 - val_accuracy: 0.7344\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8264 - val_loss: 0.5614 - val_accuracy: 0.7344\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8229 - val_loss: 0.5611 - val_accuracy: 0.7344\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8229 - val_loss: 0.5614 - val_accuracy: 0.7396\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.8247 - val_loss: 0.5617 - val_accuracy: 0.7396\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8247 - val_loss: 0.5618 - val_accuracy: 0.7396\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8247 - val_loss: 0.5622 - val_accuracy: 0.7396\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8264 - val_loss: 0.5620 - val_accuracy: 0.7448\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8229 - val_loss: 0.5620 - val_accuracy: 0.7396\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8264 - val_loss: 0.5622 - val_accuracy: 0.7396\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8264 - val_loss: 0.5624 - val_accuracy: 0.7396\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8229 - val_loss: 0.5626 - val_accuracy: 0.7448\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8247 - val_loss: 0.5626 - val_accuracy: 0.7344\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8229 - val_loss: 0.5632 - val_accuracy: 0.7344\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8264 - val_loss: 0.5637 - val_accuracy: 0.7396\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8247 - val_loss: 0.5625 - val_accuracy: 0.7396\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8229 - val_loss: 0.5632 - val_accuracy: 0.7396\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8264 - val_loss: 0.5632 - val_accuracy: 0.7344\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8264 - val_loss: 0.5635 - val_accuracy: 0.7292\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3999 - accuracy: 0.8229 - val_loss: 0.5636 - val_accuracy: 0.7188\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8229 - val_loss: 0.5633 - val_accuracy: 0.7188\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8264 - val_loss: 0.5635 - val_accuracy: 0.7240\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8247 - val_loss: 0.5629 - val_accuracy: 0.7292\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8264 - val_loss: 0.5632 - val_accuracy: 0.7292\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3994 - accuracy: 0.8264 - val_loss: 0.5646 - val_accuracy: 0.7292\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8247 - val_loss: 0.5645 - val_accuracy: 0.7240\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8264 - val_loss: 0.5643 - val_accuracy: 0.7240\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8247 - val_loss: 0.5648 - val_accuracy: 0.7240\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8229 - val_loss: 0.5651 - val_accuracy: 0.7240\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8247 - val_loss: 0.5647 - val_accuracy: 0.7240\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8264 - val_loss: 0.5647 - val_accuracy: 0.7240\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8264 - val_loss: 0.5646 - val_accuracy: 0.7240\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8299 - val_loss: 0.5641 - val_accuracy: 0.7240\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8264 - val_loss: 0.5644 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8264 - val_loss: 0.5649 - val_accuracy: 0.7240\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8247 - val_loss: 0.5640 - val_accuracy: 0.7240\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3974 - accuracy: 0.8264 - val_loss: 0.5647 - val_accuracy: 0.7240\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8299 - val_loss: 0.5648 - val_accuracy: 0.7292\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8299 - val_loss: 0.5645 - val_accuracy: 0.7292\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8281 - val_loss: 0.5645 - val_accuracy: 0.7292\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8281 - val_loss: 0.5649 - val_accuracy: 0.7292\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8316 - val_loss: 0.5651 - val_accuracy: 0.7292\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8316 - val_loss: 0.5649 - val_accuracy: 0.7240\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8299 - val_loss: 0.5657 - val_accuracy: 0.7240\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8299 - val_loss: 0.5659 - val_accuracy: 0.7240\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8299 - val_loss: 0.5659 - val_accuracy: 0.7240\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8247 - val_loss: 0.5665 - val_accuracy: 0.7292\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8281 - val_loss: 0.5669 - val_accuracy: 0.7292\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8264 - val_loss: 0.5665 - val_accuracy: 0.7240\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8299 - val_loss: 0.5660 - val_accuracy: 0.7240\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8264 - val_loss: 0.5661 - val_accuracy: 0.7240\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8281 - val_loss: 0.5657 - val_accuracy: 0.7292\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8299 - val_loss: 0.5661 - val_accuracy: 0.7188\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8316 - val_loss: 0.5660 - val_accuracy: 0.7292\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8299 - val_loss: 0.5662 - val_accuracy: 0.7292\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8299 - val_loss: 0.5661 - val_accuracy: 0.7292\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8264 - val_loss: 0.5661 - val_accuracy: 0.7292\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8264 - val_loss: 0.5663 - val_accuracy: 0.7292\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8264 - val_loss: 0.5670 - val_accuracy: 0.7292\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8281 - val_loss: 0.5672 - val_accuracy: 0.7344\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8299 - val_loss: 0.5673 - val_accuracy: 0.7292\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8299 - val_loss: 0.5673 - val_accuracy: 0.7292\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8299 - val_loss: 0.5666 - val_accuracy: 0.7292\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8299 - val_loss: 0.5665 - val_accuracy: 0.7344\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8264 - val_loss: 0.5666 - val_accuracy: 0.7292\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8281 - val_loss: 0.5672 - val_accuracy: 0.7292\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8316 - val_loss: 0.5662 - val_accuracy: 0.7292\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8281 - val_loss: 0.5671 - val_accuracy: 0.7292\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8316 - val_loss: 0.5669 - val_accuracy: 0.7240\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8299 - val_loss: 0.5670 - val_accuracy: 0.7292\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8281 - val_loss: 0.5674 - val_accuracy: 0.7240\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8316 - val_loss: 0.5672 - val_accuracy: 0.7188\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8299 - val_loss: 0.5676 - val_accuracy: 0.7188\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8316 - val_loss: 0.5680 - val_accuracy: 0.7240\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8281 - val_loss: 0.5680 - val_accuracy: 0.7240\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8264 - val_loss: 0.5677 - val_accuracy: 0.7292\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8299 - val_loss: 0.5684 - val_accuracy: 0.7188\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8316 - val_loss: 0.5682 - val_accuracy: 0.7188\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8299 - val_loss: 0.5689 - val_accuracy: 0.7188\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3928 - accuracy: 0.8299 - val_loss: 0.5688 - val_accuracy: 0.7188\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8281 - val_loss: 0.5690 - val_accuracy: 0.7188\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8299 - val_loss: 0.5693 - val_accuracy: 0.7188\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8299 - val_loss: 0.5692 - val_accuracy: 0.7188\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8333 - val_loss: 0.5687 - val_accuracy: 0.7240\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8281 - val_loss: 0.5690 - val_accuracy: 0.7188\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8281 - val_loss: 0.5688 - val_accuracy: 0.7188\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8316 - val_loss: 0.5690 - val_accuracy: 0.7188\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8299 - val_loss: 0.5687 - val_accuracy: 0.7292\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8299 - val_loss: 0.5688 - val_accuracy: 0.7188\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.8333 - val_loss: 0.5684 - val_accuracy: 0.7188\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8281 - val_loss: 0.5689 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8316 - val_loss: 0.5688 - val_accuracy: 0.7188\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8299 - val_loss: 0.5692 - val_accuracy: 0.7188\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3916 - accuracy: 0.8264 - val_loss: 0.5689 - val_accuracy: 0.7240\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8299 - val_loss: 0.5697 - val_accuracy: 0.7292\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8281 - val_loss: 0.5693 - val_accuracy: 0.7240\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8281 - val_loss: 0.5685 - val_accuracy: 0.7240\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8299 - val_loss: 0.5684 - val_accuracy: 0.7292\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8299 - val_loss: 0.5688 - val_accuracy: 0.7240\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3913 - accuracy: 0.8299 - val_loss: 0.5694 - val_accuracy: 0.7240\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8299 - val_loss: 0.5690 - val_accuracy: 0.7240\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8299 - val_loss: 0.5691 - val_accuracy: 0.7292\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3916 - accuracy: 0.8264 - val_loss: 0.5692 - val_accuracy: 0.7292\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8316 - val_loss: 0.5693 - val_accuracy: 0.7292\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8281 - val_loss: 0.5693 - val_accuracy: 0.7292\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8281 - val_loss: 0.5693 - val_accuracy: 0.7292\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8281 - val_loss: 0.5684 - val_accuracy: 0.7344\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8247 - val_loss: 0.5684 - val_accuracy: 0.7292\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8264 - val_loss: 0.5683 - val_accuracy: 0.7292\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8247 - val_loss: 0.5687 - val_accuracy: 0.7292\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8264 - val_loss: 0.5697 - val_accuracy: 0.7396\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8264 - val_loss: 0.5688 - val_accuracy: 0.7292\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8299 - val_loss: 0.5693 - val_accuracy: 0.7396\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8264 - val_loss: 0.5696 - val_accuracy: 0.7448\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.8229 - val_loss: 0.5703 - val_accuracy: 0.7500\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8247 - val_loss: 0.5696 - val_accuracy: 0.7500\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8281 - val_loss: 0.5691 - val_accuracy: 0.7500\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8299 - val_loss: 0.5692 - val_accuracy: 0.7448\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8264 - val_loss: 0.5702 - val_accuracy: 0.7448\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8212 - val_loss: 0.5692 - val_accuracy: 0.7396\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8299 - val_loss: 0.5698 - val_accuracy: 0.7396\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8247 - val_loss: 0.5695 - val_accuracy: 0.7448\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8299 - val_loss: 0.5690 - val_accuracy: 0.7448\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8281 - val_loss: 0.5687 - val_accuracy: 0.7448\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8281 - val_loss: 0.5686 - val_accuracy: 0.7396\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3900 - accuracy: 0.8281 - val_loss: 0.5687 - val_accuracy: 0.7500\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8299 - val_loss: 0.5694 - val_accuracy: 0.7500\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8299 - val_loss: 0.5700 - val_accuracy: 0.7396\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8281 - val_loss: 0.5700 - val_accuracy: 0.7500\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8281 - val_loss: 0.5688 - val_accuracy: 0.7500\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8316 - val_loss: 0.5685 - val_accuracy: 0.7500\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8299 - val_loss: 0.5700 - val_accuracy: 0.7448\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8247 - val_loss: 0.5693 - val_accuracy: 0.7448\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8299 - val_loss: 0.5692 - val_accuracy: 0.7448\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8316 - val_loss: 0.5698 - val_accuracy: 0.7448\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8299 - val_loss: 0.5694 - val_accuracy: 0.7448\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8264 - val_loss: 0.5690 - val_accuracy: 0.7500\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8316 - val_loss: 0.5690 - val_accuracy: 0.7500\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8229 - val_loss: 0.5686 - val_accuracy: 0.7500\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8299 - val_loss: 0.5691 - val_accuracy: 0.7500\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8281 - val_loss: 0.5698 - val_accuracy: 0.7500\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8264 - val_loss: 0.5696 - val_accuracy: 0.7500\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8264 - val_loss: 0.5686 - val_accuracy: 0.7448\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8281 - val_loss: 0.5689 - val_accuracy: 0.7500\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8247 - val_loss: 0.5692 - val_accuracy: 0.7500\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8333 - val_loss: 0.5701 - val_accuracy: 0.7500\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8316 - val_loss: 0.5694 - val_accuracy: 0.7500\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8264 - val_loss: 0.5697 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8281 - val_loss: 0.5691 - val_accuracy: 0.7500\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8316 - val_loss: 0.5696 - val_accuracy: 0.7500\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8264 - val_loss: 0.5685 - val_accuracy: 0.7500\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8299 - val_loss: 0.5683 - val_accuracy: 0.7500\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8316 - val_loss: 0.5681 - val_accuracy: 0.7500\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8247 - val_loss: 0.5674 - val_accuracy: 0.7552\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8281 - val_loss: 0.5673 - val_accuracy: 0.7500\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8264 - val_loss: 0.5678 - val_accuracy: 0.7500\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8281 - val_loss: 0.5690 - val_accuracy: 0.7500\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8281 - val_loss: 0.5686 - val_accuracy: 0.7500\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8247 - val_loss: 0.5684 - val_accuracy: 0.7500\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8264 - val_loss: 0.5686 - val_accuracy: 0.7552\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8264 - val_loss: 0.5682 - val_accuracy: 0.7552\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8299 - val_loss: 0.5675 - val_accuracy: 0.7500\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8264 - val_loss: 0.5682 - val_accuracy: 0.7500\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8299 - val_loss: 0.5681 - val_accuracy: 0.7500\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4700 - accuracy: 0.75 - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8333 - val_loss: 0.5684 - val_accuracy: 0.7500\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8247 - val_loss: 0.5683 - val_accuracy: 0.7500\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8316 - val_loss: 0.5685 - val_accuracy: 0.7500\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8316 - val_loss: 0.5689 - val_accuracy: 0.7500\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8264 - val_loss: 0.5693 - val_accuracy: 0.7500\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8281 - val_loss: 0.5687 - val_accuracy: 0.7500\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8281 - val_loss: 0.5686 - val_accuracy: 0.7500\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8247 - val_loss: 0.5685 - val_accuracy: 0.7500\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3871 - accuracy: 0.8299 - val_loss: 0.5688 - val_accuracy: 0.7448\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8299 - val_loss: 0.5691 - val_accuracy: 0.7500\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8247 - val_loss: 0.5688 - val_accuracy: 0.7448\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8247 - val_loss: 0.5689 - val_accuracy: 0.7448\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8299 - val_loss: 0.5688 - val_accuracy: 0.7448\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8264 - val_loss: 0.5684 - val_accuracy: 0.7448\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8264 - val_loss: 0.5688 - val_accuracy: 0.7448\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8264 - val_loss: 0.5684 - val_accuracy: 0.7448\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8247 - val_loss: 0.5686 - val_accuracy: 0.7448\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8299 - val_loss: 0.5690 - val_accuracy: 0.7448\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8264 - val_loss: 0.5695 - val_accuracy: 0.7448\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8264 - val_loss: 0.5690 - val_accuracy: 0.7448\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8316 - val_loss: 0.5690 - val_accuracy: 0.7448\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8247 - val_loss: 0.5701 - val_accuracy: 0.7448\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8281 - val_loss: 0.5700 - val_accuracy: 0.7448\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8264 - val_loss: 0.5703 - val_accuracy: 0.7448\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8299 - val_loss: 0.5696 - val_accuracy: 0.7448\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8281 - val_loss: 0.5704 - val_accuracy: 0.7448\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8247 - val_loss: 0.5703 - val_accuracy: 0.7448\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8299 - val_loss: 0.5698 - val_accuracy: 0.7448\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8247 - val_loss: 0.5701 - val_accuracy: 0.7448\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8264 - val_loss: 0.5704 - val_accuracy: 0.7448\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8281 - val_loss: 0.5706 - val_accuracy: 0.7448\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8299 - val_loss: 0.5700 - val_accuracy: 0.7448\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8247 - val_loss: 0.5700 - val_accuracy: 0.7448\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8281 - val_loss: 0.5709 - val_accuracy: 0.7448\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8229 - val_loss: 0.5699 - val_accuracy: 0.7448\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8299 - val_loss: 0.5707 - val_accuracy: 0.7448\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8299 - val_loss: 0.5697 - val_accuracy: 0.7448\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3863 - accuracy: 0.8247 - val_loss: 0.5708 - val_accuracy: 0.7344\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8247 - val_loss: 0.5707 - val_accuracy: 0.7396\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8264 - val_loss: 0.5715 - val_accuracy: 0.7396\n",
      "Epoch 569/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8316 - val_loss: 0.5715 - val_accuracy: 0.7344\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8264 - val_loss: 0.5716 - val_accuracy: 0.7344\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8316 - val_loss: 0.5714 - val_accuracy: 0.7344\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8264 - val_loss: 0.5707 - val_accuracy: 0.7344\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8281 - val_loss: 0.5718 - val_accuracy: 0.7344\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3854 - accuracy: 0.8247 - val_loss: 0.5720 - val_accuracy: 0.7396\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3856 - accuracy: 0.8212 - val_loss: 0.5715 - val_accuracy: 0.7344\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8229 - val_loss: 0.5722 - val_accuracy: 0.7344\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8247 - val_loss: 0.5710 - val_accuracy: 0.7396\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8247 - val_loss: 0.5712 - val_accuracy: 0.7396\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8281 - val_loss: 0.5718 - val_accuracy: 0.7396\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8247 - val_loss: 0.5721 - val_accuracy: 0.7344\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8229 - val_loss: 0.5728 - val_accuracy: 0.7344\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8247 - val_loss: 0.5716 - val_accuracy: 0.7344\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8281 - val_loss: 0.5730 - val_accuracy: 0.7396\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8247 - val_loss: 0.5734 - val_accuracy: 0.7344\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8247 - val_loss: 0.5728 - val_accuracy: 0.7396\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8316 - val_loss: 0.5737 - val_accuracy: 0.7344\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8264 - val_loss: 0.5736 - val_accuracy: 0.7344\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8247 - val_loss: 0.5720 - val_accuracy: 0.7344\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8281 - val_loss: 0.5725 - val_accuracy: 0.7344\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8264 - val_loss: 0.5739 - val_accuracy: 0.7344\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8281 - val_loss: 0.5726 - val_accuracy: 0.7344\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8281 - val_loss: 0.5720 - val_accuracy: 0.7396\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8299 - val_loss: 0.5723 - val_accuracy: 0.7344\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8264 - val_loss: 0.5731 - val_accuracy: 0.7344\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8281 - val_loss: 0.5734 - val_accuracy: 0.7344\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8299 - val_loss: 0.5729 - val_accuracy: 0.7344\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8299 - val_loss: 0.5738 - val_accuracy: 0.7344\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8299 - val_loss: 0.5736 - val_accuracy: 0.7344\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8299 - val_loss: 0.5730 - val_accuracy: 0.7344\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8264 - val_loss: 0.5726 - val_accuracy: 0.7344\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8299 - val_loss: 0.5735 - val_accuracy: 0.7344\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3841 - accuracy: 0.8299 - val_loss: 0.5729 - val_accuracy: 0.7344\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8264 - val_loss: 0.5741 - val_accuracy: 0.7344\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8247 - val_loss: 0.5735 - val_accuracy: 0.7344\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8281 - val_loss: 0.5741 - val_accuracy: 0.7344\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8281 - val_loss: 0.5729 - val_accuracy: 0.7344\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8316 - val_loss: 0.5725 - val_accuracy: 0.7344\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8299 - val_loss: 0.5714 - val_accuracy: 0.7344\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8264 - val_loss: 0.5723 - val_accuracy: 0.7344\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8281 - val_loss: 0.5717 - val_accuracy: 0.7344\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8333 - val_loss: 0.5723 - val_accuracy: 0.7344\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8333 - val_loss: 0.5720 - val_accuracy: 0.7344\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8264 - val_loss: 0.5722 - val_accuracy: 0.7344\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8316 - val_loss: 0.5729 - val_accuracy: 0.7344\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8281 - val_loss: 0.5719 - val_accuracy: 0.7344\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8299 - val_loss: 0.5718 - val_accuracy: 0.7344\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8299 - val_loss: 0.5721 - val_accuracy: 0.7344\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8299 - val_loss: 0.5729 - val_accuracy: 0.7344\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8299 - val_loss: 0.5727 - val_accuracy: 0.7344\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8264 - val_loss: 0.5726 - val_accuracy: 0.7344\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8264 - val_loss: 0.5733 - val_accuracy: 0.7344\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8299 - val_loss: 0.5728 - val_accuracy: 0.7344\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8316 - val_loss: 0.5732 - val_accuracy: 0.7344\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8299 - val_loss: 0.5740 - val_accuracy: 0.7344\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8316 - val_loss: 0.5734 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8299 - val_loss: 0.5729 - val_accuracy: 0.7344\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8281 - val_loss: 0.5728 - val_accuracy: 0.7344\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8316 - val_loss: 0.5731 - val_accuracy: 0.7344\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8299 - val_loss: 0.5740 - val_accuracy: 0.7344\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8281 - val_loss: 0.5730 - val_accuracy: 0.7344\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8281 - val_loss: 0.5747 - val_accuracy: 0.7344\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8264 - val_loss: 0.5743 - val_accuracy: 0.7344\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8333 - val_loss: 0.5734 - val_accuracy: 0.7344\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8299 - val_loss: 0.5741 - val_accuracy: 0.7344\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8316 - val_loss: 0.5746 - val_accuracy: 0.7344\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8264 - val_loss: 0.5749 - val_accuracy: 0.7344\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8264 - val_loss: 0.5739 - val_accuracy: 0.7344\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8281 - val_loss: 0.5731 - val_accuracy: 0.7344\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8299 - val_loss: 0.5735 - val_accuracy: 0.7344\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8299 - val_loss: 0.5746 - val_accuracy: 0.7448\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8264 - val_loss: 0.5739 - val_accuracy: 0.7344\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8299 - val_loss: 0.5729 - val_accuracy: 0.7344\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8351 - val_loss: 0.5741 - val_accuracy: 0.7448\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8351 - val_loss: 0.5747 - val_accuracy: 0.7448\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8316 - val_loss: 0.5743 - val_accuracy: 0.7448\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8333 - val_loss: 0.5741 - val_accuracy: 0.7448\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8333 - val_loss: 0.5737 - val_accuracy: 0.7448\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8351 - val_loss: 0.5742 - val_accuracy: 0.7448\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8351 - val_loss: 0.5743 - val_accuracy: 0.7448\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8333 - val_loss: 0.5745 - val_accuracy: 0.7448\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8351 - val_loss: 0.5747 - val_accuracy: 0.7448\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8316 - val_loss: 0.5753 - val_accuracy: 0.7448\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8333 - val_loss: 0.5760 - val_accuracy: 0.7448\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8351 - val_loss: 0.5751 - val_accuracy: 0.7448\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8333 - val_loss: 0.5739 - val_accuracy: 0.7448\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8385 - val_loss: 0.5738 - val_accuracy: 0.7448\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8368 - val_loss: 0.5738 - val_accuracy: 0.7396\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8333 - val_loss: 0.5755 - val_accuracy: 0.7448\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8351 - val_loss: 0.5767 - val_accuracy: 0.7448\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8299 - val_loss: 0.5750 - val_accuracy: 0.7448\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8385 - val_loss: 0.5763 - val_accuracy: 0.7448\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8351 - val_loss: 0.5760 - val_accuracy: 0.7448\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8333 - val_loss: 0.5753 - val_accuracy: 0.7448\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8351 - val_loss: 0.5762 - val_accuracy: 0.7448\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8368 - val_loss: 0.5769 - val_accuracy: 0.7448\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8351 - val_loss: 0.5755 - val_accuracy: 0.7396\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3818 - accuracy: 0.8316 - val_loss: 0.5754 - val_accuracy: 0.7396\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8368 - val_loss: 0.5752 - val_accuracy: 0.7396\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8368 - val_loss: 0.5752 - val_accuracy: 0.7396\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8368 - val_loss: 0.5751 - val_accuracy: 0.7396\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8333 - val_loss: 0.5743 - val_accuracy: 0.7396\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8368 - val_loss: 0.5731 - val_accuracy: 0.7396\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8385 - val_loss: 0.5752 - val_accuracy: 0.7396\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8351 - val_loss: 0.5746 - val_accuracy: 0.7396\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8351 - val_loss: 0.5741 - val_accuracy: 0.7396\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8351 - val_loss: 0.5754 - val_accuracy: 0.7396\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8351 - val_loss: 0.5764 - val_accuracy: 0.7396\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8368 - val_loss: 0.5759 - val_accuracy: 0.7396\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8351 - val_loss: 0.5758 - val_accuracy: 0.7396\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8333 - val_loss: 0.5760 - val_accuracy: 0.7396\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8351 - val_loss: 0.5743 - val_accuracy: 0.7396\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8351 - val_loss: 0.5745 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8351 - val_loss: 0.5749 - val_accuracy: 0.7396\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8403 - val_loss: 0.5732 - val_accuracy: 0.7396\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8351 - val_loss: 0.5734 - val_accuracy: 0.7396\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8368 - val_loss: 0.5749 - val_accuracy: 0.7396\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8351 - val_loss: 0.5743 - val_accuracy: 0.7396\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3811 - accuracy: 0.8351 - val_loss: 0.5751 - val_accuracy: 0.7396\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8368 - val_loss: 0.5746 - val_accuracy: 0.7396\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8385 - val_loss: 0.5753 - val_accuracy: 0.7396\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8368 - val_loss: 0.5756 - val_accuracy: 0.7396\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8351 - val_loss: 0.5749 - val_accuracy: 0.7396\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8368 - val_loss: 0.5746 - val_accuracy: 0.7396\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8368 - val_loss: 0.5741 - val_accuracy: 0.7396\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8368 - val_loss: 0.5739 - val_accuracy: 0.7396\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8368 - val_loss: 0.5741 - val_accuracy: 0.7396\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8351 - val_loss: 0.5738 - val_accuracy: 0.7396\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8385 - val_loss: 0.5747 - val_accuracy: 0.7396\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8403 - val_loss: 0.5753 - val_accuracy: 0.7396\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8333 - val_loss: 0.5757 - val_accuracy: 0.7344\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8351 - val_loss: 0.5754 - val_accuracy: 0.7396\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3809 - accuracy: 0.8351 - val_loss: 0.5760 - val_accuracy: 0.7344\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8368 - val_loss: 0.5758 - val_accuracy: 0.7396\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8368 - val_loss: 0.5747 - val_accuracy: 0.7344\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8351 - val_loss: 0.5764 - val_accuracy: 0.7344\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8351 - val_loss: 0.5769 - val_accuracy: 0.7344\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8368 - val_loss: 0.5763 - val_accuracy: 0.7396\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8368 - val_loss: 0.5755 - val_accuracy: 0.7344\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3804 - accuracy: 0.8368 - val_loss: 0.5761 - val_accuracy: 0.7344\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8351 - val_loss: 0.5776 - val_accuracy: 0.7344\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8368 - val_loss: 0.5757 - val_accuracy: 0.7344\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8403 - val_loss: 0.5769 - val_accuracy: 0.7344\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8351 - val_loss: 0.5748 - val_accuracy: 0.7344\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8368 - val_loss: 0.5757 - val_accuracy: 0.7344\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8368 - val_loss: 0.5751 - val_accuracy: 0.7396\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8368 - val_loss: 0.5749 - val_accuracy: 0.7344\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8351 - val_loss: 0.5745 - val_accuracy: 0.7344\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8351 - val_loss: 0.5765 - val_accuracy: 0.7344\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3803 - accuracy: 0.8368 - val_loss: 0.5761 - val_accuracy: 0.7344\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8385 - val_loss: 0.5756 - val_accuracy: 0.7344\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8403 - val_loss: 0.5754 - val_accuracy: 0.7396\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8368 - val_loss: 0.5747 - val_accuracy: 0.7344\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8385 - val_loss: 0.5762 - val_accuracy: 0.7344\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8368 - val_loss: 0.5759 - val_accuracy: 0.7344\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8351 - val_loss: 0.5767 - val_accuracy: 0.7344\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8351 - val_loss: 0.5773 - val_accuracy: 0.7344\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8351 - val_loss: 0.5766 - val_accuracy: 0.7344\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8385 - val_loss: 0.5766 - val_accuracy: 0.7344\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3802 - accuracy: 0.8368 - val_loss: 0.5761 - val_accuracy: 0.7344\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8385 - val_loss: 0.5763 - val_accuracy: 0.7344\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8368 - val_loss: 0.5764 - val_accuracy: 0.7344\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8368 - val_loss: 0.5771 - val_accuracy: 0.7344\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8333 - val_loss: 0.5766 - val_accuracy: 0.7344\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8368 - val_loss: 0.5784 - val_accuracy: 0.7344\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8368 - val_loss: 0.5771 - val_accuracy: 0.7344\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8368 - val_loss: 0.5765 - val_accuracy: 0.7344\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3799 - accuracy: 0.8351 - val_loss: 0.5773 - val_accuracy: 0.7344\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8403 - val_loss: 0.5755 - val_accuracy: 0.7344\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8333 - val_loss: 0.5769 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8333 - val_loss: 0.5768 - val_accuracy: 0.7344\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8333 - val_loss: 0.5773 - val_accuracy: 0.7344\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8385 - val_loss: 0.5763 - val_accuracy: 0.7344\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8351 - val_loss: 0.5772 - val_accuracy: 0.7344\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8368 - val_loss: 0.5768 - val_accuracy: 0.7344\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8368 - val_loss: 0.5766 - val_accuracy: 0.7344\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8333 - val_loss: 0.5765 - val_accuracy: 0.7344\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8385 - val_loss: 0.5776 - val_accuracy: 0.7344\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8351 - val_loss: 0.5769 - val_accuracy: 0.7344\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.8351 - val_loss: 0.5759 - val_accuracy: 0.7344\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8368 - val_loss: 0.5767 - val_accuracy: 0.7344\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8368 - val_loss: 0.5761 - val_accuracy: 0.7344\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8333 - val_loss: 0.5766 - val_accuracy: 0.7344\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8333 - val_loss: 0.5774 - val_accuracy: 0.7344\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8385 - val_loss: 0.5778 - val_accuracy: 0.7344\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8351 - val_loss: 0.5766 - val_accuracy: 0.7344\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8333 - val_loss: 0.5783 - val_accuracy: 0.7344\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8351 - val_loss: 0.5784 - val_accuracy: 0.7344\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8351 - val_loss: 0.5789 - val_accuracy: 0.7344\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8385 - val_loss: 0.5785 - val_accuracy: 0.7344\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3794 - accuracy: 0.8351 - val_loss: 0.5772 - val_accuracy: 0.7344\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.8368 - val_loss: 0.5772 - val_accuracy: 0.7292\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8368 - val_loss: 0.5759 - val_accuracy: 0.7344\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.8385 - val_loss: 0.5773 - val_accuracy: 0.7344\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8368 - val_loss: 0.5750 - val_accuracy: 0.7344\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8368 - val_loss: 0.5763 - val_accuracy: 0.7344\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8368 - val_loss: 0.5768 - val_accuracy: 0.7344\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8351 - val_loss: 0.5752 - val_accuracy: 0.7344\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8368 - val_loss: 0.5765 - val_accuracy: 0.7344\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8368 - val_loss: 0.5760 - val_accuracy: 0.7292\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8351 - val_loss: 0.5766 - val_accuracy: 0.7292\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8368 - val_loss: 0.5755 - val_accuracy: 0.7292\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8385 - val_loss: 0.5764 - val_accuracy: 0.7292\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8351 - val_loss: 0.5777 - val_accuracy: 0.7292\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8316 - val_loss: 0.5769 - val_accuracy: 0.7292\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8351 - val_loss: 0.5758 - val_accuracy: 0.7292\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8403 - val_loss: 0.5780 - val_accuracy: 0.7292\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8351 - val_loss: 0.5779 - val_accuracy: 0.7292\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8368 - val_loss: 0.5780 - val_accuracy: 0.7292\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8368 - val_loss: 0.5770 - val_accuracy: 0.7292\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8368 - val_loss: 0.5774 - val_accuracy: 0.7292\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8368 - val_loss: 0.5770 - val_accuracy: 0.7292\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8368 - val_loss: 0.5777 - val_accuracy: 0.7292\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8385 - val_loss: 0.5769 - val_accuracy: 0.7292\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8385 - val_loss: 0.5777 - val_accuracy: 0.7292\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8368 - val_loss: 0.5784 - val_accuracy: 0.7292\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8351 - val_loss: 0.5781 - val_accuracy: 0.7292\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3794 - accuracy: 0.8368 - val_loss: 0.5774 - val_accuracy: 0.7292\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8368 - val_loss: 0.5774 - val_accuracy: 0.7292\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8351 - val_loss: 0.5786 - val_accuracy: 0.7292\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8351 - val_loss: 0.5771 - val_accuracy: 0.7292\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8385 - val_loss: 0.5770 - val_accuracy: 0.7292\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8368 - val_loss: 0.5764 - val_accuracy: 0.7292\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8368 - val_loss: 0.5759 - val_accuracy: 0.7344\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8333 - val_loss: 0.5782 - val_accuracy: 0.7292\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8368 - val_loss: 0.5796 - val_accuracy: 0.7292\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8385 - val_loss: 0.5783 - val_accuracy: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8385 - val_loss: 0.5785 - val_accuracy: 0.7292\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8351 - val_loss: 0.5781 - val_accuracy: 0.7292\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8333 - val_loss: 0.5774 - val_accuracy: 0.7292\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8333 - val_loss: 0.5780 - val_accuracy: 0.7292\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8368 - val_loss: 0.5795 - val_accuracy: 0.7292\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8385 - val_loss: 0.5774 - val_accuracy: 0.7292\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8385 - val_loss: 0.5791 - val_accuracy: 0.7292\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8351 - val_loss: 0.5777 - val_accuracy: 0.7292\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8368 - val_loss: 0.5792 - val_accuracy: 0.7292\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3787 - accuracy: 0.8385 - val_loss: 0.5775 - val_accuracy: 0.7292\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8368 - val_loss: 0.5772 - val_accuracy: 0.7292\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8368 - val_loss: 0.5792 - val_accuracy: 0.7292\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8368 - val_loss: 0.5786 - val_accuracy: 0.7292\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8368 - val_loss: 0.5797 - val_accuracy: 0.7292\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8368 - val_loss: 0.5785 - val_accuracy: 0.7292\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8368 - val_loss: 0.5790 - val_accuracy: 0.7292\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8351 - val_loss: 0.5781 - val_accuracy: 0.7344\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8385 - val_loss: 0.5778 - val_accuracy: 0.7292\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8351 - val_loss: 0.5788 - val_accuracy: 0.7292\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8368 - val_loss: 0.5800 - val_accuracy: 0.7292\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8385 - val_loss: 0.5799 - val_accuracy: 0.7292\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8385 - val_loss: 0.5781 - val_accuracy: 0.7292\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8385 - val_loss: 0.5784 - val_accuracy: 0.7292\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8385 - val_loss: 0.5785 - val_accuracy: 0.7292\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8368 - val_loss: 0.5788 - val_accuracy: 0.7292\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8385 - val_loss: 0.5797 - val_accuracy: 0.7292\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8385 - val_loss: 0.5785 - val_accuracy: 0.7292\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8351 - val_loss: 0.5779 - val_accuracy: 0.7292\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8368 - val_loss: 0.5781 - val_accuracy: 0.7344\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8368 - val_loss: 0.5790 - val_accuracy: 0.7344\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8333 - val_loss: 0.5798 - val_accuracy: 0.7292\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8368 - val_loss: 0.5784 - val_accuracy: 0.7292\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8351 - val_loss: 0.5783 - val_accuracy: 0.7344\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8333 - val_loss: 0.5782 - val_accuracy: 0.7292\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.8351 - val_loss: 0.5799 - val_accuracy: 0.7292\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8368 - val_loss: 0.5787 - val_accuracy: 0.7292\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8385 - val_loss: 0.5776 - val_accuracy: 0.7292\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8385 - val_loss: 0.5787 - val_accuracy: 0.7292\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8385 - val_loss: 0.5793 - val_accuracy: 0.7344\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8351 - val_loss: 0.5795 - val_accuracy: 0.7344\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8368 - val_loss: 0.5808 - val_accuracy: 0.7396\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8316 - val_loss: 0.5787 - val_accuracy: 0.7344\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8368 - val_loss: 0.5800 - val_accuracy: 0.7344\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8351 - val_loss: 0.5794 - val_accuracy: 0.7344\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8368 - val_loss: 0.5783 - val_accuracy: 0.7344\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8385 - val_loss: 0.5810 - val_accuracy: 0.7344\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8385 - val_loss: 0.5808 - val_accuracy: 0.7344\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8351 - val_loss: 0.5800 - val_accuracy: 0.7344\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8351 - val_loss: 0.5800 - val_accuracy: 0.7344\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8368 - val_loss: 0.5797 - val_accuracy: 0.7344\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8385 - val_loss: 0.5790 - val_accuracy: 0.7344\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8351 - val_loss: 0.5795 - val_accuracy: 0.7344\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8368 - val_loss: 0.5785 - val_accuracy: 0.7344\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8368 - val_loss: 0.5787 - val_accuracy: 0.7344\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3777 - accuracy: 0.8385 - val_loss: 0.5797 - val_accuracy: 0.7344\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8333 - val_loss: 0.5793 - val_accuracy: 0.7344\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8351 - val_loss: 0.5800 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8351 - val_loss: 0.5799 - val_accuracy: 0.7344\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8351 - val_loss: 0.5804 - val_accuracy: 0.7344\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8351 - val_loss: 0.5792 - val_accuracy: 0.7344\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8351 - val_loss: 0.5804 - val_accuracy: 0.7344\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8385 - val_loss: 0.5817 - val_accuracy: 0.7344\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8333 - val_loss: 0.5803 - val_accuracy: 0.7344\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8368 - val_loss: 0.5809 - val_accuracy: 0.7344\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8351 - val_loss: 0.5797 - val_accuracy: 0.7344\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8351 - val_loss: 0.5796 - val_accuracy: 0.7344\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8368 - val_loss: 0.5811 - val_accuracy: 0.7344\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8351 - val_loss: 0.5811 - val_accuracy: 0.7344\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8368 - val_loss: 0.5811 - val_accuracy: 0.7344\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3767 - accuracy: 0.8385 - val_loss: 0.5786 - val_accuracy: 0.7396\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8351 - val_loss: 0.5813 - val_accuracy: 0.7344\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8351 - val_loss: 0.5812 - val_accuracy: 0.7344\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8316 - val_loss: 0.5801 - val_accuracy: 0.7396\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8351 - val_loss: 0.5807 - val_accuracy: 0.7344\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8333 - val_loss: 0.5805 - val_accuracy: 0.7396\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8351 - val_loss: 0.5803 - val_accuracy: 0.7396\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8351 - val_loss: 0.5810 - val_accuracy: 0.7396\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3774 - accuracy: 0.8351 - val_loss: 0.5818 - val_accuracy: 0.7396\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8385 - val_loss: 0.5816 - val_accuracy: 0.7396\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8351 - val_loss: 0.5807 - val_accuracy: 0.7396\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3767 - accuracy: 0.8385 - val_loss: 0.5802 - val_accuracy: 0.7396\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8385 - val_loss: 0.5813 - val_accuracy: 0.7344\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8368 - val_loss: 0.5814 - val_accuracy: 0.7344\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.8368 - val_loss: 0.5811 - val_accuracy: 0.7396\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8368 - val_loss: 0.5815 - val_accuracy: 0.7396\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8368 - val_loss: 0.5823 - val_accuracy: 0.7344\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8351 - val_loss: 0.5825 - val_accuracy: 0.7344\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8351 - val_loss: 0.5811 - val_accuracy: 0.7396\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8368 - val_loss: 0.5820 - val_accuracy: 0.7396\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8368 - val_loss: 0.5807 - val_accuracy: 0.7396\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8368 - val_loss: 0.5812 - val_accuracy: 0.7396\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8351 - val_loss: 0.5819 - val_accuracy: 0.7396\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8351 - val_loss: 0.5807 - val_accuracy: 0.7396\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8351 - val_loss: 0.5808 - val_accuracy: 0.7396\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8351 - val_loss: 0.5811 - val_accuracy: 0.7396\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8368 - val_loss: 0.5811 - val_accuracy: 0.7344\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8385 - val_loss: 0.5808 - val_accuracy: 0.7396\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3767 - accuracy: 0.8351 - val_loss: 0.5815 - val_accuracy: 0.7396\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8385 - val_loss: 0.5824 - val_accuracy: 0.7396\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.8403 - val_loss: 0.5829 - val_accuracy: 0.7344\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8368 - val_loss: 0.5814 - val_accuracy: 0.7344\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8368 - val_loss: 0.5821 - val_accuracy: 0.7344\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8385 - val_loss: 0.5824 - val_accuracy: 0.7396\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.8333 - val_loss: 0.5811 - val_accuracy: 0.7344\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8385 - val_loss: 0.5830 - val_accuracy: 0.7396\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8385 - val_loss: 0.5823 - val_accuracy: 0.7344\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8333 - val_loss: 0.5817 - val_accuracy: 0.7344\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8385 - val_loss: 0.5824 - val_accuracy: 0.7344\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.8368 - val_loss: 0.5826 - val_accuracy: 0.7396\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.8351 - val_loss: 0.5829 - val_accuracy: 0.7396\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8333 - val_loss: 0.5825 - val_accuracy: 0.7396\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8385 - val_loss: 0.5838 - val_accuracy: 0.7396\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3763 - accuracy: 0.8368 - val_loss: 0.5834 - val_accuracy: 0.7396\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8351 - val_loss: 0.5822 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8368 - val_loss: 0.5822 - val_accuracy: 0.7344\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8368 - val_loss: 0.5821 - val_accuracy: 0.7344\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8351 - val_loss: 0.5812 - val_accuracy: 0.7344\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3763 - accuracy: 0.8351 - val_loss: 0.5822 - val_accuracy: 0.7344\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8351 - val_loss: 0.5814 - val_accuracy: 0.7344\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8368 - val_loss: 0.5831 - val_accuracy: 0.7344\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8385 - val_loss: 0.5822 - val_accuracy: 0.7344\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8385 - val_loss: 0.5829 - val_accuracy: 0.7344\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8351 - val_loss: 0.5827 - val_accuracy: 0.7344\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8385 - val_loss: 0.5829 - val_accuracy: 0.7344\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8385 - val_loss: 0.5826 - val_accuracy: 0.7344\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8333 - val_loss: 0.5822 - val_accuracy: 0.7344\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8368 - val_loss: 0.5815 - val_accuracy: 0.7344\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8351 - val_loss: 0.5817 - val_accuracy: 0.7344\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3757 - accuracy: 0.8403 - val_loss: 0.5831 - val_accuracy: 0.7344\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3756 - accuracy: 0.8351 - val_loss: 0.5842 - val_accuracy: 0.7344\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8351 - val_loss: 0.5825 - val_accuracy: 0.7344\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8368 - val_loss: 0.5816 - val_accuracy: 0.7344\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8368 - val_loss: 0.5824 - val_accuracy: 0.7344\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8368 - val_loss: 0.5823 - val_accuracy: 0.7344\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8368 - val_loss: 0.5834 - val_accuracy: 0.7344\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8351 - val_loss: 0.5818 - val_accuracy: 0.7344\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8403 - val_loss: 0.5819 - val_accuracy: 0.7344\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8385 - val_loss: 0.5823 - val_accuracy: 0.7344\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8316 - val_loss: 0.5822 - val_accuracy: 0.7344\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3756 - accuracy: 0.8368 - val_loss: 0.5830 - val_accuracy: 0.7344\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8351 - val_loss: 0.5828 - val_accuracy: 0.7344\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8368 - val_loss: 0.5816 - val_accuracy: 0.7344\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8368 - val_loss: 0.5826 - val_accuracy: 0.7344\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8368 - val_loss: 0.5833 - val_accuracy: 0.7344\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3760 - accuracy: 0.8351 - val_loss: 0.5832 - val_accuracy: 0.7344\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8368 - val_loss: 0.5831 - val_accuracy: 0.7344\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8351 - val_loss: 0.5825 - val_accuracy: 0.7344\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8368 - val_loss: 0.5818 - val_accuracy: 0.7344\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3755 - accuracy: 0.8368 - val_loss: 0.5823 - val_accuracy: 0.7344\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8351 - val_loss: 0.5818 - val_accuracy: 0.7344\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8351 - val_loss: 0.5822 - val_accuracy: 0.7344\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8368 - val_loss: 0.5820 - val_accuracy: 0.7344\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.8368 - val_loss: 0.5827 - val_accuracy: 0.7344\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8385 - val_loss: 0.5820 - val_accuracy: 0.7344\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8385 - val_loss: 0.5824 - val_accuracy: 0.7344\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8385 - val_loss: 0.5827 - val_accuracy: 0.7344\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3746 - accuracy: 0.8403 - val_loss: 0.5821 - val_accuracy: 0.7344\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8385 - val_loss: 0.5821 - val_accuracy: 0.7344\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8420 - val_loss: 0.5829 - val_accuracy: 0.7344\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8368 - val_loss: 0.5830 - val_accuracy: 0.7344\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8351 - val_loss: 0.5829 - val_accuracy: 0.7344\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8368 - val_loss: 0.5824 - val_accuracy: 0.7344\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8403 - val_loss: 0.5827 - val_accuracy: 0.7344\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8368 - val_loss: 0.5821 - val_accuracy: 0.7344\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8420 - val_loss: 0.5831 - val_accuracy: 0.7344\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8368 - val_loss: 0.5842 - val_accuracy: 0.7344\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8385 - val_loss: 0.5843 - val_accuracy: 0.7344\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3748 - accuracy: 0.8333 - val_loss: 0.5833 - val_accuracy: 0.7344\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8351 - val_loss: 0.5836 - val_accuracy: 0.7344\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8351 - val_loss: 0.5835 - val_accuracy: 0.7344\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8351 - val_loss: 0.5827 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8368 - val_loss: 0.5828 - val_accuracy: 0.7344\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8333 - val_loss: 0.5820 - val_accuracy: 0.7396\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8385 - val_loss: 0.5829 - val_accuracy: 0.7396\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8403 - val_loss: 0.5834 - val_accuracy: 0.7344\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8368 - val_loss: 0.5841 - val_accuracy: 0.7344\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8385 - val_loss: 0.5834 - val_accuracy: 0.7344\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8351 - val_loss: 0.5833 - val_accuracy: 0.7344\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8368 - val_loss: 0.5836 - val_accuracy: 0.7344\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8368 - val_loss: 0.5823 - val_accuracy: 0.7344\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3743 - accuracy: 0.8385 - val_loss: 0.5839 - val_accuracy: 0.7344\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8368 - val_loss: 0.5838 - val_accuracy: 0.7344\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8351 - val_loss: 0.5834 - val_accuracy: 0.7344\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8333 - val_loss: 0.5831 - val_accuracy: 0.7344\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8385 - val_loss: 0.5832 - val_accuracy: 0.7344\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8385 - val_loss: 0.5831 - val_accuracy: 0.7344\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8368 - val_loss: 0.5830 - val_accuracy: 0.7344\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3743 - accuracy: 0.8368 - val_loss: 0.5837 - val_accuracy: 0.7344\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8351 - val_loss: 0.5836 - val_accuracy: 0.7396\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8385 - val_loss: 0.5838 - val_accuracy: 0.7396\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8368 - val_loss: 0.5846 - val_accuracy: 0.7344\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8316 - val_loss: 0.5832 - val_accuracy: 0.7396\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8333 - val_loss: 0.5833 - val_accuracy: 0.7344\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8368 - val_loss: 0.5835 - val_accuracy: 0.7344\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8385 - val_loss: 0.5841 - val_accuracy: 0.7344\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8351 - val_loss: 0.5851 - val_accuracy: 0.7344\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8351 - val_loss: 0.5844 - val_accuracy: 0.7344\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8333 - val_loss: 0.5845 - val_accuracy: 0.7344\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8385 - val_loss: 0.5851 - val_accuracy: 0.7344\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8351 - val_loss: 0.5842 - val_accuracy: 0.7344\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8351 - val_loss: 0.5850 - val_accuracy: 0.7344\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8368 - val_loss: 0.5859 - val_accuracy: 0.7344\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8351 - val_loss: 0.5860 - val_accuracy: 0.7344\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8333 - val_loss: 0.5845 - val_accuracy: 0.7344\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8333 - val_loss: 0.5851 - val_accuracy: 0.7344\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8351 - val_loss: 0.5847 - val_accuracy: 0.7344\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8333 - val_loss: 0.5862 - val_accuracy: 0.7344\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8368 - val_loss: 0.5856 - val_accuracy: 0.7344\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8368 - val_loss: 0.5862 - val_accuracy: 0.7344\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8385 - val_loss: 0.5859 - val_accuracy: 0.7344\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8368 - val_loss: 0.5852 - val_accuracy: 0.7344\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8368 - val_loss: 0.5853 - val_accuracy: 0.7344\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8385 - val_loss: 0.5855 - val_accuracy: 0.7344\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8351 - val_loss: 0.5855 - val_accuracy: 0.7344\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8368 - val_loss: 0.5863 - val_accuracy: 0.7344\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8368 - val_loss: 0.5862 - val_accuracy: 0.7344\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8368 - val_loss: 0.5858 - val_accuracy: 0.7344\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8351 - val_loss: 0.5858 - val_accuracy: 0.7344\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8368 - val_loss: 0.5859 - val_accuracy: 0.7344\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8368 - val_loss: 0.5867 - val_accuracy: 0.7344\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8368 - val_loss: 0.5877 - val_accuracy: 0.7344\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8368 - val_loss: 0.5872 - val_accuracy: 0.7344\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3735 - accuracy: 0.8333 - val_loss: 0.5870 - val_accuracy: 0.7344\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8351 - val_loss: 0.5877 - val_accuracy: 0.7344\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2838 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8368 - val_loss: 0.5875 - val_accuracy: 0.7344\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8333 - val_loss: 0.5873 - val_accuracy: 0.7344\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8368 - val_loss: 0.5876 - val_accuracy: 0.7344\n",
      "Epoch 1024/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8351 - val_loss: 0.5875 - val_accuracy: 0.7344\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8351 - val_loss: 0.5882 - val_accuracy: 0.7344\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8368 - val_loss: 0.5872 - val_accuracy: 0.7344\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8368 - val_loss: 0.5886 - val_accuracy: 0.7344\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8368 - val_loss: 0.5877 - val_accuracy: 0.7344\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8333 - val_loss: 0.5877 - val_accuracy: 0.7344\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8403 - val_loss: 0.5891 - val_accuracy: 0.7344\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8333 - val_loss: 0.5895 - val_accuracy: 0.7344\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8368 - val_loss: 0.5881 - val_accuracy: 0.7344\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8333 - val_loss: 0.5881 - val_accuracy: 0.7344\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3731 - accuracy: 0.8368 - val_loss: 0.5891 - val_accuracy: 0.7344\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8368 - val_loss: 0.5883 - val_accuracy: 0.7344\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8368 - val_loss: 0.5888 - val_accuracy: 0.7344\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3729 - accuracy: 0.8333 - val_loss: 0.5901 - val_accuracy: 0.7344\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3730 - accuracy: 0.8351 - val_loss: 0.5886 - val_accuracy: 0.7344\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8385 - val_loss: 0.5896 - val_accuracy: 0.7344\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8351 - val_loss: 0.5894 - val_accuracy: 0.7396\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8385 - val_loss: 0.5901 - val_accuracy: 0.7344\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8403 - val_loss: 0.5908 - val_accuracy: 0.7344\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8368 - val_loss: 0.5899 - val_accuracy: 0.7344\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3726 - accuracy: 0.8385 - val_loss: 0.5900 - val_accuracy: 0.7344\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8368 - val_loss: 0.5907 - val_accuracy: 0.7344\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8333 - val_loss: 0.5895 - val_accuracy: 0.7344\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8368 - val_loss: 0.5902 - val_accuracy: 0.7344\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8368 - val_loss: 0.5909 - val_accuracy: 0.7344\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.8333 - val_loss: 0.5899 - val_accuracy: 0.7344\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8333 - val_loss: 0.5903 - val_accuracy: 0.7344\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8368 - val_loss: 0.5901 - val_accuracy: 0.7344\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8385 - val_loss: 0.5907 - val_accuracy: 0.7344\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.8368 - val_loss: 0.5899 - val_accuracy: 0.7344\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8351 - val_loss: 0.5901 - val_accuracy: 0.7344\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8385 - val_loss: 0.5897 - val_accuracy: 0.7344\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8351 - val_loss: 0.5903 - val_accuracy: 0.7344\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8351 - val_loss: 0.5897 - val_accuracy: 0.7344\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8368 - val_loss: 0.5904 - val_accuracy: 0.7344\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8351 - val_loss: 0.5902 - val_accuracy: 0.7344\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8368 - val_loss: 0.5900 - val_accuracy: 0.7344\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8385 - val_loss: 0.5906 - val_accuracy: 0.7344\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8333 - val_loss: 0.5907 - val_accuracy: 0.7344\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8368 - val_loss: 0.5909 - val_accuracy: 0.7344\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8385 - val_loss: 0.5916 - val_accuracy: 0.7344\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8351 - val_loss: 0.5912 - val_accuracy: 0.7344\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8368 - val_loss: 0.5909 - val_accuracy: 0.7344\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8351 - val_loss: 0.5917 - val_accuracy: 0.7344\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8351 - val_loss: 0.5918 - val_accuracy: 0.7344\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8368 - val_loss: 0.5908 - val_accuracy: 0.7344\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8368 - val_loss: 0.5909 - val_accuracy: 0.7344\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8351 - val_loss: 0.5917 - val_accuracy: 0.7344\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8368 - val_loss: 0.5925 - val_accuracy: 0.7344\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8351 - val_loss: 0.5924 - val_accuracy: 0.7344\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8351 - val_loss: 0.5920 - val_accuracy: 0.7344\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8385 - val_loss: 0.5922 - val_accuracy: 0.7344\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8368 - val_loss: 0.5928 - val_accuracy: 0.7344\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8351 - val_loss: 0.5935 - val_accuracy: 0.7344\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8351 - val_loss: 0.5945 - val_accuracy: 0.7344\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8351 - val_loss: 0.5936 - val_accuracy: 0.7344\n",
      "Epoch 1080/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8351 - val_loss: 0.5923 - val_accuracy: 0.7344\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8368 - val_loss: 0.5930 - val_accuracy: 0.7344\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8351 - val_loss: 0.5922 - val_accuracy: 0.7344\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8368 - val_loss: 0.5939 - val_accuracy: 0.7344\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8351 - val_loss: 0.5923 - val_accuracy: 0.7344\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8368 - val_loss: 0.5926 - val_accuracy: 0.7344\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8351 - val_loss: 0.5932 - val_accuracy: 0.7344\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8368 - val_loss: 0.5929 - val_accuracy: 0.7344\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8351 - val_loss: 0.5939 - val_accuracy: 0.7344\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8351 - val_loss: 0.5923 - val_accuracy: 0.7344\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8368 - val_loss: 0.5929 - val_accuracy: 0.7344\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8351 - val_loss: 0.5918 - val_accuracy: 0.7344\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8351 - val_loss: 0.5917 - val_accuracy: 0.7344\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8368 - val_loss: 0.5931 - val_accuracy: 0.7344\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8368 - val_loss: 0.5940 - val_accuracy: 0.7344\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8351 - val_loss: 0.5944 - val_accuracy: 0.7344\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8385 - val_loss: 0.5941 - val_accuracy: 0.7344\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8351 - val_loss: 0.5931 - val_accuracy: 0.7344\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8351 - val_loss: 0.5926 - val_accuracy: 0.7344\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8368 - val_loss: 0.5936 - val_accuracy: 0.7344\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8368 - val_loss: 0.5948 - val_accuracy: 0.7344\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8368 - val_loss: 0.5953 - val_accuracy: 0.7344\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8368 - val_loss: 0.5947 - val_accuracy: 0.7344\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8333 - val_loss: 0.5945 - val_accuracy: 0.7344\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8368 - val_loss: 0.5944 - val_accuracy: 0.7344\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8368 - val_loss: 0.5942 - val_accuracy: 0.7344\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8351 - val_loss: 0.5948 - val_accuracy: 0.7344\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8333 - val_loss: 0.5958 - val_accuracy: 0.7344\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8385 - val_loss: 0.5978 - val_accuracy: 0.7344\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8368 - val_loss: 0.5976 - val_accuracy: 0.7344\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8333 - val_loss: 0.5953 - val_accuracy: 0.7344\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8351 - val_loss: 0.5954 - val_accuracy: 0.7344\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8368 - val_loss: 0.5951 - val_accuracy: 0.7344\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8351 - val_loss: 0.5953 - val_accuracy: 0.7344\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8333 - val_loss: 0.5957 - val_accuracy: 0.7344\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8351 - val_loss: 0.5958 - val_accuracy: 0.7344\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8351 - val_loss: 0.5965 - val_accuracy: 0.7344\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8316 - val_loss: 0.5939 - val_accuracy: 0.7344\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8351 - val_loss: 0.5944 - val_accuracy: 0.7344\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8368 - val_loss: 0.5945 - val_accuracy: 0.7344\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.8368 - val_loss: 0.5962 - val_accuracy: 0.7344\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8351 - val_loss: 0.5966 - val_accuracy: 0.7344\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8351 - val_loss: 0.5963 - val_accuracy: 0.7344\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8333 - val_loss: 0.5973 - val_accuracy: 0.7344\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8368 - val_loss: 0.5966 - val_accuracy: 0.7344\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8368 - val_loss: 0.5962 - val_accuracy: 0.7344\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8368 - val_loss: 0.5972 - val_accuracy: 0.7344\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3701 - accuracy: 0.8368 - val_loss: 0.5962 - val_accuracy: 0.7344\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.8368 - val_loss: 0.5981 - val_accuracy: 0.7344\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8368 - val_loss: 0.5956 - val_accuracy: 0.7344\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8368 - val_loss: 0.5957 - val_accuracy: 0.7344\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8385 - val_loss: 0.5971 - val_accuracy: 0.7344\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8351 - val_loss: 0.5965 - val_accuracy: 0.7344\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3697 - accuracy: 0.8385 - val_loss: 0.5977 - val_accuracy: 0.7344\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8368 - val_loss: 0.5973 - val_accuracy: 0.7344\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8368 - val_loss: 0.5978 - val_accuracy: 0.7344\n",
      "Epoch 1136/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8385 - val_loss: 0.5971 - val_accuracy: 0.7344\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8368 - val_loss: 0.5966 - val_accuracy: 0.7344\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8385 - val_loss: 0.5959 - val_accuracy: 0.7344\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8351 - val_loss: 0.5971 - val_accuracy: 0.7344\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8351 - val_loss: 0.5977 - val_accuracy: 0.7344\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8351 - val_loss: 0.5989 - val_accuracy: 0.7344\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8351 - val_loss: 0.5986 - val_accuracy: 0.7344\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8368 - val_loss: 0.5984 - val_accuracy: 0.7344\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8403 - val_loss: 0.5965 - val_accuracy: 0.7344\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8368 - val_loss: 0.5967 - val_accuracy: 0.7344\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8351 - val_loss: 0.5974 - val_accuracy: 0.7344\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3699 - accuracy: 0.8385 - val_loss: 0.5987 - val_accuracy: 0.7344\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8333 - val_loss: 0.6000 - val_accuracy: 0.7344\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8368 - val_loss: 0.5988 - val_accuracy: 0.7344\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8368 - val_loss: 0.6010 - val_accuracy: 0.7344\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8368 - val_loss: 0.6002 - val_accuracy: 0.7344\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8351 - val_loss: 0.5996 - val_accuracy: 0.7344\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8385 - val_loss: 0.5990 - val_accuracy: 0.7344\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8385 - val_loss: 0.5988 - val_accuracy: 0.7344\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8368 - val_loss: 0.5989 - val_accuracy: 0.7344\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8368 - val_loss: 0.5980 - val_accuracy: 0.7344\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8403 - val_loss: 0.5981 - val_accuracy: 0.7344\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8420 - val_loss: 0.6000 - val_accuracy: 0.7344\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8385 - val_loss: 0.5998 - val_accuracy: 0.7344\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8368 - val_loss: 0.6015 - val_accuracy: 0.7344\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8403 - val_loss: 0.6004 - val_accuracy: 0.7344\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8403 - val_loss: 0.5997 - val_accuracy: 0.7344\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8385 - val_loss: 0.6000 - val_accuracy: 0.7344\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8403 - val_loss: 0.5995 - val_accuracy: 0.7344\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3698 - accuracy: 0.8385 - val_loss: 0.6014 - val_accuracy: 0.7344\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8403 - val_loss: 0.6010 - val_accuracy: 0.7344\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8385 - val_loss: 0.6011 - val_accuracy: 0.7344\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8403 - val_loss: 0.6004 - val_accuracy: 0.7344\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.8385 - val_loss: 0.6011 - val_accuracy: 0.7344\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8403 - val_loss: 0.6008 - val_accuracy: 0.7344\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8385 - val_loss: 0.6000 - val_accuracy: 0.7344\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8385 - val_loss: 0.6013 - val_accuracy: 0.7344\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8385 - val_loss: 0.6013 - val_accuracy: 0.7344\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8385 - val_loss: 0.6006 - val_accuracy: 0.7344\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8403 - val_loss: 0.6022 - val_accuracy: 0.7344\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8403 - val_loss: 0.6017 - val_accuracy: 0.7396\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8420 - val_loss: 0.6013 - val_accuracy: 0.7396\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8420 - val_loss: 0.6019 - val_accuracy: 0.7396\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8403 - val_loss: 0.6015 - val_accuracy: 0.7396\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8403 - val_loss: 0.6019 - val_accuracy: 0.7396\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8420 - val_loss: 0.6018 - val_accuracy: 0.7344\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8403 - val_loss: 0.6036 - val_accuracy: 0.7344\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8420 - val_loss: 0.6028 - val_accuracy: 0.7396\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8420 - val_loss: 0.6023 - val_accuracy: 0.7396\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8403 - val_loss: 0.6037 - val_accuracy: 0.7344\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3688 - accuracy: 0.8403 - val_loss: 0.6038 - val_accuracy: 0.7292\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8438 - val_loss: 0.6015 - val_accuracy: 0.7396\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8368 - val_loss: 0.6029 - val_accuracy: 0.7344\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3688 - accuracy: 0.8420 - val_loss: 0.6032 - val_accuracy: 0.7344\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8438 - val_loss: 0.6019 - val_accuracy: 0.7396\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8420 - val_loss: 0.6019 - val_accuracy: 0.7396\n",
      "Epoch 1192/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8385 - val_loss: 0.6044 - val_accuracy: 0.7344\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8438 - val_loss: 0.6034 - val_accuracy: 0.7344\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8438 - val_loss: 0.6020 - val_accuracy: 0.7396\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8385 - val_loss: 0.6022 - val_accuracy: 0.7396\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3684 - accuracy: 0.8403 - val_loss: 0.6020 - val_accuracy: 0.7396\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8385 - val_loss: 0.6012 - val_accuracy: 0.7396\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8368 - val_loss: 0.6022 - val_accuracy: 0.7344\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8420 - val_loss: 0.6011 - val_accuracy: 0.7344\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.8403 - val_loss: 0.6027 - val_accuracy: 0.7344\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8455 - val_loss: 0.6027 - val_accuracy: 0.7292\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.8420 - val_loss: 0.6027 - val_accuracy: 0.7344\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8403 - val_loss: 0.6022 - val_accuracy: 0.7344\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8420 - val_loss: 0.6020 - val_accuracy: 0.7344\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8403 - val_loss: 0.6016 - val_accuracy: 0.7396\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8420 - val_loss: 0.6029 - val_accuracy: 0.7344\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8403 - val_loss: 0.6045 - val_accuracy: 0.7344\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.8438 - val_loss: 0.6037 - val_accuracy: 0.7344\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3675 - accuracy: 0.8455 - val_loss: 0.6023 - val_accuracy: 0.7396\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8438 - val_loss: 0.6018 - val_accuracy: 0.7396\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8385 - val_loss: 0.6025 - val_accuracy: 0.7344\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8420 - val_loss: 0.6025 - val_accuracy: 0.7344\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8420 - val_loss: 0.6017 - val_accuracy: 0.7448\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8403 - val_loss: 0.6025 - val_accuracy: 0.7396\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3673 - accuracy: 0.8420 - val_loss: 0.6032 - val_accuracy: 0.7396\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8420 - val_loss: 0.6043 - val_accuracy: 0.7396\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8403 - val_loss: 0.6028 - val_accuracy: 0.7396\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8420 - val_loss: 0.6026 - val_accuracy: 0.7396\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8403 - val_loss: 0.6025 - val_accuracy: 0.7344\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8438 - val_loss: 0.6023 - val_accuracy: 0.7344\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8403 - val_loss: 0.6020 - val_accuracy: 0.7344\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8438 - val_loss: 0.6024 - val_accuracy: 0.7396\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8420 - val_loss: 0.6021 - val_accuracy: 0.7396\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8455 - val_loss: 0.6027 - val_accuracy: 0.7344\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3663 - accuracy: 0.8403 - val_loss: 0.6028 - val_accuracy: 0.7396\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8403 - val_loss: 0.6031 - val_accuracy: 0.7448\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8472 - val_loss: 0.6011 - val_accuracy: 0.7396\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8420 - val_loss: 0.6016 - val_accuracy: 0.7448\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8385 - val_loss: 0.6035 - val_accuracy: 0.7396\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8472 - val_loss: 0.6017 - val_accuracy: 0.7396\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8455 - val_loss: 0.6016 - val_accuracy: 0.7396\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8403 - val_loss: 0.6021 - val_accuracy: 0.7448\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8420 - val_loss: 0.6038 - val_accuracy: 0.7396\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8420 - val_loss: 0.6037 - val_accuracy: 0.7396\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8455 - val_loss: 0.6030 - val_accuracy: 0.7396\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8472 - val_loss: 0.6027 - val_accuracy: 0.7448\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8438 - val_loss: 0.6029 - val_accuracy: 0.7396\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8438 - val_loss: 0.6033 - val_accuracy: 0.7396\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8490 - val_loss: 0.6032 - val_accuracy: 0.7396\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3653 - accuracy: 0.8438 - val_loss: 0.6027 - val_accuracy: 0.7396\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8438 - val_loss: 0.6042 - val_accuracy: 0.7396\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8455 - val_loss: 0.6035 - val_accuracy: 0.7396\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8438 - val_loss: 0.6036 - val_accuracy: 0.7396\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3650 - accuracy: 0.8455 - val_loss: 0.6042 - val_accuracy: 0.7396\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3655 - accuracy: 0.8438 - val_loss: 0.6041 - val_accuracy: 0.7396\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8420 - val_loss: 0.6037 - val_accuracy: 0.7396\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8438 - val_loss: 0.6043 - val_accuracy: 0.7396\n",
      "Epoch 1248/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3650 - accuracy: 0.8455 - val_loss: 0.6052 - val_accuracy: 0.7396\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3647 - accuracy: 0.8438 - val_loss: 0.6045 - val_accuracy: 0.7396\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8438 - val_loss: 0.6049 - val_accuracy: 0.7396\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8490 - val_loss: 0.6032 - val_accuracy: 0.7396\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8420 - val_loss: 0.6043 - val_accuracy: 0.7396\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8490 - val_loss: 0.6035 - val_accuracy: 0.7396\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8420 - val_loss: 0.6046 - val_accuracy: 0.7396\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8455 - val_loss: 0.6053 - val_accuracy: 0.7396\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3642 - accuracy: 0.8438 - val_loss: 0.6054 - val_accuracy: 0.7396\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8438 - val_loss: 0.6056 - val_accuracy: 0.7396\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8455 - val_loss: 0.6060 - val_accuracy: 0.7396\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8420 - val_loss: 0.6063 - val_accuracy: 0.7396\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8420 - val_loss: 0.6053 - val_accuracy: 0.7396\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8438 - val_loss: 0.6061 - val_accuracy: 0.7396\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8438 - val_loss: 0.6054 - val_accuracy: 0.7396\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8472 - val_loss: 0.6052 - val_accuracy: 0.7396\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8438 - val_loss: 0.6064 - val_accuracy: 0.7396\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8472 - val_loss: 0.6048 - val_accuracy: 0.7396\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8472 - val_loss: 0.6058 - val_accuracy: 0.7396\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8455 - val_loss: 0.6079 - val_accuracy: 0.7448\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8490 - val_loss: 0.6067 - val_accuracy: 0.7396\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8472 - val_loss: 0.6065 - val_accuracy: 0.7448\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8472 - val_loss: 0.6062 - val_accuracy: 0.7448\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8455 - val_loss: 0.6071 - val_accuracy: 0.7448\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8455 - val_loss: 0.6081 - val_accuracy: 0.7448\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8490 - val_loss: 0.6077 - val_accuracy: 0.7448\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8490 - val_loss: 0.6077 - val_accuracy: 0.7396\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8472 - val_loss: 0.6084 - val_accuracy: 0.7396\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8472 - val_loss: 0.6082 - val_accuracy: 0.7396\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8490 - val_loss: 0.6072 - val_accuracy: 0.7396\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8490 - val_loss: 0.6069 - val_accuracy: 0.7396\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8472 - val_loss: 0.6087 - val_accuracy: 0.7448\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8472 - val_loss: 0.6070 - val_accuracy: 0.7448\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8490 - val_loss: 0.6090 - val_accuracy: 0.7448\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8472 - val_loss: 0.6083 - val_accuracy: 0.7448\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3615 - accuracy: 0.8490 - val_loss: 0.6090 - val_accuracy: 0.7448\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8490 - val_loss: 0.6084 - val_accuracy: 0.7448\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8472 - val_loss: 0.6087 - val_accuracy: 0.7448\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8490 - val_loss: 0.6074 - val_accuracy: 0.7448\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8507 - val_loss: 0.6102 - val_accuracy: 0.7448\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8472 - val_loss: 0.6100 - val_accuracy: 0.7448\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8472 - val_loss: 0.6090 - val_accuracy: 0.7448\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8490 - val_loss: 0.6094 - val_accuracy: 0.7448\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8490 - val_loss: 0.6107 - val_accuracy: 0.7448\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8490 - val_loss: 0.6112 - val_accuracy: 0.7448\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8472 - val_loss: 0.6116 - val_accuracy: 0.7448\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8507 - val_loss: 0.6116 - val_accuracy: 0.7448\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8490 - val_loss: 0.6107 - val_accuracy: 0.7448\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8507 - val_loss: 0.6100 - val_accuracy: 0.7448\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8490 - val_loss: 0.6091 - val_accuracy: 0.7448\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8490 - val_loss: 0.6086 - val_accuracy: 0.7448\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8490 - val_loss: 0.6091 - val_accuracy: 0.7448\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8472 - val_loss: 0.6106 - val_accuracy: 0.7448\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8490 - val_loss: 0.6101 - val_accuracy: 0.7448\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8490 - val_loss: 0.6136 - val_accuracy: 0.7448\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.8472 - val_loss: 0.6145 - val_accuracy: 0.7448\n",
      "Epoch 1304/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8507 - val_loss: 0.6126 - val_accuracy: 0.7448\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8490 - val_loss: 0.6125 - val_accuracy: 0.7448\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8507 - val_loss: 0.6150 - val_accuracy: 0.7448\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8507 - val_loss: 0.6145 - val_accuracy: 0.7448\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8507 - val_loss: 0.6119 - val_accuracy: 0.7448\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8507 - val_loss: 0.6121 - val_accuracy: 0.7448\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8507 - val_loss: 0.6130 - val_accuracy: 0.7448\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8524 - val_loss: 0.6111 - val_accuracy: 0.7448\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8507 - val_loss: 0.6130 - val_accuracy: 0.7448\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8524 - val_loss: 0.6125 - val_accuracy: 0.7448\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8507 - val_loss: 0.6120 - val_accuracy: 0.7448\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8507 - val_loss: 0.6122 - val_accuracy: 0.7448\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8507 - val_loss: 0.6128 - val_accuracy: 0.7448\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8507 - val_loss: 0.6130 - val_accuracy: 0.7448\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8507 - val_loss: 0.6135 - val_accuracy: 0.7448\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8524 - val_loss: 0.6142 - val_accuracy: 0.7448\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8507 - val_loss: 0.6156 - val_accuracy: 0.7448\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8542 - val_loss: 0.6138 - val_accuracy: 0.7448\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8524 - val_loss: 0.6137 - val_accuracy: 0.7448\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8507 - val_loss: 0.6161 - val_accuracy: 0.7448\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8507 - val_loss: 0.6161 - val_accuracy: 0.7448\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8524 - val_loss: 0.6162 - val_accuracy: 0.7448\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8507 - val_loss: 0.6164 - val_accuracy: 0.7448\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3595 - accuracy: 0.8542 - val_loss: 0.6158 - val_accuracy: 0.7448\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8507 - val_loss: 0.6151 - val_accuracy: 0.7448\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8542 - val_loss: 0.6157 - val_accuracy: 0.7448\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8524 - val_loss: 0.6143 - val_accuracy: 0.7448\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8524 - val_loss: 0.6162 - val_accuracy: 0.7448\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8524 - val_loss: 0.6150 - val_accuracy: 0.7448\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8507 - val_loss: 0.6156 - val_accuracy: 0.7448\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8542 - val_loss: 0.6157 - val_accuracy: 0.7448\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8524 - val_loss: 0.6160 - val_accuracy: 0.7448\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8542 - val_loss: 0.6176 - val_accuracy: 0.7448\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8524 - val_loss: 0.6148 - val_accuracy: 0.7448\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8542 - val_loss: 0.6162 - val_accuracy: 0.7448\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8559 - val_loss: 0.6150 - val_accuracy: 0.7448\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8542 - val_loss: 0.6161 - val_accuracy: 0.7448\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8542 - val_loss: 0.6155 - val_accuracy: 0.7448\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3589 - accuracy: 0.8542 - val_loss: 0.6164 - val_accuracy: 0.7448\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8524 - val_loss: 0.6159 - val_accuracy: 0.7448\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8524 - val_loss: 0.6157 - val_accuracy: 0.7448\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8524 - val_loss: 0.6189 - val_accuracy: 0.7448\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8524 - val_loss: 0.6186 - val_accuracy: 0.7448\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8559 - val_loss: 0.6153 - val_accuracy: 0.7448\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8507 - val_loss: 0.6177 - val_accuracy: 0.7448\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8507 - val_loss: 0.6161 - val_accuracy: 0.7448\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8524 - val_loss: 0.6176 - val_accuracy: 0.7448\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8524 - val_loss: 0.6175 - val_accuracy: 0.7448\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8524 - val_loss: 0.6182 - val_accuracy: 0.7448\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8542 - val_loss: 0.6175 - val_accuracy: 0.7448\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8524 - val_loss: 0.6174 - val_accuracy: 0.7448\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8524 - val_loss: 0.6190 - val_accuracy: 0.7448\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.8559 - val_loss: 0.6172 - val_accuracy: 0.7448\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8507 - val_loss: 0.6186 - val_accuracy: 0.7448\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8542 - val_loss: 0.6175 - val_accuracy: 0.7448\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8524 - val_loss: 0.6174 - val_accuracy: 0.7448\n",
      "Epoch 1360/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8524 - val_loss: 0.6172 - val_accuracy: 0.7448\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.8524 - val_loss: 0.6193 - val_accuracy: 0.7448\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8524 - val_loss: 0.6199 - val_accuracy: 0.7448\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8524 - val_loss: 0.6159 - val_accuracy: 0.7448\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8524 - val_loss: 0.6188 - val_accuracy: 0.7448\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8524 - val_loss: 0.6204 - val_accuracy: 0.7448\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8507 - val_loss: 0.6205 - val_accuracy: 0.7448\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8507 - val_loss: 0.6185 - val_accuracy: 0.7448\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8524 - val_loss: 0.6194 - val_accuracy: 0.7448\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8542 - val_loss: 0.6191 - val_accuracy: 0.7448\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8524 - val_loss: 0.6200 - val_accuracy: 0.7448\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8524 - val_loss: 0.6212 - val_accuracy: 0.7448\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8524 - val_loss: 0.6210 - val_accuracy: 0.7448\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8524 - val_loss: 0.6189 - val_accuracy: 0.7448\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8507 - val_loss: 0.6207 - val_accuracy: 0.7448\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8507 - val_loss: 0.6211 - val_accuracy: 0.7448\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8524 - val_loss: 0.6202 - val_accuracy: 0.7448\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8524 - val_loss: 0.6215 - val_accuracy: 0.7448\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8524 - val_loss: 0.6228 - val_accuracy: 0.7448\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8507 - val_loss: 0.6210 - val_accuracy: 0.7448\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8524 - val_loss: 0.6204 - val_accuracy: 0.7448\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8524 - val_loss: 0.6236 - val_accuracy: 0.7448\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8507 - val_loss: 0.6234 - val_accuracy: 0.7448\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8524 - val_loss: 0.6240 - val_accuracy: 0.7448\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8507 - val_loss: 0.6253 - val_accuracy: 0.7448\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8524 - val_loss: 0.6253 - val_accuracy: 0.7448\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8507 - val_loss: 0.6239 - val_accuracy: 0.7448\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8524 - val_loss: 0.6237 - val_accuracy: 0.7448\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8524 - val_loss: 0.6226 - val_accuracy: 0.7396\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8524 - val_loss: 0.6234 - val_accuracy: 0.7448\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8524 - val_loss: 0.6232 - val_accuracy: 0.7448\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3568 - accuracy: 0.8507 - val_loss: 0.6228 - val_accuracy: 0.7448\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8524 - val_loss: 0.6244 - val_accuracy: 0.7448\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8524 - val_loss: 0.6228 - val_accuracy: 0.7344\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8524 - val_loss: 0.6223 - val_accuracy: 0.7344\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8507 - val_loss: 0.6235 - val_accuracy: 0.7396\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8524 - val_loss: 0.6215 - val_accuracy: 0.7344\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8507 - val_loss: 0.6208 - val_accuracy: 0.7344\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8524 - val_loss: 0.6231 - val_accuracy: 0.7344\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8507 - val_loss: 0.6209 - val_accuracy: 0.7344\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8490 - val_loss: 0.6225 - val_accuracy: 0.7344\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8507 - val_loss: 0.6226 - val_accuracy: 0.7344\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8490 - val_loss: 0.6233 - val_accuracy: 0.7344\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8490 - val_loss: 0.6222 - val_accuracy: 0.7344\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8507 - val_loss: 0.6229 - val_accuracy: 0.7344\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8524 - val_loss: 0.6225 - val_accuracy: 0.7344\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8542 - val_loss: 0.6238 - val_accuracy: 0.7344\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8490 - val_loss: 0.6244 - val_accuracy: 0.7344\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8490 - val_loss: 0.6249 - val_accuracy: 0.7344\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8490 - val_loss: 0.6246 - val_accuracy: 0.7344\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8490 - val_loss: 0.6245 - val_accuracy: 0.7344\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.8490 - val_loss: 0.6250 - val_accuracy: 0.7344\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8490 - val_loss: 0.6254 - val_accuracy: 0.7344\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8490 - val_loss: 0.6254 - val_accuracy: 0.7344\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3555 - accuracy: 0.8490 - val_loss: 0.6229 - val_accuracy: 0.7344\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8490 - val_loss: 0.6222 - val_accuracy: 0.7344\n",
      "Epoch 1416/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8490 - val_loss: 0.6242 - val_accuracy: 0.7344\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8542 - val_loss: 0.6262 - val_accuracy: 0.7292\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8507 - val_loss: 0.6256 - val_accuracy: 0.7344\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8490 - val_loss: 0.6240 - val_accuracy: 0.7344\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8490 - val_loss: 0.6250 - val_accuracy: 0.7344\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8524 - val_loss: 0.6229 - val_accuracy: 0.7292\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8490 - val_loss: 0.6237 - val_accuracy: 0.7292\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8507 - val_loss: 0.6249 - val_accuracy: 0.7344\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.8490 - val_loss: 0.6233 - val_accuracy: 0.7344\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8490 - val_loss: 0.6229 - val_accuracy: 0.7292\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8507 - val_loss: 0.6234 - val_accuracy: 0.7292\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8507 - val_loss: 0.6240 - val_accuracy: 0.7344\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8507 - val_loss: 0.6236 - val_accuracy: 0.7292\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8507 - val_loss: 0.6245 - val_accuracy: 0.7292\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8490 - val_loss: 0.6233 - val_accuracy: 0.7292\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8490 - val_loss: 0.6219 - val_accuracy: 0.7292\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8507 - val_loss: 0.6235 - val_accuracy: 0.7292\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8507 - val_loss: 0.6242 - val_accuracy: 0.7292\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8490 - val_loss: 0.6235 - val_accuracy: 0.7292\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8490 - val_loss: 0.6247 - val_accuracy: 0.7292\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8524 - val_loss: 0.6244 - val_accuracy: 0.7292\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8507 - val_loss: 0.6242 - val_accuracy: 0.7292\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8507 - val_loss: 0.6266 - val_accuracy: 0.7292\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8472 - val_loss: 0.6252 - val_accuracy: 0.7292\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8507 - val_loss: 0.6247 - val_accuracy: 0.7292\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8524 - val_loss: 0.6243 - val_accuracy: 0.7292\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8490 - val_loss: 0.6244 - val_accuracy: 0.7292\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8524 - val_loss: 0.6243 - val_accuracy: 0.7292\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8490 - val_loss: 0.6253 - val_accuracy: 0.7292\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8507 - val_loss: 0.6237 - val_accuracy: 0.7292\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3543 - accuracy: 0.8524 - val_loss: 0.6248 - val_accuracy: 0.7292\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8507 - val_loss: 0.6235 - val_accuracy: 0.7292\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8507 - val_loss: 0.6238 - val_accuracy: 0.7292\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8507 - val_loss: 0.6228 - val_accuracy: 0.7292\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8490 - val_loss: 0.6237 - val_accuracy: 0.7292\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8524 - val_loss: 0.6226 - val_accuracy: 0.7292\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8490 - val_loss: 0.6249 - val_accuracy: 0.7292\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8490 - val_loss: 0.6242 - val_accuracy: 0.7292\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8507 - val_loss: 0.6227 - val_accuracy: 0.7292\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8490 - val_loss: 0.6263 - val_accuracy: 0.7292\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8524 - val_loss: 0.6261 - val_accuracy: 0.7292\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8490 - val_loss: 0.6258 - val_accuracy: 0.7292\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8507 - val_loss: 0.6268 - val_accuracy: 0.7292\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8524 - val_loss: 0.6273 - val_accuracy: 0.7292\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8490 - val_loss: 0.6269 - val_accuracy: 0.7292\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8507 - val_loss: 0.6261 - val_accuracy: 0.7292\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8490 - val_loss: 0.6263 - val_accuracy: 0.7292\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8490 - val_loss: 0.6280 - val_accuracy: 0.7292\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8507 - val_loss: 0.6279 - val_accuracy: 0.7292\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8490 - val_loss: 0.6274 - val_accuracy: 0.7292\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8472 - val_loss: 0.6301 - val_accuracy: 0.7240\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.8542 - val_loss: 0.6284 - val_accuracy: 0.7292\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3538 - accuracy: 0.8490 - val_loss: 0.6292 - val_accuracy: 0.7292\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.8507 - val_loss: 0.6300 - val_accuracy: 0.7292\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8507 - val_loss: 0.6275 - val_accuracy: 0.7292\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.8490 - val_loss: 0.6289 - val_accuracy: 0.7240\n",
      "Epoch 1472/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8524 - val_loss: 0.6283 - val_accuracy: 0.7292\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8507 - val_loss: 0.6301 - val_accuracy: 0.7292\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8507 - val_loss: 0.6295 - val_accuracy: 0.7292\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8490 - val_loss: 0.6285 - val_accuracy: 0.7292\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8524 - val_loss: 0.6272 - val_accuracy: 0.7292\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8490 - val_loss: 0.6289 - val_accuracy: 0.7292\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8507 - val_loss: 0.6289 - val_accuracy: 0.7292\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8490 - val_loss: 0.6292 - val_accuracy: 0.7292\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8524 - val_loss: 0.6278 - val_accuracy: 0.7292\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8490 - val_loss: 0.6318 - val_accuracy: 0.7292\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8507 - val_loss: 0.6330 - val_accuracy: 0.7292\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8507 - val_loss: 0.6314 - val_accuracy: 0.7292\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8490 - val_loss: 0.6336 - val_accuracy: 0.7292\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8507 - val_loss: 0.6322 - val_accuracy: 0.7292\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3529 - accuracy: 0.8507 - val_loss: 0.6330 - val_accuracy: 0.7292\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8507 - val_loss: 0.6335 - val_accuracy: 0.7292\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8507 - val_loss: 0.6332 - val_accuracy: 0.7292\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8507 - val_loss: 0.6323 - val_accuracy: 0.7292\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8507 - val_loss: 0.6323 - val_accuracy: 0.7292\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8524 - val_loss: 0.6320 - val_accuracy: 0.7292\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8507 - val_loss: 0.6315 - val_accuracy: 0.7292\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8490 - val_loss: 0.6340 - val_accuracy: 0.7292\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8507 - val_loss: 0.6328 - val_accuracy: 0.7292\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8490 - val_loss: 0.6333 - val_accuracy: 0.7292\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3532 - accuracy: 0.8507 - val_loss: 0.6355 - val_accuracy: 0.7292\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8507 - val_loss: 0.6347 - val_accuracy: 0.7240\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8524 - val_loss: 0.6363 - val_accuracy: 0.7240\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8507 - val_loss: 0.6371 - val_accuracy: 0.7188\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8507 - val_loss: 0.6360 - val_accuracy: 0.7240\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_3.add(Dense(6, activation=\"relu\"))\n",
    "model_3.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_3.compile('rmsprop', \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_3 = model_3.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(2, 2, (1,1))\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, (1,2))\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')\n",
    "\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.729\n",
      "roc-auc is 0.796\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
