{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from tensorflow.keras.models  import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Practice\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "# from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('data/diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "0               6                     148              72              35   \n",
       "1               1                      85              66              29   \n",
       "2               8                     183              64               0   \n",
       "3               1                      89              66              23   \n",
       "4               0                     137              40              35   \n",
       "\n",
       "   insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "0        0  33.6              0.627   50             1  \n",
       "1        0  26.6              0.351   31             0  \n",
       "2        0  23.3              0.672   32             1  \n",
       "3       94  28.1              0.167   21             0  \n",
       "4      168  43.1              2.288   33             1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>64</td>\n",
       "      <td>37</td>\n",
       "      <td>64</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>78</td>\n",
       "      <td>29</td>\n",
       "      <td>76</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.365</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>70</td>\n",
       "      <td>38</td>\n",
       "      <td>360</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.337</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>76</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>0.378</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.6</td>\n",
       "      <td>0.368</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "448               0                     104              64              37   \n",
       "544               1                      88              78              29   \n",
       "296               2                     146              70              38   \n",
       "719               5                      97              76              27   \n",
       "366               6                     124              72               0   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "448       64  33.6              0.510   22             1  \n",
       "544       76  32.0              0.365   29             0  \n",
       "296      360  28.0              0.337   29             1  \n",
       "719        0  35.6              0.378   52             1  \n",
       "366        0  27.6              0.368   29             1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.651042\n",
       "1    0.348958\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.786\n",
      "roc-auc is 0.831\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# roc_auc_score(y_test,y_pred_prob_rf[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.766\n",
      "roc-auc is 0.824\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(accuracy_score(y_test,y_pred_class_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.01449275, 0.04347826, 0.10144928, 0.13043478,\n",
       "       0.15942029, 0.20289855, 0.23188406, 0.26086957, 0.26086957,\n",
       "       0.28985507, 0.28985507, 0.30434783, 0.33333333, 0.33333333,\n",
       "       0.34782609, 0.37681159, 0.37681159, 0.39130435, 0.4057971 ,\n",
       "       0.42028986, 0.44927536, 0.46376812, 0.50724638, 0.50724638,\n",
       "       0.52173913, 0.53623188, 0.53623188, 0.56521739, 0.5942029 ,\n",
       "       0.60869565, 0.60869565, 0.62318841, 0.62318841, 0.62318841,\n",
       "       0.62318841, 0.63768116, 0.63768116, 0.65217391, 0.65217391,\n",
       "       0.68115942, 0.69565217, 0.69565217, 0.72463768, 0.73913043,\n",
       "       0.76811594, 0.7826087 , 0.7826087 , 0.79710145, 0.79710145,\n",
       "       0.8115942 , 0.8115942 , 0.8115942 , 0.8115942 , 0.82608696,\n",
       "       0.82608696, 0.84057971, 0.84057971, 0.85507246, 0.85507246,\n",
       "       0.86956522, 0.86956522, 0.88405797, 0.88405797, 0.88405797,\n",
       "       0.91304348, 0.92753623, 0.92753623, 0.94202899, 0.94202899,\n",
       "       0.97101449, 0.97101449, 0.97101449, 0.97101449, 0.97101449,\n",
       "       0.97101449, 0.97101449, 0.97101449, 0.98550725, 0.98550725,\n",
       "       0.98550725, 0.98550725, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thr = roc_curve(y_test, y_pred_prob_rf[:, 1])\n",
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>576.0</td>\n",
       "      <td>4.625929e-18</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>-1.105597</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.216592</td>\n",
       "      <td>0.672413</td>\n",
       "      <td>3.932097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>576.0</td>\n",
       "      <td>9.406056e-17</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>-3.819562</td>\n",
       "      <td>-0.675618</td>\n",
       "      <td>-0.116169</td>\n",
       "      <td>0.624510</td>\n",
       "      <td>2.452568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>576.0</td>\n",
       "      <td>1.603655e-16</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>-3.393556</td>\n",
       "      <td>-0.312803</td>\n",
       "      <td>0.084714</td>\n",
       "      <td>0.581609</td>\n",
       "      <td>2.668571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576.0</td>\n",
       "      <td>-1.063964e-16</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>-1.312452</td>\n",
       "      <td>-1.312452</td>\n",
       "      <td>0.152734</td>\n",
       "      <td>0.726068</td>\n",
       "      <td>2.700884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>576.0</td>\n",
       "      <td>3.700743e-17</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>-0.713038</td>\n",
       "      <td>-0.713038</td>\n",
       "      <td>-0.361185</td>\n",
       "      <td>0.430486</td>\n",
       "      <td>6.728669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>576.0</td>\n",
       "      <td>1.023872e-15</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>-4.106147</td>\n",
       "      <td>-0.603208</td>\n",
       "      <td>0.021397</td>\n",
       "      <td>0.568731</td>\n",
       "      <td>4.535295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>576.0</td>\n",
       "      <td>1.531183e-15</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>-1.182175</td>\n",
       "      <td>-0.695967</td>\n",
       "      <td>-0.273210</td>\n",
       "      <td>0.480818</td>\n",
       "      <td>5.711795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>576.0</td>\n",
       "      <td>2.097088e-16</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>-1.023736</td>\n",
       "      <td>-0.767022</td>\n",
       "      <td>-0.339165</td>\n",
       "      <td>0.602119</td>\n",
       "      <td>4.110542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count          mean       std       min       25%       50%       75%  \\\n",
       "0  576.0  4.625929e-18  1.000869 -1.105597 -0.809262 -0.216592  0.672413   \n",
       "1  576.0  9.406056e-17  1.000869 -3.819562 -0.675618 -0.116169  0.624510   \n",
       "2  576.0  1.603655e-16  1.000869 -3.393556 -0.312803  0.084714  0.581609   \n",
       "3  576.0 -1.063964e-16  1.000869 -1.312452 -1.312452  0.152734  0.726068   \n",
       "4  576.0  3.700743e-17  1.000869 -0.713038 -0.713038 -0.361185  0.430486   \n",
       "5  576.0  1.023872e-15  1.000869 -4.106147 -0.603208  0.021397  0.568731   \n",
       "6  576.0  1.531183e-15  1.000869 -1.182175 -0.695967 -0.273210  0.480818   \n",
       "7  576.0  2.097088e-16  1.000869 -1.023736 -0.767022 -0.339165  0.602119   \n",
       "\n",
       "        max  \n",
       "0  3.932097  \n",
       "1  2.452568  \n",
       "2  2.668571  \n",
       "3  2.700884  \n",
       "4  6.728669  \n",
       "5  4.535295  \n",
       "6  5.711795  \n",
       "7  4.110542  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_norm).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Practice\n",
    "# normalizer = StandardScaler()\n",
    "# X_train_norm = normalizer.fit_transform(X_train)\n",
    "# X_test_norm = normalizer.fit_transform(X_test)\n",
    "\n",
    "# model_1 = Sequential()\n",
    "# model_1.add(Dense(12, input_shape = (8,), activation = 'sigmoid'))\n",
    "# model_1.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6342 - accuracy: 0.6684 - val_loss: 0.6262 - val_accuracy: 0.6875\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.6753 - val_loss: 0.6229 - val_accuracy: 0.6979\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6875 - val_loss: 0.6200 - val_accuracy: 0.7031\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6875 - val_loss: 0.6174 - val_accuracy: 0.7031\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6771 - val_loss: 0.6149 - val_accuracy: 0.7031\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6840 - val_loss: 0.6127 - val_accuracy: 0.7031\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6875 - val_loss: 0.6107 - val_accuracy: 0.7031\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.6962 - val_loss: 0.6088 - val_accuracy: 0.6875\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.6927 - val_loss: 0.6070 - val_accuracy: 0.6979\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6962 - val_loss: 0.6054 - val_accuracy: 0.6927\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.6979 - val_loss: 0.6040 - val_accuracy: 0.6927\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.7031 - val_loss: 0.6026 - val_accuracy: 0.7031\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.6927 - val_loss: 0.6013 - val_accuracy: 0.6979\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.6944 - val_loss: 0.6001 - val_accuracy: 0.7031\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.6910 - val_loss: 0.5990 - val_accuracy: 0.7135\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.6892 - val_loss: 0.5980 - val_accuracy: 0.7135\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.6910 - val_loss: 0.5970 - val_accuracy: 0.7188\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.6910 - val_loss: 0.5960 - val_accuracy: 0.7188\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.6910 - val_loss: 0.5952 - val_accuracy: 0.7135\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.6962 - val_loss: 0.5943 - val_accuracy: 0.7135\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.6944 - val_loss: 0.5935 - val_accuracy: 0.7083\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6979 - val_loss: 0.5928 - val_accuracy: 0.7083\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.6997 - val_loss: 0.5920 - val_accuracy: 0.7083\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.6979 - val_loss: 0.5913 - val_accuracy: 0.7083\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.6979 - val_loss: 0.5906 - val_accuracy: 0.7083\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.6979 - val_loss: 0.5900 - val_accuracy: 0.7083\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.6962 - val_loss: 0.5894 - val_accuracy: 0.7083\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.6979 - val_loss: 0.5887 - val_accuracy: 0.7083\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.6962 - val_loss: 0.5882 - val_accuracy: 0.7031\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.6962 - val_loss: 0.5876 - val_accuracy: 0.7031\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.6962 - val_loss: 0.5870 - val_accuracy: 0.7031\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.6962 - val_loss: 0.5864 - val_accuracy: 0.7031\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.6979 - val_loss: 0.5859 - val_accuracy: 0.7083\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.6979 - val_loss: 0.5854 - val_accuracy: 0.7083\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.6979 - val_loss: 0.5848 - val_accuracy: 0.7083\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.6997 - val_loss: 0.5843 - val_accuracy: 0.7083\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.6997 - val_loss: 0.5838 - val_accuracy: 0.7083\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.6997 - val_loss: 0.5833 - val_accuracy: 0.7083\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.6997 - val_loss: 0.5828 - val_accuracy: 0.7083\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.6997 - val_loss: 0.5823 - val_accuracy: 0.7083\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.7014 - val_loss: 0.5818 - val_accuracy: 0.7083\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.7014 - val_loss: 0.5814 - val_accuracy: 0.7083\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7014 - val_loss: 0.5809 - val_accuracy: 0.7083\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.7031 - val_loss: 0.5804 - val_accuracy: 0.7083\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7031 - val_loss: 0.5799 - val_accuracy: 0.7083\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7031 - val_loss: 0.5795 - val_accuracy: 0.7135\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7031 - val_loss: 0.5790 - val_accuracy: 0.7135\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.7049 - val_loss: 0.5786 - val_accuracy: 0.7135\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.7049 - val_loss: 0.5781 - val_accuracy: 0.7135\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.7031 - val_loss: 0.5776 - val_accuracy: 0.7135\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7031 - val_loss: 0.5772 - val_accuracy: 0.7135\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.7031 - val_loss: 0.5767 - val_accuracy: 0.7135\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.7031 - val_loss: 0.5763 - val_accuracy: 0.7135\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7031 - val_loss: 0.5759 - val_accuracy: 0.7135\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.7014 - val_loss: 0.5754 - val_accuracy: 0.7135\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7014 - val_loss: 0.5750 - val_accuracy: 0.7135\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.7014 - val_loss: 0.5745 - val_accuracy: 0.7135\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7049 - val_loss: 0.5741 - val_accuracy: 0.7135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7031 - val_loss: 0.5737 - val_accuracy: 0.7135\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7031 - val_loss: 0.5732 - val_accuracy: 0.7135\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7031 - val_loss: 0.5728 - val_accuracy: 0.7135\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7031 - val_loss: 0.5724 - val_accuracy: 0.7135\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7031 - val_loss: 0.5720 - val_accuracy: 0.7135\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7049 - val_loss: 0.5715 - val_accuracy: 0.7135\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7066 - val_loss: 0.5711 - val_accuracy: 0.7188\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7066 - val_loss: 0.5707 - val_accuracy: 0.7188\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7049 - val_loss: 0.5703 - val_accuracy: 0.7240\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7049 - val_loss: 0.5699 - val_accuracy: 0.7240\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7066 - val_loss: 0.5695 - val_accuracy: 0.7240\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7066 - val_loss: 0.5690 - val_accuracy: 0.7240\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7066 - val_loss: 0.5686 - val_accuracy: 0.7240\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7066 - val_loss: 0.5682 - val_accuracy: 0.7240\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7083 - val_loss: 0.5678 - val_accuracy: 0.7240\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7083 - val_loss: 0.5674 - val_accuracy: 0.7240\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5636 - accuracy: 0.7083 - val_loss: 0.5670 - val_accuracy: 0.7240\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7083 - val_loss: 0.5666 - val_accuracy: 0.7240\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7083 - val_loss: 0.5662 - val_accuracy: 0.7240\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7083 - val_loss: 0.5658 - val_accuracy: 0.7240\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7101 - val_loss: 0.5654 - val_accuracy: 0.7292\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7101 - val_loss: 0.5650 - val_accuracy: 0.7292\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7101 - val_loss: 0.5646 - val_accuracy: 0.7292\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7101 - val_loss: 0.5642 - val_accuracy: 0.7292\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7135 - val_loss: 0.5638 - val_accuracy: 0.7344\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7135 - val_loss: 0.5634 - val_accuracy: 0.7344\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7153 - val_loss: 0.5630 - val_accuracy: 0.7344\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7153 - val_loss: 0.5627 - val_accuracy: 0.7344\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7153 - val_loss: 0.5623 - val_accuracy: 0.7344\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7153 - val_loss: 0.5619 - val_accuracy: 0.7344\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7153 - val_loss: 0.5615 - val_accuracy: 0.7344\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7170 - val_loss: 0.5611 - val_accuracy: 0.7344\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7170 - val_loss: 0.5607 - val_accuracy: 0.7344\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7170 - val_loss: 0.5604 - val_accuracy: 0.7396\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7188 - val_loss: 0.5600 - val_accuracy: 0.7396\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7205 - val_loss: 0.5596 - val_accuracy: 0.7396\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7205 - val_loss: 0.5592 - val_accuracy: 0.7396\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7188 - val_loss: 0.5589 - val_accuracy: 0.7396\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7205 - val_loss: 0.5585 - val_accuracy: 0.7396\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7222 - val_loss: 0.5581 - val_accuracy: 0.7396\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7205 - val_loss: 0.5578 - val_accuracy: 0.7396\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7205 - val_loss: 0.5574 - val_accuracy: 0.7396\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7205 - val_loss: 0.5570 - val_accuracy: 0.7396\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.7205 - val_loss: 0.5567 - val_accuracy: 0.7396\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7222 - val_loss: 0.5563 - val_accuracy: 0.7396\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7257 - val_loss: 0.5560 - val_accuracy: 0.7396\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7257 - val_loss: 0.5556 - val_accuracy: 0.7448\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7274 - val_loss: 0.5553 - val_accuracy: 0.7448\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7274 - val_loss: 0.5549 - val_accuracy: 0.7448\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7257 - val_loss: 0.5546 - val_accuracy: 0.7448\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7292 - val_loss: 0.5542 - val_accuracy: 0.7448\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7292 - val_loss: 0.5539 - val_accuracy: 0.7448\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7292 - val_loss: 0.5535 - val_accuracy: 0.7448\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7292 - val_loss: 0.5532 - val_accuracy: 0.7448\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7292 - val_loss: 0.5528 - val_accuracy: 0.7448\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7292 - val_loss: 0.5525 - val_accuracy: 0.7448\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7292 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.7292 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7292 - val_loss: 0.5515 - val_accuracy: 0.7448\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7292 - val_loss: 0.5511 - val_accuracy: 0.7448\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7292 - val_loss: 0.5508 - val_accuracy: 0.7448\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7292 - val_loss: 0.5505 - val_accuracy: 0.7448\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7292 - val_loss: 0.5501 - val_accuracy: 0.7448\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7292 - val_loss: 0.5498 - val_accuracy: 0.7448\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7274 - val_loss: 0.5495 - val_accuracy: 0.7448\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7274 - val_loss: 0.5491 - val_accuracy: 0.7448\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7274 - val_loss: 0.5488 - val_accuracy: 0.7396\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7274 - val_loss: 0.5485 - val_accuracy: 0.7396\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7274 - val_loss: 0.5482 - val_accuracy: 0.7396\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7309 - val_loss: 0.5478 - val_accuracy: 0.7448\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7292 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7274 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7292 - val_loss: 0.5469 - val_accuracy: 0.7448\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7274 - val_loss: 0.5466 - val_accuracy: 0.7448\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7292 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7309 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7292 - val_loss: 0.5456 - val_accuracy: 0.7500\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7309 - val_loss: 0.5453 - val_accuracy: 0.7500\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7309 - val_loss: 0.5450 - val_accuracy: 0.7500\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7309 - val_loss: 0.5447 - val_accuracy: 0.7500\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7309 - val_loss: 0.5444 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7309 - val_loss: 0.5441 - val_accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7309 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7309 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7309 - val_loss: 0.5432 - val_accuracy: 0.7500\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7309 - val_loss: 0.5429 - val_accuracy: 0.7500\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7309 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7309 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7309 - val_loss: 0.5420 - val_accuracy: 0.7500\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7309 - val_loss: 0.5417 - val_accuracy: 0.7500\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7309 - val_loss: 0.5414 - val_accuracy: 0.7500\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7292 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7292 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7309 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7309 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7326 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7309 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7326 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7326 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7326 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7326 - val_loss: 0.5386 - val_accuracy: 0.7500\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7326 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7326 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7326 - val_loss: 0.5378 - val_accuracy: 0.7500\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7326 - val_loss: 0.5375 - val_accuracy: 0.7500\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7326 - val_loss: 0.5373 - val_accuracy: 0.7500\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7326 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7326 - val_loss: 0.5367 - val_accuracy: 0.7500\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7326 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7326 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7326 - val_loss: 0.5359 - val_accuracy: 0.7500\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7326 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7326 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7326 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7326 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7344 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7344 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7378 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7378 - val_loss: 0.5339 - val_accuracy: 0.7552\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7378 - val_loss: 0.5336 - val_accuracy: 0.7552\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7378 - val_loss: 0.5334 - val_accuracy: 0.7552\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7361 - val_loss: 0.5331 - val_accuracy: 0.7552\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7378 - val_loss: 0.5329 - val_accuracy: 0.7552\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7361 - val_loss: 0.5326 - val_accuracy: 0.7552\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7361 - val_loss: 0.5324 - val_accuracy: 0.7552\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7378 - val_loss: 0.5321 - val_accuracy: 0.7552\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7378 - val_loss: 0.5319 - val_accuracy: 0.7552\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7378 - val_loss: 0.5316 - val_accuracy: 0.7552\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7378 - val_loss: 0.5314 - val_accuracy: 0.7552\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7378 - val_loss: 0.5312 - val_accuracy: 0.7552\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7378 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7396 - val_loss: 0.5307 - val_accuracy: 0.7552\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7378 - val_loss: 0.5304 - val_accuracy: 0.7552\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7396 - val_loss: 0.5302 - val_accuracy: 0.7604\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7378 - val_loss: 0.5300 - val_accuracy: 0.7604\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7448 - val_loss: 0.5297 - val_accuracy: 0.7604\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7448 - val_loss: 0.5295 - val_accuracy: 0.7604\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7448 - val_loss: 0.5293 - val_accuracy: 0.7604\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7448 - val_loss: 0.5290 - val_accuracy: 0.7604\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7448 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7448 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7448 - val_loss: 0.5284 - val_accuracy: 0.7604\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4227847 ],\n",
       "       [0.637563  ],\n",
       "       [0.2852093 ],\n",
       "       [0.26319802],\n",
       "       [0.22936916],\n",
       "       [0.5490242 ],\n",
       "       [0.18383697],\n",
       "       [0.34049025],\n",
       "       [0.6217444 ],\n",
       "       [0.3332693 ]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.760\n",
      "roc-auc is 0.811\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6341755390167236,\n",
       "  0.6303138136863708,\n",
       "  0.6268115043640137,\n",
       "  0.6236129403114319,\n",
       "  0.6206603646278381,\n",
       "  0.6179781556129456,\n",
       "  0.6154729127883911,\n",
       "  0.6131836771965027,\n",
       "  0.6110233068466187,\n",
       "  0.6090730428695679,\n",
       "  0.6072262525558472,\n",
       "  0.6055330634117126,\n",
       "  0.6039467453956604,\n",
       "  0.6024807095527649,\n",
       "  0.6010957360267639,\n",
       "  0.5997856855392456,\n",
       "  0.5985662341117859,\n",
       "  0.597402811050415,\n",
       "  0.5963103175163269,\n",
       "  0.5952363014221191,\n",
       "  0.5942342281341553,\n",
       "  0.5933167934417725,\n",
       "  0.5923969745635986,\n",
       "  0.5915281772613525,\n",
       "  0.5906646847724915,\n",
       "  0.5898797512054443,\n",
       "  0.5890949964523315,\n",
       "  0.5883294939994812,\n",
       "  0.587642252445221,\n",
       "  0.5869181156158447,\n",
       "  0.5862325429916382,\n",
       "  0.5855403542518616,\n",
       "  0.5848969221115112,\n",
       "  0.5842614769935608,\n",
       "  0.5836129784584045,\n",
       "  0.5830145478248596,\n",
       "  0.582401692867279,\n",
       "  0.5818077921867371,\n",
       "  0.5812395811080933,\n",
       "  0.5806864500045776,\n",
       "  0.5800901651382446,\n",
       "  0.5795584917068481,\n",
       "  0.5789914727210999,\n",
       "  0.5784467458724976,\n",
       "  0.577895998954773,\n",
       "  0.5773550271987915,\n",
       "  0.5768756866455078,\n",
       "  0.5763417482376099,\n",
       "  0.5758108496665955,\n",
       "  0.5753121972084045,\n",
       "  0.5747840404510498,\n",
       "  0.5742891430854797,\n",
       "  0.5738188624382019,\n",
       "  0.5733280181884766,\n",
       "  0.5728127956390381,\n",
       "  0.5723304152488708,\n",
       "  0.5718463063240051,\n",
       "  0.5713831782341003,\n",
       "  0.5708810687065125,\n",
       "  0.5704073905944824,\n",
       "  0.5699485540390015,\n",
       "  0.5694720149040222,\n",
       "  0.5690049529075623,\n",
       "  0.5685332417488098,\n",
       "  0.5680831670761108,\n",
       "  0.5676208138465881,\n",
       "  0.5671707391738892,\n",
       "  0.566713273525238,\n",
       "  0.566246747970581,\n",
       "  0.5658010840415955,\n",
       "  0.5653614401817322,\n",
       "  0.5649195909500122,\n",
       "  0.5644753575325012,\n",
       "  0.5640252828598022,\n",
       "  0.5635966062545776,\n",
       "  0.5631687641143799,\n",
       "  0.5627272129058838,\n",
       "  0.5622852444648743,\n",
       "  0.5618610382080078,\n",
       "  0.5614365935325623,\n",
       "  0.5610219240188599,\n",
       "  0.5605647563934326,\n",
       "  0.56017005443573,\n",
       "  0.5597334504127502,\n",
       "  0.5592989325523376,\n",
       "  0.5588924884796143,\n",
       "  0.5584679841995239,\n",
       "  0.5580744743347168,\n",
       "  0.5576409101486206,\n",
       "  0.5572453141212463,\n",
       "  0.556835412979126,\n",
       "  0.5564181208610535,\n",
       "  0.5560144186019897,\n",
       "  0.5556207895278931,\n",
       "  0.5552070140838623,\n",
       "  0.5548203587532043,\n",
       "  0.5544214248657227,\n",
       "  0.5540223717689514,\n",
       "  0.5536147952079773,\n",
       "  0.5532535314559937,\n",
       "  0.5528272390365601,\n",
       "  0.5524479150772095,\n",
       "  0.5520784854888916,\n",
       "  0.5516626834869385,\n",
       "  0.5512964129447937,\n",
       "  0.5509183406829834,\n",
       "  0.550523042678833,\n",
       "  0.5501943826675415,\n",
       "  0.5497749447822571,\n",
       "  0.5493764281272888,\n",
       "  0.5490208864212036,\n",
       "  0.5486330986022949,\n",
       "  0.548255205154419,\n",
       "  0.5478914380073547,\n",
       "  0.5475154519081116,\n",
       "  0.5471504926681519,\n",
       "  0.5467869639396667,\n",
       "  0.5463913083076477,\n",
       "  0.5460590124130249,\n",
       "  0.5456879138946533,\n",
       "  0.5453238487243652,\n",
       "  0.5449544191360474,\n",
       "  0.5446161031723022,\n",
       "  0.544241726398468,\n",
       "  0.5438868999481201,\n",
       "  0.5435431599617004,\n",
       "  0.5431833267211914,\n",
       "  0.5428512096405029,\n",
       "  0.5425065159797668,\n",
       "  0.5421420931816101,\n",
       "  0.5417883396148682,\n",
       "  0.541461706161499,\n",
       "  0.5411012768745422,\n",
       "  0.5407636761665344,\n",
       "  0.5404173135757446,\n",
       "  0.5401022434234619,\n",
       "  0.5397508144378662,\n",
       "  0.5394255518913269,\n",
       "  0.5390772223472595,\n",
       "  0.5387586951255798,\n",
       "  0.5384103059768677,\n",
       "  0.5380876064300537,\n",
       "  0.5377385020256042,\n",
       "  0.5374087691307068,\n",
       "  0.5370901823043823,\n",
       "  0.5367835164070129,\n",
       "  0.5364479422569275,\n",
       "  0.5361123085021973,\n",
       "  0.5357896089553833,\n",
       "  0.5354704260826111,\n",
       "  0.5351604223251343,\n",
       "  0.534861147403717,\n",
       "  0.5345255732536316,\n",
       "  0.5342027544975281,\n",
       "  0.5338979363441467,\n",
       "  0.5335895419120789,\n",
       "  0.5332815647125244,\n",
       "  0.5329587459564209,\n",
       "  0.5326554775238037,\n",
       "  0.5323429703712463,\n",
       "  0.5320295691490173,\n",
       "  0.5317254662513733,\n",
       "  0.5314479470252991,\n",
       "  0.5311443209648132,\n",
       "  0.530808687210083,\n",
       "  0.5305236577987671,\n",
       "  0.5302294492721558,\n",
       "  0.5299320220947266,\n",
       "  0.5296376943588257,\n",
       "  0.5293394923210144,\n",
       "  0.5290296673774719,\n",
       "  0.5287404656410217,\n",
       "  0.5284707546234131,\n",
       "  0.5281816720962524,\n",
       "  0.5278863906860352,\n",
       "  0.5275712609291077,\n",
       "  0.5272859334945679,\n",
       "  0.5270130038261414,\n",
       "  0.5267388820648193,\n",
       "  0.5264498591423035,\n",
       "  0.5261613726615906,\n",
       "  0.5258802175521851,\n",
       "  0.5255930423736572,\n",
       "  0.5253117084503174,\n",
       "  0.5250362157821655,\n",
       "  0.5247658491134644,\n",
       "  0.5244863033294678,\n",
       "  0.5242183804512024,\n",
       "  0.5239589214324951,\n",
       "  0.5236804485321045,\n",
       "  0.5234096050262451,\n",
       "  0.5231295824050903,\n",
       "  0.5228778719902039,\n",
       "  0.5226008892059326,\n",
       "  0.522328794002533,\n",
       "  0.5220938920974731,\n",
       "  0.5218052864074707,\n",
       "  0.5215571522712708,\n",
       "  0.5212926864624023,\n",
       "  0.5210213661193848],\n",
       " 'accuracy': [0.6684027910232544,\n",
       "  0.6753472089767456,\n",
       "  0.6875,\n",
       "  0.6875,\n",
       "  0.6770833134651184,\n",
       "  0.6840277910232544,\n",
       "  0.6875,\n",
       "  0.6961805820465088,\n",
       "  0.6927083134651184,\n",
       "  0.6961805820465088,\n",
       "  0.6979166865348816,\n",
       "  0.703125,\n",
       "  0.6927083134651184,\n",
       "  0.6944444179534912,\n",
       "  0.6909722089767456,\n",
       "  0.6892361044883728,\n",
       "  0.6909722089767456,\n",
       "  0.6909722089767456,\n",
       "  0.6909722089767456,\n",
       "  0.6961805820465088,\n",
       "  0.6944444179534912,\n",
       "  0.6979166865348816,\n",
       "  0.6996527910232544,\n",
       "  0.6979166865348816,\n",
       "  0.6979166865348816,\n",
       "  0.6979166865348816,\n",
       "  0.6961805820465088,\n",
       "  0.6979166865348816,\n",
       "  0.6961805820465088,\n",
       "  0.6961805820465088,\n",
       "  0.6961805820465088,\n",
       "  0.6961805820465088,\n",
       "  0.6979166865348816,\n",
       "  0.6979166865348816,\n",
       "  0.6979166865348816,\n",
       "  0.6996527910232544,\n",
       "  0.6996527910232544,\n",
       "  0.6996527910232544,\n",
       "  0.6996527910232544,\n",
       "  0.6996527910232544,\n",
       "  0.7013888955116272,\n",
       "  0.7013888955116272,\n",
       "  0.7013888955116272,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.7048611044883728,\n",
       "  0.7048611044883728,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.7013888955116272,\n",
       "  0.7013888955116272,\n",
       "  0.7013888955116272,\n",
       "  0.7048611044883728,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.7048611044883728,\n",
       "  0.7065972089767456,\n",
       "  0.7065972089767456,\n",
       "  0.7048611044883728,\n",
       "  0.7048611044883728,\n",
       "  0.7065972089767456,\n",
       "  0.7065972089767456,\n",
       "  0.7065972089767456,\n",
       "  0.7065972089767456,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7100694179534912,\n",
       "  0.7100694179534912,\n",
       "  0.7100694179534912,\n",
       "  0.7100694179534912,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7152777910232544,\n",
       "  0.7152777910232544,\n",
       "  0.7152777910232544,\n",
       "  0.7152777910232544,\n",
       "  0.7152777910232544,\n",
       "  0.7170138955116272,\n",
       "  0.7170138955116272,\n",
       "  0.7170138955116272,\n",
       "  0.71875,\n",
       "  0.7204861044883728,\n",
       "  0.7204861044883728,\n",
       "  0.71875,\n",
       "  0.7204861044883728,\n",
       "  0.7222222089767456,\n",
       "  0.7204861044883728,\n",
       "  0.7204861044883728,\n",
       "  0.7204861044883728,\n",
       "  0.7204861044883728,\n",
       "  0.7222222089767456,\n",
       "  0.7256944179534912,\n",
       "  0.7256944179534912,\n",
       "  0.7274305820465088,\n",
       "  0.7274305820465088,\n",
       "  0.7256944179534912,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7274305820465088,\n",
       "  0.7274305820465088,\n",
       "  0.7274305820465088,\n",
       "  0.7274305820465088,\n",
       "  0.7274305820465088,\n",
       "  0.7309027910232544,\n",
       "  0.7291666865348816,\n",
       "  0.7274305820465088,\n",
       "  0.7291666865348816,\n",
       "  0.7274305820465088,\n",
       "  0.7291666865348816,\n",
       "  0.7309027910232544,\n",
       "  0.7291666865348816,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7309027910232544,\n",
       "  0.7309027910232544,\n",
       "  0.7326388955116272,\n",
       "  0.7309027910232544,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.7326388955116272,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.7378472089767456,\n",
       "  0.7378472089767456,\n",
       "  0.7378472089767456,\n",
       "  0.7378472089767456,\n",
       "  0.7361111044883728,\n",
       "  0.7378472089767456,\n",
       "  0.7361111044883728,\n",
       "  0.7361111044883728,\n",
       "  0.7378472089767456,\n",
       "  0.7378472089767456,\n",
       "  0.7378472089767456,\n",
       "  0.7378472089767456,\n",
       "  0.7378472089767456,\n",
       "  0.7378472089767456,\n",
       "  0.7395833134651184,\n",
       "  0.7378472089767456,\n",
       "  0.7395833134651184,\n",
       "  0.7378472089767456,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816],\n",
       " 'val_loss': [0.6261606812477112,\n",
       "  0.6229429244995117,\n",
       "  0.6200256943702698,\n",
       "  0.6173620820045471,\n",
       "  0.6149211525917053,\n",
       "  0.6126871705055237,\n",
       "  0.6106511950492859,\n",
       "  0.6087638735771179,\n",
       "  0.6070367693901062,\n",
       "  0.6054324507713318,\n",
       "  0.603952944278717,\n",
       "  0.6025863289833069,\n",
       "  0.601311445236206,\n",
       "  0.6001222133636475,\n",
       "  0.5990056395530701,\n",
       "  0.5979605317115784,\n",
       "  0.5969743132591248,\n",
       "  0.596045732498169,\n",
       "  0.5951617360115051,\n",
       "  0.5943240523338318,\n",
       "  0.5935247540473938,\n",
       "  0.5927608609199524,\n",
       "  0.5920297503471375,\n",
       "  0.5913246273994446,\n",
       "  0.5906479358673096,\n",
       "  0.589995265007019,\n",
       "  0.589363157749176,\n",
       "  0.5887491106987,\n",
       "  0.5881530046463013,\n",
       "  0.587570309638977,\n",
       "  0.5870009064674377,\n",
       "  0.586444616317749,\n",
       "  0.5858988761901855,\n",
       "  0.5853634476661682,\n",
       "  0.5848374962806702,\n",
       "  0.5843202471733093,\n",
       "  0.5838103294372559,\n",
       "  0.5833072066307068,\n",
       "  0.5828104615211487,\n",
       "  0.5823194980621338,\n",
       "  0.5818339586257935,\n",
       "  0.5813533663749695,\n",
       "  0.5808774828910828,\n",
       "  0.5804055333137512,\n",
       "  0.579937756061554,\n",
       "  0.5794732570648193,\n",
       "  0.579011857509613,\n",
       "  0.5785536170005798,\n",
       "  0.5780988335609436,\n",
       "  0.5776472687721252,\n",
       "  0.5771974325180054,\n",
       "  0.5767499804496765,\n",
       "  0.5763041377067566,\n",
       "  0.5758615136146545,\n",
       "  0.5754203200340271,\n",
       "  0.5749821066856384,\n",
       "  0.5745459198951721,\n",
       "  0.5741121768951416,\n",
       "  0.5736793875694275,\n",
       "  0.5732479691505432,\n",
       "  0.5728192329406738,\n",
       "  0.5723919868469238,\n",
       "  0.571966826915741,\n",
       "  0.5715441703796387,\n",
       "  0.5711217522621155,\n",
       "  0.5707013607025146,\n",
       "  0.5702840685844421,\n",
       "  0.5698688626289368,\n",
       "  0.5694538354873657,\n",
       "  0.5690411925315857,\n",
       "  0.568631112575531,\n",
       "  0.5682203769683838,\n",
       "  0.5678122043609619,\n",
       "  0.5674061179161072,\n",
       "  0.5670012831687927,\n",
       "  0.5665982365608215,\n",
       "  0.5661973357200623,\n",
       "  0.5657966732978821,\n",
       "  0.5653992295265198,\n",
       "  0.5650026798248291,\n",
       "  0.5646079778671265,\n",
       "  0.5642134547233582,\n",
       "  0.5638229846954346,\n",
       "  0.5634320378303528,\n",
       "  0.5630436539649963,\n",
       "  0.5626575350761414,\n",
       "  0.562272310256958,\n",
       "  0.561889111995697,\n",
       "  0.5615065693855286,\n",
       "  0.5611246824264526,\n",
       "  0.560746967792511,\n",
       "  0.5603687167167664,\n",
       "  0.5599926114082336,\n",
       "  0.5596200823783875,\n",
       "  0.5592464208602905,\n",
       "  0.5588752031326294,\n",
       "  0.55850750207901,\n",
       "  0.5581404566764832,\n",
       "  0.5577744245529175,\n",
       "  0.5574095845222473,\n",
       "  0.5570465922355652,\n",
       "  0.5566840767860413,\n",
       "  0.5563237071037292,\n",
       "  0.555966317653656,\n",
       "  0.5556097626686096,\n",
       "  0.5552546977996826,\n",
       "  0.5549024939537048,\n",
       "  0.5545503497123718,\n",
       "  0.554202139377594,\n",
       "  0.5538544058799744,\n",
       "  0.553508996963501,\n",
       "  0.553163468837738,\n",
       "  0.5528197288513184,\n",
       "  0.5524782538414001,\n",
       "  0.5521370768547058,\n",
       "  0.551798403263092,\n",
       "  0.5514605045318604,\n",
       "  0.5511242747306824,\n",
       "  0.5507900714874268,\n",
       "  0.5504581332206726,\n",
       "  0.5501247048377991,\n",
       "  0.5497943758964539,\n",
       "  0.5494667887687683,\n",
       "  0.5491397976875305,\n",
       "  0.5488152503967285,\n",
       "  0.5484917163848877,\n",
       "  0.548168957233429,\n",
       "  0.5478480458259583,\n",
       "  0.5475285053253174,\n",
       "  0.5472099184989929,\n",
       "  0.5468948483467102,\n",
       "  0.5465803742408752,\n",
       "  0.5462678670883179,\n",
       "  0.5459574460983276,\n",
       "  0.5456447601318359,\n",
       "  0.5453364253044128,\n",
       "  0.545028567314148,\n",
       "  0.5447234511375427,\n",
       "  0.5444192290306091,\n",
       "  0.5441150665283203,\n",
       "  0.5438140630722046,\n",
       "  0.5435124635696411,\n",
       "  0.5432136654853821,\n",
       "  0.5429153442382812,\n",
       "  0.5426185727119446,\n",
       "  0.5423237681388855,\n",
       "  0.5420296788215637,\n",
       "  0.5417371392250061,\n",
       "  0.5414469838142395,\n",
       "  0.5411574244499207,\n",
       "  0.5408701300621033,\n",
       "  0.5405842661857605,\n",
       "  0.540299117565155,\n",
       "  0.5400155186653137,\n",
       "  0.5397323966026306,\n",
       "  0.5394511818885803,\n",
       "  0.539173424243927,\n",
       "  0.5388937592506409,\n",
       "  0.5386162400245667,\n",
       "  0.5383409857749939,\n",
       "  0.5380674004554749,\n",
       "  0.5377952456474304,\n",
       "  0.5375223755836487,\n",
       "  0.5372541546821594,\n",
       "  0.5369861721992493,\n",
       "  0.5367204546928406,\n",
       "  0.5364547967910767,\n",
       "  0.5361902117729187,\n",
       "  0.5359276533126831,\n",
       "  0.5356661677360535,\n",
       "  0.5354045629501343,\n",
       "  0.5351443290710449,\n",
       "  0.5348851680755615,\n",
       "  0.5346289277076721,\n",
       "  0.534371554851532,\n",
       "  0.5341159105300903,\n",
       "  0.5338630080223083,\n",
       "  0.5336107611656189,\n",
       "  0.5333606600761414,\n",
       "  0.5331118702888489,\n",
       "  0.5328611731529236,\n",
       "  0.5326130986213684,\n",
       "  0.5323667526245117,\n",
       "  0.5321211218833923,\n",
       "  0.5318775773048401,\n",
       "  0.5316354036331177,\n",
       "  0.531394362449646,\n",
       "  0.53115314245224,\n",
       "  0.5309135913848877,\n",
       "  0.5306757688522339,\n",
       "  0.5304389595985413,\n",
       "  0.5302031636238098,\n",
       "  0.5299676656723022,\n",
       "  0.5297342538833618,\n",
       "  0.5295008420944214,\n",
       "  0.5292716026306152,\n",
       "  0.529043436050415,\n",
       "  0.5288143754005432,\n",
       "  0.5285873413085938,\n",
       "  0.5283614993095398],\n",
       " 'val_accuracy': [0.6875,\n",
       "  0.6979166865348816,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.6875,\n",
       "  0.6979166865348816,\n",
       "  0.6927083134651184,\n",
       "  0.6927083134651184,\n",
       "  0.703125,\n",
       "  0.6979166865348816,\n",
       "  0.703125,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.71875,\n",
       "  0.71875,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.703125,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7083333134651184,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.7135416865348816,\n",
       "  0.71875,\n",
       "  0.71875,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7395833134651184,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7552083134651184,\n",
       "  0.7604166865348816,\n",
       "  0.7604166865348816,\n",
       "  0.7604166865348816,\n",
       "  0.7604166865348816,\n",
       "  0.7604166865348816,\n",
       "  0.7604166865348816,\n",
       "  0.7604166865348816,\n",
       "  0.7604166865348816,\n",
       "  0.7604166865348816]}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x241b94d7c70>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "# ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "# ax.legend()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"], 'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"], 'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7448 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7448 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7448 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7465 - val_loss: 0.5275 - val_accuracy: 0.7656\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7465 - val_loss: 0.5272 - val_accuracy: 0.7656\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7465 - val_loss: 0.5270 - val_accuracy: 0.7656\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7465 - val_loss: 0.5268 - val_accuracy: 0.7656\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7465 - val_loss: 0.5266 - val_accuracy: 0.7656\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7465 - val_loss: 0.5264 - val_accuracy: 0.7708\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7465 - val_loss: 0.5262 - val_accuracy: 0.7708\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7483 - val_loss: 0.5259 - val_accuracy: 0.7708\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7483 - val_loss: 0.5257 - val_accuracy: 0.7708\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7483 - val_loss: 0.5255 - val_accuracy: 0.7708\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7483 - val_loss: 0.5253 - val_accuracy: 0.7708\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7465 - val_loss: 0.5251 - val_accuracy: 0.7708\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7483 - val_loss: 0.5249 - val_accuracy: 0.7760\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7483 - val_loss: 0.5247 - val_accuracy: 0.7760\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7465 - val_loss: 0.5245 - val_accuracy: 0.7760\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7465 - val_loss: 0.5243 - val_accuracy: 0.7760\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7483 - val_loss: 0.5241 - val_accuracy: 0.7760\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7465 - val_loss: 0.5239 - val_accuracy: 0.7760\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7448 - val_loss: 0.5237 - val_accuracy: 0.7760\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7448 - val_loss: 0.5235 - val_accuracy: 0.7760\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7448 - val_loss: 0.5233 - val_accuracy: 0.7760\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7448 - val_loss: 0.5231 - val_accuracy: 0.7760\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7448 - val_loss: 0.5229 - val_accuracy: 0.7760\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7483 - val_loss: 0.5227 - val_accuracy: 0.7760\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7448 - val_loss: 0.5225 - val_accuracy: 0.7760\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7465 - val_loss: 0.5223 - val_accuracy: 0.7760\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7465 - val_loss: 0.5221 - val_accuracy: 0.7760\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7483 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7465 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7465 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7483 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7500 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7483 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7500 - val_loss: 0.5207 - val_accuracy: 0.7760\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7517 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7517 - val_loss: 0.5204 - val_accuracy: 0.7760\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7517 - val_loss: 0.5202 - val_accuracy: 0.7760\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7517 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7517 - val_loss: 0.5198 - val_accuracy: 0.7760\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7517 - val_loss: 0.5196 - val_accuracy: 0.7760\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7517 - val_loss: 0.5195 - val_accuracy: 0.7760\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7517 - val_loss: 0.5193 - val_accuracy: 0.7760\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7517 - val_loss: 0.5191 - val_accuracy: 0.7760\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7517 - val_loss: 0.5189 - val_accuracy: 0.7760\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7500 - val_loss: 0.5187 - val_accuracy: 0.7760\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7500 - val_loss: 0.5186 - val_accuracy: 0.7760\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7517 - val_loss: 0.5184 - val_accuracy: 0.7760\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7517 - val_loss: 0.5182 - val_accuracy: 0.7760\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7517 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7517 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7552 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7569 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7569 - val_loss: 0.5173 - val_accuracy: 0.7760\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7569 - val_loss: 0.5172 - val_accuracy: 0.7760\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7569 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7569 - val_loss: 0.5168 - val_accuracy: 0.7656\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7569 - val_loss: 0.5167 - val_accuracy: 0.7656\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7569 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7569 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7587 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7587 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7587 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7587 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7587 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7587 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7587 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7587 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7587 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7587 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7587 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7587 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7622 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7639 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7639 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7639 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7639 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7639 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7656 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7639 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7656 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7656 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7656 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7656 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7656 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7656 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7656 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7656 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7656 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7674 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7656 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7674 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7708 - val_loss: 0.5113 - val_accuracy: 0.7708\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7708 - val_loss: 0.5112 - val_accuracy: 0.7708\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7708 - val_loss: 0.5111 - val_accuracy: 0.7708\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7708 - val_loss: 0.5109 - val_accuracy: 0.7708\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7691 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7708 - val_loss: 0.5107 - val_accuracy: 0.7708\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7708 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7691 - val_loss: 0.5104 - val_accuracy: 0.7708\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7691 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7691 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7691 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7691 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7691 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7691 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7708 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7708 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7691 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7691 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7691 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7674 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7674 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7674 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7674 - val_loss: 0.5085 - val_accuracy: 0.7708\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7674 - val_loss: 0.5083 - val_accuracy: 0.7708\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7691 - val_loss: 0.5082 - val_accuracy: 0.7708\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7691 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7691 - val_loss: 0.5080 - val_accuracy: 0.7708\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7691 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7691 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7691 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7691 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7691 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7691 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7691 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7691 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7708 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7691 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7691 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7708 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7708 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7708 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7708 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7726 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7726 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7726 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7726 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7726 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7726 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7726 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7726 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7726 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7726 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7726 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7726 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7726 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7726 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7726 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7726 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7726 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7726 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7726 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7726 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7726 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7708 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7708 - val_loss: 0.5038 - val_accuracy: 0.7708\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7708 - val_loss: 0.5037 - val_accuracy: 0.7708\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7708 - val_loss: 0.5036 - val_accuracy: 0.7708\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7708 - val_loss: 0.5035 - val_accuracy: 0.7708\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7708 - val_loss: 0.5034 - val_accuracy: 0.7708\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7708 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7708 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7708 - val_loss: 0.5031 - val_accuracy: 0.7760\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7708 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7708 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7708 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7708 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7726 - val_loss: 0.5026 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7726 - val_loss: 0.5026 - val_accuracy: 0.7760\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7726 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7726 - val_loss: 0.5024 - val_accuracy: 0.7760\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7726 - val_loss: 0.5023 - val_accuracy: 0.7760\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7726 - val_loss: 0.5022 - val_accuracy: 0.7760\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7726 - val_loss: 0.5021 - val_accuracy: 0.7760\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7726 - val_loss: 0.5020 - val_accuracy: 0.7760\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7726 - val_loss: 0.5019 - val_accuracy: 0.7760\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7726 - val_loss: 0.5018 - val_accuracy: 0.7760\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7726 - val_loss: 0.5017 - val_accuracy: 0.7760\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7726 - val_loss: 0.5016 - val_accuracy: 0.7760\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7726 - val_loss: 0.5016 - val_accuracy: 0.7760\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7726 - val_loss: 0.5015 - val_accuracy: 0.7760\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7726 - val_loss: 0.5014 - val_accuracy: 0.7760\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7726 - val_loss: 0.5013 - val_accuracy: 0.7760\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7726 - val_loss: 0.5012 - val_accuracy: 0.7760\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7726 - val_loss: 0.5011 - val_accuracy: 0.7760\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7726 - val_loss: 0.5010 - val_accuracy: 0.7760\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7726 - val_loss: 0.5010 - val_accuracy: 0.7760\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7726 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7726 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7726 - val_loss: 0.5007 - val_accuracy: 0.7760\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7726 - val_loss: 0.5006 - val_accuracy: 0.7760\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7726 - val_loss: 0.5005 - val_accuracy: 0.7760\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7726 - val_loss: 0.5005 - val_accuracy: 0.7760\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7726 - val_loss: 0.5004 - val_accuracy: 0.7760\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7726 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7760\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7743 - val_loss: 0.4999 - val_accuracy: 0.7760\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7743 - val_loss: 0.4998 - val_accuracy: 0.7760\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7726 - val_loss: 0.4997 - val_accuracy: 0.7760\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7726 - val_loss: 0.4997 - val_accuracy: 0.7760\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7726 - val_loss: 0.4996 - val_accuracy: 0.7760\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7726 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7726 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7726 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7726 - val_loss: 0.4993 - val_accuracy: 0.7760\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7726 - val_loss: 0.4992 - val_accuracy: 0.7760\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7726 - val_loss: 0.4991 - val_accuracy: 0.7760\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7726 - val_loss: 0.4991 - val_accuracy: 0.7760\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7726 - val_loss: 0.4990 - val_accuracy: 0.7760\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7726 - val_loss: 0.4989 - val_accuracy: 0.7760\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7726 - val_loss: 0.4988 - val_accuracy: 0.7760\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7726 - val_loss: 0.4988 - val_accuracy: 0.7760\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7743 - val_loss: 0.4987 - val_accuracy: 0.7760\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7743 - val_loss: 0.4986 - val_accuracy: 0.7760\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7726 - val_loss: 0.4986 - val_accuracy: 0.7760\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7726 - val_loss: 0.4985 - val_accuracy: 0.7760\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7743 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7726 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7708 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7726 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7726 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7708 - val_loss: 0.4973 - val_accuracy: 0.7604\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7708 - val_loss: 0.4973 - val_accuracy: 0.7604\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7708 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7708 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7708 - val_loss: 0.4970 - val_accuracy: 0.7604\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7708 - val_loss: 0.4970 - val_accuracy: 0.7604\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7708 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7708 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7708 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7708 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7708 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7708 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7708 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7708 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7708 - val_loss: 0.4964 - val_accuracy: 0.7604\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7708 - val_loss: 0.4962 - val_accuracy: 0.7604\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7708 - val_loss: 0.4962 - val_accuracy: 0.7604\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7708 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7708 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7708 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7708 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7708 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7708 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7708 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7708 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7708 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7708 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7708 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7708 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7708 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7708 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7708 - val_loss: 0.4951 - val_accuracy: 0.7604\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7726 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7726 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7726 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7726 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7726 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7726 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7726 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7726 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7743 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7743 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7760 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7760 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7743 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7760 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7760 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7760 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7760 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7760 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7760 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7760 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7760 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7760 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7760 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7760 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7760 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7760 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7760 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7760 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7760 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7760 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7743 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7743 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7743 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7743 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7743 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7760 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7760 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7743 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7743 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7760 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7760 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7760 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7760 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7760 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7743 - val_loss: 0.4922 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7743 - val_loss: 0.4922 - val_accuracy: 0.7708\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7760 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7760 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7743 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7743 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7760 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7760 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7760 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7760 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7760 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7760 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7760 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7760 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7760 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7760 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7760 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7760 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7760 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7760 - val_loss: 0.4904 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7760 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7760 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7760 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7760 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7760 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7760 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7760 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7760 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7760 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7778 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7778 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7778 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7778 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7812 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7812 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7847 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7847 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7847 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7865 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7865 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7865 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7882 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7882 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7865 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7882 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7865 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7865 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7760 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7760 - val_loss: 0.4864 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7760 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7760 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7760 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7795 - val_loss: 0.4865 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x241b935d6d0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.7503 - accuracy: 0.3819 - val_loss: 0.7546 - val_accuracy: 0.4010\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7393 - accuracy: 0.4045 - val_loss: 0.7439 - val_accuracy: 0.4010\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7293 - accuracy: 0.4306 - val_loss: 0.7343 - val_accuracy: 0.4219\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7204 - accuracy: 0.4497 - val_loss: 0.7257 - val_accuracy: 0.4167\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7125 - accuracy: 0.4740 - val_loss: 0.7179 - val_accuracy: 0.4271\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7052 - accuracy: 0.4861 - val_loss: 0.7109 - val_accuracy: 0.4531\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.5191 - val_loss: 0.7045 - val_accuracy: 0.4844\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5260 - val_loss: 0.6987 - val_accuracy: 0.5000\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5590 - val_loss: 0.6934 - val_accuracy: 0.5312\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5781 - val_loss: 0.6885 - val_accuracy: 0.5260\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.6128 - val_loss: 0.6839 - val_accuracy: 0.5469\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6740 - accuracy: 0.6198 - val_loss: 0.6797 - val_accuracy: 0.5625\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6702 - accuracy: 0.6372 - val_loss: 0.6758 - val_accuracy: 0.5781\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.6476 - val_loss: 0.6722 - val_accuracy: 0.5833\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.6528 - val_loss: 0.6687 - val_accuracy: 0.5885\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.6562 - val_loss: 0.6656 - val_accuracy: 0.5938\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6571 - accuracy: 0.6615 - val_loss: 0.6625 - val_accuracy: 0.6146\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.6736 - val_loss: 0.6597 - val_accuracy: 0.6250\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6736 - val_loss: 0.6570 - val_accuracy: 0.6354\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.6753 - val_loss: 0.6545 - val_accuracy: 0.6406\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6840 - val_loss: 0.6522 - val_accuracy: 0.6510\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6447 - accuracy: 0.6806 - val_loss: 0.6500 - val_accuracy: 0.6719\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6788 - val_loss: 0.6478 - val_accuracy: 0.6667\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6788 - val_loss: 0.6458 - val_accuracy: 0.6823\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.6788 - val_loss: 0.6438 - val_accuracy: 0.6615\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6368 - accuracy: 0.6788 - val_loss: 0.6419 - val_accuracy: 0.6615\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6823 - val_loss: 0.6400 - val_accuracy: 0.6615\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6333 - accuracy: 0.6840 - val_loss: 0.6383 - val_accuracy: 0.6615\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.6840 - val_loss: 0.6366 - val_accuracy: 0.6719\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.6840 - val_loss: 0.6349 - val_accuracy: 0.6875\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.6892 - val_loss: 0.6332 - val_accuracy: 0.6719\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6267 - accuracy: 0.6892 - val_loss: 0.6316 - val_accuracy: 0.6823\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6875 - val_loss: 0.6300 - val_accuracy: 0.6823\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6858 - val_loss: 0.6284 - val_accuracy: 0.6823\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.6840 - val_loss: 0.6269 - val_accuracy: 0.6875\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6840 - val_loss: 0.6254 - val_accuracy: 0.6927\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6892 - val_loss: 0.6240 - val_accuracy: 0.6927\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.6858 - val_loss: 0.6225 - val_accuracy: 0.6927\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.6788 - val_loss: 0.6211 - val_accuracy: 0.6875\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.6823 - val_loss: 0.6197 - val_accuracy: 0.6875\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.6806 - val_loss: 0.6183 - val_accuracy: 0.6823\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.6823 - val_loss: 0.6170 - val_accuracy: 0.6875\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.6840 - val_loss: 0.6156 - val_accuracy: 0.6927\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.6840 - val_loss: 0.6143 - val_accuracy: 0.6927\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.6875 - val_loss: 0.6130 - val_accuracy: 0.6927\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.6892 - val_loss: 0.6117 - val_accuracy: 0.6875\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6875 - val_loss: 0.6104 - val_accuracy: 0.6979\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.6875 - val_loss: 0.6091 - val_accuracy: 0.6927\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.6892 - val_loss: 0.6078 - val_accuracy: 0.6927\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6020 - accuracy: 0.6892 - val_loss: 0.6066 - val_accuracy: 0.6927\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.6927 - val_loss: 0.6053 - val_accuracy: 0.6927\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.6910 - val_loss: 0.6041 - val_accuracy: 0.6927\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.6927 - val_loss: 0.6029 - val_accuracy: 0.6927\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.6927 - val_loss: 0.6017 - val_accuracy: 0.6927\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6892 - val_loss: 0.6005 - val_accuracy: 0.6927\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.6910 - val_loss: 0.5993 - val_accuracy: 0.6927\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.6944 - val_loss: 0.5981 - val_accuracy: 0.6927\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.6962 - val_loss: 0.5970 - val_accuracy: 0.6979\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.6962 - val_loss: 0.5958 - val_accuracy: 0.6979\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.6997 - val_loss: 0.5946 - val_accuracy: 0.6979\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.7014 - val_loss: 0.5935 - val_accuracy: 0.6875\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.7031 - val_loss: 0.5924 - val_accuracy: 0.6875\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.7031 - val_loss: 0.5913 - val_accuracy: 0.6927\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7031 - val_loss: 0.5902 - val_accuracy: 0.6927\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7049 - val_loss: 0.5891 - val_accuracy: 0.6927\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7049 - val_loss: 0.5880 - val_accuracy: 0.6927\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7049 - val_loss: 0.5869 - val_accuracy: 0.6927\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7083 - val_loss: 0.5858 - val_accuracy: 0.6927\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7101 - val_loss: 0.5847 - val_accuracy: 0.6927\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7118 - val_loss: 0.5837 - val_accuracy: 0.6979\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7135 - val_loss: 0.5826 - val_accuracy: 0.6979\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7153 - val_loss: 0.5816 - val_accuracy: 0.6979\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.7118 - val_loss: 0.5805 - val_accuracy: 0.6979\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7118 - val_loss: 0.5795 - val_accuracy: 0.6979\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.7118 - val_loss: 0.5785 - val_accuracy: 0.6979\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7118 - val_loss: 0.5775 - val_accuracy: 0.6979\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.7153 - val_loss: 0.5765 - val_accuracy: 0.6979\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7170 - val_loss: 0.5755 - val_accuracy: 0.6979\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7170 - val_loss: 0.5745 - val_accuracy: 0.6979\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7188 - val_loss: 0.5736 - val_accuracy: 0.6979\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7205 - val_loss: 0.5726 - val_accuracy: 0.6979\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7188 - val_loss: 0.5717 - val_accuracy: 0.6979\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7222 - val_loss: 0.5707 - val_accuracy: 0.6979\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7205 - val_loss: 0.5698 - val_accuracy: 0.6979\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7205 - val_loss: 0.5688 - val_accuracy: 0.6979\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7205 - val_loss: 0.5679 - val_accuracy: 0.6979\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7188 - val_loss: 0.5670 - val_accuracy: 0.6979\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7205 - val_loss: 0.5661 - val_accuracy: 0.6979\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7188 - val_loss: 0.5652 - val_accuracy: 0.6979\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7205 - val_loss: 0.5643 - val_accuracy: 0.6979\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7222 - val_loss: 0.5634 - val_accuracy: 0.6927\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7222 - val_loss: 0.5625 - val_accuracy: 0.6927\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7240 - val_loss: 0.5616 - val_accuracy: 0.6875\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7257 - val_loss: 0.5607 - val_accuracy: 0.6927\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7274 - val_loss: 0.5599 - val_accuracy: 0.6927\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7240 - val_loss: 0.5590 - val_accuracy: 0.6927\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7240 - val_loss: 0.5582 - val_accuracy: 0.6875\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7240 - val_loss: 0.5574 - val_accuracy: 0.6875\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7222 - val_loss: 0.5565 - val_accuracy: 0.6875\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7222 - val_loss: 0.5557 - val_accuracy: 0.6875\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7188 - val_loss: 0.5549 - val_accuracy: 0.6875\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7205 - val_loss: 0.5541 - val_accuracy: 0.6875\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7222 - val_loss: 0.5533 - val_accuracy: 0.6979\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7222 - val_loss: 0.5526 - val_accuracy: 0.6979\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7257 - val_loss: 0.5518 - val_accuracy: 0.7031\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5419 - accuracy: 0.7240 - val_loss: 0.5510 - val_accuracy: 0.7031\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.7274 - val_loss: 0.5503 - val_accuracy: 0.7031\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7257 - val_loss: 0.5495 - val_accuracy: 0.7031\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7292 - val_loss: 0.5488 - val_accuracy: 0.7031\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7292 - val_loss: 0.5481 - val_accuracy: 0.7083\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7326 - val_loss: 0.5474 - val_accuracy: 0.7083\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7326 - val_loss: 0.5467 - val_accuracy: 0.7083\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7326 - val_loss: 0.5459 - val_accuracy: 0.7083\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7344 - val_loss: 0.5452 - val_accuracy: 0.7083\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7344 - val_loss: 0.5445 - val_accuracy: 0.7083\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7344 - val_loss: 0.5439 - val_accuracy: 0.7083\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7344 - val_loss: 0.5432 - val_accuracy: 0.7083\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7344 - val_loss: 0.5425 - val_accuracy: 0.7083\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7344 - val_loss: 0.5418 - val_accuracy: 0.7135\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7344 - val_loss: 0.5412 - val_accuracy: 0.7031\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7344 - val_loss: 0.5405 - val_accuracy: 0.7031\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7344 - val_loss: 0.5399 - val_accuracy: 0.7031\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7344 - val_loss: 0.5392 - val_accuracy: 0.7083\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7344 - val_loss: 0.5386 - val_accuracy: 0.7083\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7344 - val_loss: 0.5380 - val_accuracy: 0.7083\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7378 - val_loss: 0.5374 - val_accuracy: 0.7083\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5251 - accuracy: 0.7378 - val_loss: 0.5368 - val_accuracy: 0.7083\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7378 - val_loss: 0.5362 - val_accuracy: 0.7083\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7344 - val_loss: 0.5356 - val_accuracy: 0.7083\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7361 - val_loss: 0.5350 - val_accuracy: 0.7083\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7361 - val_loss: 0.5345 - val_accuracy: 0.7135\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7361 - val_loss: 0.5339 - val_accuracy: 0.7135\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7378 - val_loss: 0.5333 - val_accuracy: 0.7135\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7396 - val_loss: 0.5328 - val_accuracy: 0.7135\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7396 - val_loss: 0.5322 - val_accuracy: 0.7135\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7413 - val_loss: 0.5317 - val_accuracy: 0.7135\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7396 - val_loss: 0.5312 - val_accuracy: 0.7135\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7413 - val_loss: 0.5307 - val_accuracy: 0.7188\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7396 - val_loss: 0.5302 - val_accuracy: 0.7188\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7413 - val_loss: 0.5297 - val_accuracy: 0.7188\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7396 - val_loss: 0.5292 - val_accuracy: 0.7188\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7396 - val_loss: 0.5287 - val_accuracy: 0.7188\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7396 - val_loss: 0.5283 - val_accuracy: 0.7240\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7378 - val_loss: 0.5278 - val_accuracy: 0.7240\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7396 - val_loss: 0.5274 - val_accuracy: 0.7240\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7413 - val_loss: 0.5269 - val_accuracy: 0.7240\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7431 - val_loss: 0.5265 - val_accuracy: 0.7240\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7465 - val_loss: 0.5261 - val_accuracy: 0.7240\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7465 - val_loss: 0.5256 - val_accuracy: 0.7240\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7465 - val_loss: 0.5252 - val_accuracy: 0.7240\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7465 - val_loss: 0.5248 - val_accuracy: 0.7240\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7465 - val_loss: 0.5244 - val_accuracy: 0.7240\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7483 - val_loss: 0.5240 - val_accuracy: 0.7240\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7448 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7465 - val_loss: 0.5232 - val_accuracy: 0.7188\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7483 - val_loss: 0.5229 - val_accuracy: 0.7188\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7483 - val_loss: 0.5225 - val_accuracy: 0.7188\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7465 - val_loss: 0.5221 - val_accuracy: 0.7188\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7483 - val_loss: 0.5218 - val_accuracy: 0.7188\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7483 - val_loss: 0.5214 - val_accuracy: 0.7188\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7535 - val_loss: 0.5208 - val_accuracy: 0.7135\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7535 - val_loss: 0.5204 - val_accuracy: 0.7188\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.7188\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7535 - val_loss: 0.5198 - val_accuracy: 0.7188\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7517 - val_loss: 0.5195 - val_accuracy: 0.7188\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7535 - val_loss: 0.5191 - val_accuracy: 0.7188\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7535 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7188\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7552 - val_loss: 0.5183 - val_accuracy: 0.7188\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7552 - val_loss: 0.5180 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7535 - val_loss: 0.5177 - val_accuracy: 0.7188\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7569 - val_loss: 0.5174 - val_accuracy: 0.7188\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7552 - val_loss: 0.5171 - val_accuracy: 0.7188\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7569 - val_loss: 0.5168 - val_accuracy: 0.7188\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7587 - val_loss: 0.5166 - val_accuracy: 0.7188\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7587 - val_loss: 0.5163 - val_accuracy: 0.7188\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7587 - val_loss: 0.5160 - val_accuracy: 0.7240\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7587 - val_loss: 0.5157 - val_accuracy: 0.7240\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7587 - val_loss: 0.5155 - val_accuracy: 0.7240\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7587 - val_loss: 0.5152 - val_accuracy: 0.7240\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7604 - val_loss: 0.5149 - val_accuracy: 0.7240\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7587 - val_loss: 0.5146 - val_accuracy: 0.7240\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7656 - val_loss: 0.5143 - val_accuracy: 0.7240\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7622 - val_loss: 0.5141 - val_accuracy: 0.7240\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7674 - val_loss: 0.5138 - val_accuracy: 0.7240\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7674 - val_loss: 0.5135 - val_accuracy: 0.7240\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.7674 - val_loss: 0.5133 - val_accuracy: 0.7240\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7674 - val_loss: 0.5130 - val_accuracy: 0.7240\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7674 - val_loss: 0.5127 - val_accuracy: 0.7240\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7674 - val_loss: 0.5125 - val_accuracy: 0.7240\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7691 - val_loss: 0.5123 - val_accuracy: 0.7240\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7691 - val_loss: 0.5120 - val_accuracy: 0.7240\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7674 - val_loss: 0.5118 - val_accuracy: 0.7240\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7674 - val_loss: 0.5116 - val_accuracy: 0.7240\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7691 - val_loss: 0.5113 - val_accuracy: 0.7240\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7674 - val_loss: 0.5111 - val_accuracy: 0.7240\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7691 - val_loss: 0.5109 - val_accuracy: 0.7240\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7691 - val_loss: 0.5107 - val_accuracy: 0.7240\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7691 - val_loss: 0.5104 - val_accuracy: 0.7240\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7674 - val_loss: 0.5102 - val_accuracy: 0.7292\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7691 - val_loss: 0.5100 - val_accuracy: 0.7292\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7674 - val_loss: 0.5098 - val_accuracy: 0.7292\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7674 - val_loss: 0.5096 - val_accuracy: 0.7292\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7674 - val_loss: 0.5094 - val_accuracy: 0.7292\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7674 - val_loss: 0.5092 - val_accuracy: 0.7292\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7674 - val_loss: 0.5090 - val_accuracy: 0.7292\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7674 - val_loss: 0.5088 - val_accuracy: 0.7292\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7674 - val_loss: 0.5086 - val_accuracy: 0.7292\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7674 - val_loss: 0.5085 - val_accuracy: 0.7292\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7674 - val_loss: 0.5083 - val_accuracy: 0.7292\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7691 - val_loss: 0.5081 - val_accuracy: 0.7292\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7691 - val_loss: 0.5079 - val_accuracy: 0.7292\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7691 - val_loss: 0.5077 - val_accuracy: 0.7344\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7691 - val_loss: 0.5076 - val_accuracy: 0.7344\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7691 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7691 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7691 - val_loss: 0.5071 - val_accuracy: 0.7344\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7691 - val_loss: 0.5069 - val_accuracy: 0.7344\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7691 - val_loss: 0.5067 - val_accuracy: 0.7344\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7691 - val_loss: 0.5065 - val_accuracy: 0.7344\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7691 - val_loss: 0.5064 - val_accuracy: 0.7344\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7691 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7691 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7674 - val_loss: 0.5059 - val_accuracy: 0.7344\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7674 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7674 - val_loss: 0.5056 - val_accuracy: 0.7344\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7674 - val_loss: 0.5055 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7674 - val_loss: 0.5053 - val_accuracy: 0.7344\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7674 - val_loss: 0.5052 - val_accuracy: 0.7344\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7674 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7674 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7674 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7691 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7691 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7691 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7691 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7691 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7708 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7708 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7708 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7708 - val_loss: 0.5038 - val_accuracy: 0.7396\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7708 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7691 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7708 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7691 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7691 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7691 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7691 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7691 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7691 - val_loss: 0.5029 - val_accuracy: 0.7396\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7691 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7691 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7691 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7674 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7691 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7691 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7674 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7708 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.7691 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7691 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7691 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7691 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7691 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7691 - val_loss: 0.5017 - val_accuracy: 0.7344\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7691 - val_loss: 0.5016 - val_accuracy: 0.7344\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7691 - val_loss: 0.5015 - val_accuracy: 0.7344\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7691 - val_loss: 0.5015 - val_accuracy: 0.7344\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7691 - val_loss: 0.5014 - val_accuracy: 0.7344\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7691 - val_loss: 0.5013 - val_accuracy: 0.7344\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7691 - val_loss: 0.5013 - val_accuracy: 0.7344\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7691 - val_loss: 0.5012 - val_accuracy: 0.7344\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7691 - val_loss: 0.5011 - val_accuracy: 0.7344\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7691 - val_loss: 0.5010 - val_accuracy: 0.7344\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.5010 - val_accuracy: 0.7448\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7691 - val_loss: 0.5009 - val_accuracy: 0.7448\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7691 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7691 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7691 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7691 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7691 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7691 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7691 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7691 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7691 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7691 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7708 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7691 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7691 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7691 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7691 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7674 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7691 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7708 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7674 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7691 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7708 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7691 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7691 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7691 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7691 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7691 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7674 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7708 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7691 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7708 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7691 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7708 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7708 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7708 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7708 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7708 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7726 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7726 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7726 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7726 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7743 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7743 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7743 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7743 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7726 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7726 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7743 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7726 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7743 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7726 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7760 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7726 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7743 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7743 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7726 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7708 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7708 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7708 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7708 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7726 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7691 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7726 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7726 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7691 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7726 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7726 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7708 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7708 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7691 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7708 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7691 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7691 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7691 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7691 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7691 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7708 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7726 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7726 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7743 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7847 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7847 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7865 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7847 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7847 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7847 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7812 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7847 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7847 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7847 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7847 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7847 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7847 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7830 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7830 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7812 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7847 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7865 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7812 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7847 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7812 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7812 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7847 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7812 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7847 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7812 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7812 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7812 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7865 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7830 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7847 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7899 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7899 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7899 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7882 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.4982 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7917 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7899 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7899 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7917 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4990 - val_accuracy: 0.7396\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4990 - val_accuracy: 0.7396\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7396\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7396\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7899 - val_loss: 0.4990 - val_accuracy: 0.7396\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7934 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7899 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7934 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7934 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7934 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7917 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7934 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1083/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7396\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7396\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7396\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7396\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7396\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7396\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7396\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7396\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7396\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7396\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7396\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7396\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7396\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7396\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7396\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7396\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7396\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7396\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7396\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7396\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7396\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.4999 - val_accuracy: 0.7396\n",
      "Epoch 1139/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.4999 - val_accuracy: 0.7396\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7396\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.4999 - val_accuracy: 0.7396\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.4999 - val_accuracy: 0.7396\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7396\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.5000 - val_accuracy: 0.7396\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7882 - val_loss: 0.5000 - val_accuracy: 0.7396\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7396\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7396\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7396\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7865 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7865 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7865 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7865 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.5003 - val_accuracy: 0.7396\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7865 - val_loss: 0.5003 - val_accuracy: 0.7396\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.5003 - val_accuracy: 0.7396\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.5003 - val_accuracy: 0.7396\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7396\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7396\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7396\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7865 - val_loss: 0.5005 - val_accuracy: 0.7396\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7396\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7396\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7865 - val_loss: 0.5006 - val_accuracy: 0.7396\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7396\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7865 - val_loss: 0.5006 - val_accuracy: 0.7396\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7396\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7396\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7396\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7396\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7396\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7396\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7396\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7396\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7396\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7396\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7396\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7865 - val_loss: 0.5008 - val_accuracy: 0.7396\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7396\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7396\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7396\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7396\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7865 - val_loss: 0.5009 - val_accuracy: 0.7396\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7396\n",
      "Epoch 1195/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7865 - val_loss: 0.5009 - val_accuracy: 0.7396\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7396\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7396\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7396\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7396\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7865 - val_loss: 0.5010 - val_accuracy: 0.7396\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7396\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7865 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7865 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7396\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 1251/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7951 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7951 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7934 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1307/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1363/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1419/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7986 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7986 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1475/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5026 - val_accuracy: 0.7396\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 1s 8ms/step - loss: 0.7211 - accuracy: 0.5417 - val_loss: 0.7163 - val_accuracy: 0.5729\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7096 - accuracy: 0.6059 - val_loss: 0.7079 - val_accuracy: 0.5885\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7012 - accuracy: 0.6267 - val_loss: 0.7006 - val_accuracy: 0.5990\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6458 - val_loss: 0.6935 - val_accuracy: 0.6146\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.6580 - val_loss: 0.6865 - val_accuracy: 0.6146\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.6580 - val_loss: 0.6785 - val_accuracy: 0.6146\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.6597 - val_loss: 0.6692 - val_accuracy: 0.6198\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6580 - val_loss: 0.6593 - val_accuracy: 0.6198\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.6562 - val_loss: 0.6476 - val_accuracy: 0.6302\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6304 - accuracy: 0.6580 - val_loss: 0.6368 - val_accuracy: 0.6302\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6597 - val_loss: 0.6259 - val_accuracy: 0.6302\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.6649 - val_loss: 0.6154 - val_accuracy: 0.6354\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.6667 - val_loss: 0.6058 - val_accuracy: 0.6354\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.6684 - val_loss: 0.5973 - val_accuracy: 0.6458\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.6684 - val_loss: 0.5894 - val_accuracy: 0.6458\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.6753 - val_loss: 0.5823 - val_accuracy: 0.6458\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.6771 - val_loss: 0.5763 - val_accuracy: 0.6354\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.6771 - val_loss: 0.5707 - val_accuracy: 0.6354\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.6892 - val_loss: 0.5656 - val_accuracy: 0.6354\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.6962 - val_loss: 0.5609 - val_accuracy: 0.6510\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.7049 - val_loss: 0.5566 - val_accuracy: 0.6719\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7153 - val_loss: 0.5530 - val_accuracy: 0.6875\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7326 - val_loss: 0.5490 - val_accuracy: 0.7031\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7396 - val_loss: 0.5455 - val_accuracy: 0.7135\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7448 - val_loss: 0.5421 - val_accuracy: 0.7083\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7378 - val_loss: 0.5392 - val_accuracy: 0.7031\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7413 - val_loss: 0.5364 - val_accuracy: 0.7031\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7483 - val_loss: 0.5342 - val_accuracy: 0.6979\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7500 - val_loss: 0.5320 - val_accuracy: 0.6927\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7517 - val_loss: 0.5302 - val_accuracy: 0.7292\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7604 - val_loss: 0.5288 - val_accuracy: 0.7292\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7622 - val_loss: 0.5279 - val_accuracy: 0.7240\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7656 - val_loss: 0.5269 - val_accuracy: 0.7344\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7743 - val_loss: 0.5262 - val_accuracy: 0.7344\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7778 - val_loss: 0.5257 - val_accuracy: 0.7396\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7795 - val_loss: 0.5256 - val_accuracy: 0.7344\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7760 - val_loss: 0.5253 - val_accuracy: 0.7344\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.5252 - val_accuracy: 0.7292\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7778 - val_loss: 0.5248 - val_accuracy: 0.7292\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.5244 - val_accuracy: 0.7292\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.5243 - val_accuracy: 0.7240\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7812 - val_loss: 0.5240 - val_accuracy: 0.7240\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7743 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.5237 - val_accuracy: 0.7292\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.5234 - val_accuracy: 0.7240\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.5231 - val_accuracy: 0.7292\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7812 - val_loss: 0.5231 - val_accuracy: 0.7292\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7292\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7292\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7240\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7292\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7292\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.5225 - val_accuracy: 0.7240\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7830 - val_loss: 0.5225 - val_accuracy: 0.7292\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7830 - val_loss: 0.5224 - val_accuracy: 0.7292\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7812 - val_loss: 0.5219 - val_accuracy: 0.7292\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7830 - val_loss: 0.5217 - val_accuracy: 0.7292\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7830 - val_loss: 0.5217 - val_accuracy: 0.7292\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7830 - val_loss: 0.5219 - val_accuracy: 0.7292\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7830 - val_loss: 0.5217 - val_accuracy: 0.7292\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7865 - val_loss: 0.5216 - val_accuracy: 0.7292\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7847 - val_loss: 0.5215 - val_accuracy: 0.7344\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7865 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7865 - val_loss: 0.5211 - val_accuracy: 0.7344\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7899 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7899 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7882 - val_loss: 0.5210 - val_accuracy: 0.7344\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7882 - val_loss: 0.5212 - val_accuracy: 0.7344\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7899 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7934 - val_loss: 0.5215 - val_accuracy: 0.7396\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.5216 - val_accuracy: 0.7344\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.5220 - val_accuracy: 0.7344\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.5224 - val_accuracy: 0.7344\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.5227 - val_accuracy: 0.7344\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.5233 - val_accuracy: 0.7292\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7899 - val_loss: 0.5236 - val_accuracy: 0.7292\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7934 - val_loss: 0.5241 - val_accuracy: 0.7292\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7934 - val_loss: 0.5245 - val_accuracy: 0.7344\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7934 - val_loss: 0.5250 - val_accuracy: 0.7396\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7934 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.5260 - val_accuracy: 0.7396\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7934 - val_loss: 0.5263 - val_accuracy: 0.7396\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.5267 - val_accuracy: 0.7448\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7951 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7969 - val_loss: 0.5278 - val_accuracy: 0.7396\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7969 - val_loss: 0.5282 - val_accuracy: 0.7396\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7951 - val_loss: 0.5284 - val_accuracy: 0.7396\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7951 - val_loss: 0.5290 - val_accuracy: 0.7396\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7969 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7986 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8003 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7986 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7986 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8021 - val_loss: 0.5324 - val_accuracy: 0.7344\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.8003 - val_loss: 0.5326 - val_accuracy: 0.7344\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8003 - val_loss: 0.5329 - val_accuracy: 0.7344\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.5332 - val_accuracy: 0.7292\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5336 - val_accuracy: 0.7292\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7951 - val_loss: 0.5337 - val_accuracy: 0.7292\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8003 - val_loss: 0.5340 - val_accuracy: 0.7292\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7986 - val_loss: 0.5342 - val_accuracy: 0.7292\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8003 - val_loss: 0.5345 - val_accuracy: 0.7292\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7969 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8003 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8003 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8003 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.8003 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8003 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8003 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.5375 - val_accuracy: 0.7240\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7969 - val_loss: 0.5377 - val_accuracy: 0.7240\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7951 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.5381 - val_accuracy: 0.7240\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7969 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7969 - val_loss: 0.5386 - val_accuracy: 0.7240\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7969 - val_loss: 0.5389 - val_accuracy: 0.7188\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8021 - val_loss: 0.5395 - val_accuracy: 0.7188\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7986 - val_loss: 0.5398 - val_accuracy: 0.7188\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7986 - val_loss: 0.5397 - val_accuracy: 0.7188\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.7934 - val_loss: 0.5399 - val_accuracy: 0.7188\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.5401 - val_accuracy: 0.7188\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8021 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5407 - val_accuracy: 0.7188\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7986 - val_loss: 0.5406 - val_accuracy: 0.7188\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7934 - val_loss: 0.5407 - val_accuracy: 0.7188\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7986 - val_loss: 0.5410 - val_accuracy: 0.7188\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8021 - val_loss: 0.5411 - val_accuracy: 0.7188\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.5415 - val_accuracy: 0.7135\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5415 - val_accuracy: 0.7135\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5415 - val_accuracy: 0.7135\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8003 - val_loss: 0.5418 - val_accuracy: 0.7135\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5419 - val_accuracy: 0.7135\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.8021 - val_loss: 0.5421 - val_accuracy: 0.7135\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8003 - val_loss: 0.5423 - val_accuracy: 0.7135\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8038 - val_loss: 0.5427 - val_accuracy: 0.7135\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.5427 - val_accuracy: 0.7135\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.8021 - val_loss: 0.5427 - val_accuracy: 0.7135\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8056 - val_loss: 0.5431 - val_accuracy: 0.7188\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8073 - val_loss: 0.5432 - val_accuracy: 0.7135\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8038 - val_loss: 0.5432 - val_accuracy: 0.7135\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8038 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8038 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8108 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8090 - val_loss: 0.5438 - val_accuracy: 0.7188\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8073 - val_loss: 0.5442 - val_accuracy: 0.7188\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.8073 - val_loss: 0.5443 - val_accuracy: 0.7188\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.8090 - val_loss: 0.5444 - val_accuracy: 0.7188\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8056 - val_loss: 0.5448 - val_accuracy: 0.7188\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8108 - val_loss: 0.5449 - val_accuracy: 0.7188\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.8073 - val_loss: 0.5449 - val_accuracy: 0.7188\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8108 - val_loss: 0.5452 - val_accuracy: 0.7188\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8073 - val_loss: 0.5452 - val_accuracy: 0.7188\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8090 - val_loss: 0.5452 - val_accuracy: 0.7188\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8038 - val_loss: 0.5450 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8108 - val_loss: 0.5452 - val_accuracy: 0.7188\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8090 - val_loss: 0.5454 - val_accuracy: 0.7188\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8073 - val_loss: 0.5454 - val_accuracy: 0.7188\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8073 - val_loss: 0.5455 - val_accuracy: 0.7188\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8108 - val_loss: 0.5454 - val_accuracy: 0.7188\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8108 - val_loss: 0.5455 - val_accuracy: 0.7188\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8125 - val_loss: 0.5453 - val_accuracy: 0.7188\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8090 - val_loss: 0.5454 - val_accuracy: 0.7188\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8108 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8090 - val_loss: 0.5456 - val_accuracy: 0.7240\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4414 - accuracy: 0.84 - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8108 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8090 - val_loss: 0.5457 - val_accuracy: 0.7188\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8090 - val_loss: 0.5453 - val_accuracy: 0.7188\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8108 - val_loss: 0.5452 - val_accuracy: 0.7188\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8090 - val_loss: 0.5456 - val_accuracy: 0.7188\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8073 - val_loss: 0.5455 - val_accuracy: 0.7188\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8090 - val_loss: 0.5455 - val_accuracy: 0.7188\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8108 - val_loss: 0.5452 - val_accuracy: 0.7188\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8108 - val_loss: 0.5456 - val_accuracy: 0.7240\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8125 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8090 - val_loss: 0.5454 - val_accuracy: 0.7240\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8090 - val_loss: 0.5453 - val_accuracy: 0.7240\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8056 - val_loss: 0.5451 - val_accuracy: 0.7240\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8142 - val_loss: 0.5453 - val_accuracy: 0.7240\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8142 - val_loss: 0.5456 - val_accuracy: 0.7240\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8142 - val_loss: 0.5456 - val_accuracy: 0.7240\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8125 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.8125 - val_loss: 0.5457 - val_accuracy: 0.7188\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8142 - val_loss: 0.5458 - val_accuracy: 0.7188\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8142 - val_loss: 0.5456 - val_accuracy: 0.7188\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8160 - val_loss: 0.5459 - val_accuracy: 0.7188\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8125 - val_loss: 0.5457 - val_accuracy: 0.7188\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8142 - val_loss: 0.5458 - val_accuracy: 0.7188\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8142 - val_loss: 0.5460 - val_accuracy: 0.7188\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8160 - val_loss: 0.5463 - val_accuracy: 0.7188\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8142 - val_loss: 0.5461 - val_accuracy: 0.7188\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8142 - val_loss: 0.5465 - val_accuracy: 0.7188\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8177 - val_loss: 0.5464 - val_accuracy: 0.7188\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8142 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8125 - val_loss: 0.5458 - val_accuracy: 0.7188\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8125 - val_loss: 0.5458 - val_accuracy: 0.7188\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8160 - val_loss: 0.5459 - val_accuracy: 0.7188\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8160 - val_loss: 0.5457 - val_accuracy: 0.7188\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8160 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8160 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8142 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8177 - val_loss: 0.5455 - val_accuracy: 0.7240\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8125 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8142 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8142 - val_loss: 0.5463 - val_accuracy: 0.7240\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8177 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8160 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8160 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8142 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8177 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8160 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 228/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8142 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8177 - val_loss: 0.5456 - val_accuracy: 0.7240\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8160 - val_loss: 0.5456 - val_accuracy: 0.7240\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8142 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8160 - val_loss: 0.5464 - val_accuracy: 0.7240\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8142 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8108 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8160 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8125 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8160 - val_loss: 0.5464 - val_accuracy: 0.7240\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8125 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8125 - val_loss: 0.5468 - val_accuracy: 0.7292\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8125 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8108 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8177 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8090 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8177 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8194 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8142 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8142 - val_loss: 0.5478 - val_accuracy: 0.7240\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8108 - val_loss: 0.5474 - val_accuracy: 0.7240\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.8142 - val_loss: 0.5477 - val_accuracy: 0.7240\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8160 - val_loss: 0.5480 - val_accuracy: 0.7292\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8160 - val_loss: 0.5483 - val_accuracy: 0.7292\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8142 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8177 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8125 - val_loss: 0.5490 - val_accuracy: 0.7292\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8177 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8177 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8160 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8125 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8142 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8194 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8160 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8177 - val_loss: 0.5496 - val_accuracy: 0.7292\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8194 - val_loss: 0.5494 - val_accuracy: 0.7344\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8177 - val_loss: 0.5493 - val_accuracy: 0.7344\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8142 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8160 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8177 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8177 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8177 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8177 - val_loss: 0.5497 - val_accuracy: 0.7240\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8160 - val_loss: 0.5497 - val_accuracy: 0.7240\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8177 - val_loss: 0.5504 - val_accuracy: 0.7240\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8177 - val_loss: 0.5500 - val_accuracy: 0.7240\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8160 - val_loss: 0.5502 - val_accuracy: 0.7240\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8160 - val_loss: 0.5500 - val_accuracy: 0.7344\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8160 - val_loss: 0.5503 - val_accuracy: 0.7292\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8160 - val_loss: 0.5503 - val_accuracy: 0.7344\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8160 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8177 - val_loss: 0.5505 - val_accuracy: 0.7344\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8160 - val_loss: 0.5507 - val_accuracy: 0.7344\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8160 - val_loss: 0.5506 - val_accuracy: 0.7344\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8142 - val_loss: 0.5506 - val_accuracy: 0.7344\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8177 - val_loss: 0.5506 - val_accuracy: 0.7344\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8177 - val_loss: 0.5513 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8194 - val_loss: 0.5509 - val_accuracy: 0.7344\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8177 - val_loss: 0.5511 - val_accuracy: 0.7396\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8212 - val_loss: 0.5516 - val_accuracy: 0.7344\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8212 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8194 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8194 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8177 - val_loss: 0.5519 - val_accuracy: 0.7396\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8194 - val_loss: 0.5520 - val_accuracy: 0.7396\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8212 - val_loss: 0.5523 - val_accuracy: 0.7396\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8194 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8212 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8194 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8212 - val_loss: 0.5522 - val_accuracy: 0.7396\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8212 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8212 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8212 - val_loss: 0.5535 - val_accuracy: 0.7396\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8212 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8212 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8229 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8229 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8247 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8194 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8247 - val_loss: 0.5527 - val_accuracy: 0.7396\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8264 - val_loss: 0.5530 - val_accuracy: 0.7396\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8247 - val_loss: 0.5527 - val_accuracy: 0.7396\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8247 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8247 - val_loss: 0.5536 - val_accuracy: 0.7396\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8247 - val_loss: 0.5541 - val_accuracy: 0.7396\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8247 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8247 - val_loss: 0.5537 - val_accuracy: 0.7396\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8247 - val_loss: 0.5535 - val_accuracy: 0.7396\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8229 - val_loss: 0.5537 - val_accuracy: 0.7396\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8229 - val_loss: 0.5539 - val_accuracy: 0.7396\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8229 - val_loss: 0.5544 - val_accuracy: 0.7396\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8229 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8229 - val_loss: 0.5544 - val_accuracy: 0.7396\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8229 - val_loss: 0.5551 - val_accuracy: 0.7396\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8229 - val_loss: 0.5547 - val_accuracy: 0.7396\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8247 - val_loss: 0.5547 - val_accuracy: 0.7396\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8212 - val_loss: 0.5550 - val_accuracy: 0.7396\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8229 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8212 - val_loss: 0.5550 - val_accuracy: 0.7396\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8229 - val_loss: 0.5552 - val_accuracy: 0.7448\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8229 - val_loss: 0.5554 - val_accuracy: 0.7448\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8229 - val_loss: 0.5558 - val_accuracy: 0.7448\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8212 - val_loss: 0.5560 - val_accuracy: 0.7500\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8229 - val_loss: 0.5561 - val_accuracy: 0.7448\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4047 - accuracy: 0.8229 - val_loss: 0.5559 - val_accuracy: 0.7448\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8229 - val_loss: 0.5559 - val_accuracy: 0.7448\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8212 - val_loss: 0.5561 - val_accuracy: 0.7448\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8229 - val_loss: 0.5556 - val_accuracy: 0.7448\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8264 - val_loss: 0.5559 - val_accuracy: 0.7448\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8247 - val_loss: 0.5563 - val_accuracy: 0.7500\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8229 - val_loss: 0.5568 - val_accuracy: 0.7448\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8264 - val_loss: 0.5571 - val_accuracy: 0.7448\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8229 - val_loss: 0.5564 - val_accuracy: 0.7448\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8247 - val_loss: 0.5566 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8247 - val_loss: 0.5570 - val_accuracy: 0.7448\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8247 - val_loss: 0.5575 - val_accuracy: 0.7448\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8264 - val_loss: 0.5573 - val_accuracy: 0.7500\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8264 - val_loss: 0.5576 - val_accuracy: 0.7448\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8264 - val_loss: 0.5576 - val_accuracy: 0.7448\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8264 - val_loss: 0.5579 - val_accuracy: 0.7448\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8247 - val_loss: 0.5578 - val_accuracy: 0.7448\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8247 - val_loss: 0.5584 - val_accuracy: 0.7500\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8247 - val_loss: 0.5583 - val_accuracy: 0.7500\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8247 - val_loss: 0.5586 - val_accuracy: 0.7448\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8264 - val_loss: 0.5593 - val_accuracy: 0.7448\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8247 - val_loss: 0.5589 - val_accuracy: 0.7448\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8229 - val_loss: 0.5585 - val_accuracy: 0.7448\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8247 - val_loss: 0.5591 - val_accuracy: 0.7396\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8229 - val_loss: 0.5598 - val_accuracy: 0.7396\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8247 - val_loss: 0.5597 - val_accuracy: 0.7448\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8212 - val_loss: 0.5594 - val_accuracy: 0.7396\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8229 - val_loss: 0.5597 - val_accuracy: 0.7396\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8247 - val_loss: 0.5604 - val_accuracy: 0.7344\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8247 - val_loss: 0.5603 - val_accuracy: 0.7344\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8247 - val_loss: 0.5600 - val_accuracy: 0.7396\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8264 - val_loss: 0.5600 - val_accuracy: 0.7344\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8281 - val_loss: 0.5610 - val_accuracy: 0.7344\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8247 - val_loss: 0.5609 - val_accuracy: 0.7344\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8264 - val_loss: 0.5614 - val_accuracy: 0.7344\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8229 - val_loss: 0.5611 - val_accuracy: 0.7344\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8229 - val_loss: 0.5614 - val_accuracy: 0.7396\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.8247 - val_loss: 0.5617 - val_accuracy: 0.7396\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8247 - val_loss: 0.5618 - val_accuracy: 0.7396\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8247 - val_loss: 0.5622 - val_accuracy: 0.7396\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8264 - val_loss: 0.5620 - val_accuracy: 0.7448\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8229 - val_loss: 0.5620 - val_accuracy: 0.7396\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8264 - val_loss: 0.5622 - val_accuracy: 0.7396\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8264 - val_loss: 0.5624 - val_accuracy: 0.7396\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8229 - val_loss: 0.5626 - val_accuracy: 0.7448\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8247 - val_loss: 0.5626 - val_accuracy: 0.7344\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8229 - val_loss: 0.5632 - val_accuracy: 0.7344\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8264 - val_loss: 0.5637 - val_accuracy: 0.7396\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8247 - val_loss: 0.5625 - val_accuracy: 0.7396\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8229 - val_loss: 0.5632 - val_accuracy: 0.7396\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8264 - val_loss: 0.5632 - val_accuracy: 0.7344\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8264 - val_loss: 0.5635 - val_accuracy: 0.7292\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3999 - accuracy: 0.8229 - val_loss: 0.5636 - val_accuracy: 0.7188\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8229 - val_loss: 0.5633 - val_accuracy: 0.7188\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8264 - val_loss: 0.5635 - val_accuracy: 0.7240\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8247 - val_loss: 0.5629 - val_accuracy: 0.7292\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8264 - val_loss: 0.5632 - val_accuracy: 0.7292\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3994 - accuracy: 0.8264 - val_loss: 0.5646 - val_accuracy: 0.7292\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8247 - val_loss: 0.5645 - val_accuracy: 0.7240\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8264 - val_loss: 0.5643 - val_accuracy: 0.7240\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8247 - val_loss: 0.5648 - val_accuracy: 0.7240\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8229 - val_loss: 0.5651 - val_accuracy: 0.7240\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8247 - val_loss: 0.5647 - val_accuracy: 0.7240\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8264 - val_loss: 0.5647 - val_accuracy: 0.7240\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8264 - val_loss: 0.5646 - val_accuracy: 0.7240\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8299 - val_loss: 0.5641 - val_accuracy: 0.7240\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8264 - val_loss: 0.5644 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8264 - val_loss: 0.5649 - val_accuracy: 0.7240\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8247 - val_loss: 0.5640 - val_accuracy: 0.7240\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3974 - accuracy: 0.8264 - val_loss: 0.5647 - val_accuracy: 0.7240\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8299 - val_loss: 0.5648 - val_accuracy: 0.7292\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8299 - val_loss: 0.5645 - val_accuracy: 0.7292\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8281 - val_loss: 0.5645 - val_accuracy: 0.7292\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8281 - val_loss: 0.5649 - val_accuracy: 0.7292\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8316 - val_loss: 0.5651 - val_accuracy: 0.7292\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8316 - val_loss: 0.5649 - val_accuracy: 0.7240\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8299 - val_loss: 0.5657 - val_accuracy: 0.7240\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8299 - val_loss: 0.5659 - val_accuracy: 0.7240\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8299 - val_loss: 0.5659 - val_accuracy: 0.7240\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8247 - val_loss: 0.5665 - val_accuracy: 0.7292\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8281 - val_loss: 0.5669 - val_accuracy: 0.7292\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8264 - val_loss: 0.5665 - val_accuracy: 0.7240\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8299 - val_loss: 0.5660 - val_accuracy: 0.7240\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8264 - val_loss: 0.5661 - val_accuracy: 0.7240\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8281 - val_loss: 0.5657 - val_accuracy: 0.7292\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8299 - val_loss: 0.5661 - val_accuracy: 0.7188\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8316 - val_loss: 0.5660 - val_accuracy: 0.7292\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8299 - val_loss: 0.5662 - val_accuracy: 0.7292\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8299 - val_loss: 0.5661 - val_accuracy: 0.7292\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8264 - val_loss: 0.5661 - val_accuracy: 0.7292\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8264 - val_loss: 0.5663 - val_accuracy: 0.7292\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8264 - val_loss: 0.5670 - val_accuracy: 0.7292\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8281 - val_loss: 0.5672 - val_accuracy: 0.7344\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8299 - val_loss: 0.5673 - val_accuracy: 0.7292\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8299 - val_loss: 0.5673 - val_accuracy: 0.7292\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8299 - val_loss: 0.5666 - val_accuracy: 0.7292\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8299 - val_loss: 0.5665 - val_accuracy: 0.7344\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8264 - val_loss: 0.5666 - val_accuracy: 0.7292\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8281 - val_loss: 0.5672 - val_accuracy: 0.7292\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8316 - val_loss: 0.5662 - val_accuracy: 0.7292\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8281 - val_loss: 0.5671 - val_accuracy: 0.7292\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8316 - val_loss: 0.5669 - val_accuracy: 0.7240\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8299 - val_loss: 0.5670 - val_accuracy: 0.7292\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8281 - val_loss: 0.5674 - val_accuracy: 0.7240\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8316 - val_loss: 0.5672 - val_accuracy: 0.7188\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8299 - val_loss: 0.5676 - val_accuracy: 0.7188\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8316 - val_loss: 0.5680 - val_accuracy: 0.7240\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8281 - val_loss: 0.5680 - val_accuracy: 0.7240\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8264 - val_loss: 0.5677 - val_accuracy: 0.7292\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8299 - val_loss: 0.5684 - val_accuracy: 0.7188\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8316 - val_loss: 0.5682 - val_accuracy: 0.7188\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8299 - val_loss: 0.5689 - val_accuracy: 0.7188\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3928 - accuracy: 0.8299 - val_loss: 0.5688 - val_accuracy: 0.7188\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8281 - val_loss: 0.5690 - val_accuracy: 0.7188\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8299 - val_loss: 0.5693 - val_accuracy: 0.7188\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8299 - val_loss: 0.5692 - val_accuracy: 0.7188\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8333 - val_loss: 0.5687 - val_accuracy: 0.7240\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8281 - val_loss: 0.5690 - val_accuracy: 0.7188\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8281 - val_loss: 0.5688 - val_accuracy: 0.7188\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8316 - val_loss: 0.5690 - val_accuracy: 0.7188\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8299 - val_loss: 0.5687 - val_accuracy: 0.7292\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8299 - val_loss: 0.5688 - val_accuracy: 0.7188\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.8333 - val_loss: 0.5684 - val_accuracy: 0.7188\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8281 - val_loss: 0.5689 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8316 - val_loss: 0.5688 - val_accuracy: 0.7188\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8299 - val_loss: 0.5692 - val_accuracy: 0.7188\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3916 - accuracy: 0.8264 - val_loss: 0.5689 - val_accuracy: 0.7240\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8299 - val_loss: 0.5697 - val_accuracy: 0.7292\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8281 - val_loss: 0.5693 - val_accuracy: 0.7240\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8281 - val_loss: 0.5685 - val_accuracy: 0.7240\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8299 - val_loss: 0.5684 - val_accuracy: 0.7292\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8299 - val_loss: 0.5688 - val_accuracy: 0.7240\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3913 - accuracy: 0.8299 - val_loss: 0.5694 - val_accuracy: 0.7240\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8299 - val_loss: 0.5690 - val_accuracy: 0.7240\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8299 - val_loss: 0.5691 - val_accuracy: 0.7292\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3916 - accuracy: 0.8264 - val_loss: 0.5692 - val_accuracy: 0.7292\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8316 - val_loss: 0.5693 - val_accuracy: 0.7292\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8281 - val_loss: 0.5693 - val_accuracy: 0.7292\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8281 - val_loss: 0.5693 - val_accuracy: 0.7292\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8281 - val_loss: 0.5684 - val_accuracy: 0.7344\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8247 - val_loss: 0.5684 - val_accuracy: 0.7292\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8264 - val_loss: 0.5683 - val_accuracy: 0.7292\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8247 - val_loss: 0.5687 - val_accuracy: 0.7292\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8264 - val_loss: 0.5697 - val_accuracy: 0.7396\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8264 - val_loss: 0.5688 - val_accuracy: 0.7292\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8299 - val_loss: 0.5693 - val_accuracy: 0.7396\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8264 - val_loss: 0.5696 - val_accuracy: 0.7448\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.8229 - val_loss: 0.5703 - val_accuracy: 0.7500\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8247 - val_loss: 0.5696 - val_accuracy: 0.7500\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8281 - val_loss: 0.5691 - val_accuracy: 0.7500\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8299 - val_loss: 0.5692 - val_accuracy: 0.7448\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8264 - val_loss: 0.5702 - val_accuracy: 0.7448\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8212 - val_loss: 0.5692 - val_accuracy: 0.7396\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8299 - val_loss: 0.5698 - val_accuracy: 0.7396\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8247 - val_loss: 0.5695 - val_accuracy: 0.7448\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8299 - val_loss: 0.5690 - val_accuracy: 0.7448\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8281 - val_loss: 0.5687 - val_accuracy: 0.7448\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8281 - val_loss: 0.5686 - val_accuracy: 0.7396\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3900 - accuracy: 0.8281 - val_loss: 0.5687 - val_accuracy: 0.7500\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8299 - val_loss: 0.5694 - val_accuracy: 0.7500\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8299 - val_loss: 0.5700 - val_accuracy: 0.7396\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8281 - val_loss: 0.5700 - val_accuracy: 0.7500\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8281 - val_loss: 0.5688 - val_accuracy: 0.7500\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8316 - val_loss: 0.5685 - val_accuracy: 0.7500\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8299 - val_loss: 0.5700 - val_accuracy: 0.7448\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8247 - val_loss: 0.5693 - val_accuracy: 0.7448\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8299 - val_loss: 0.5692 - val_accuracy: 0.7448\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8316 - val_loss: 0.5698 - val_accuracy: 0.7448\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8299 - val_loss: 0.5694 - val_accuracy: 0.7448\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8264 - val_loss: 0.5690 - val_accuracy: 0.7500\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8316 - val_loss: 0.5690 - val_accuracy: 0.7500\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8229 - val_loss: 0.5686 - val_accuracy: 0.7500\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8299 - val_loss: 0.5691 - val_accuracy: 0.7500\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8281 - val_loss: 0.5698 - val_accuracy: 0.7500\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8264 - val_loss: 0.5696 - val_accuracy: 0.7500\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8264 - val_loss: 0.5686 - val_accuracy: 0.7448\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8281 - val_loss: 0.5689 - val_accuracy: 0.7500\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8247 - val_loss: 0.5692 - val_accuracy: 0.7500\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8333 - val_loss: 0.5701 - val_accuracy: 0.7500\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8316 - val_loss: 0.5694 - val_accuracy: 0.7500\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8264 - val_loss: 0.5697 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8281 - val_loss: 0.5691 - val_accuracy: 0.7500\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8316 - val_loss: 0.5696 - val_accuracy: 0.7500\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8264 - val_loss: 0.5685 - val_accuracy: 0.7500\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8299 - val_loss: 0.5683 - val_accuracy: 0.7500\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8316 - val_loss: 0.5681 - val_accuracy: 0.7500\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8247 - val_loss: 0.5674 - val_accuracy: 0.7552\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8281 - val_loss: 0.5673 - val_accuracy: 0.7500\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8264 - val_loss: 0.5678 - val_accuracy: 0.7500\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8281 - val_loss: 0.5690 - val_accuracy: 0.7500\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8281 - val_loss: 0.5686 - val_accuracy: 0.7500\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8247 - val_loss: 0.5684 - val_accuracy: 0.7500\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8264 - val_loss: 0.5686 - val_accuracy: 0.7552\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8264 - val_loss: 0.5682 - val_accuracy: 0.7552\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8299 - val_loss: 0.5675 - val_accuracy: 0.7500\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8264 - val_loss: 0.5682 - val_accuracy: 0.7500\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8299 - val_loss: 0.5681 - val_accuracy: 0.7500\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4700 - accuracy: 0.75 - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8333 - val_loss: 0.5684 - val_accuracy: 0.7500\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8247 - val_loss: 0.5683 - val_accuracy: 0.7500\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8316 - val_loss: 0.5685 - val_accuracy: 0.7500\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8316 - val_loss: 0.5689 - val_accuracy: 0.7500\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8264 - val_loss: 0.5693 - val_accuracy: 0.7500\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8281 - val_loss: 0.5687 - val_accuracy: 0.7500\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8281 - val_loss: 0.5686 - val_accuracy: 0.7500\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8247 - val_loss: 0.5685 - val_accuracy: 0.7500\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3871 - accuracy: 0.8299 - val_loss: 0.5688 - val_accuracy: 0.7448\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8299 - val_loss: 0.5691 - val_accuracy: 0.7500\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8247 - val_loss: 0.5688 - val_accuracy: 0.7448\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8247 - val_loss: 0.5689 - val_accuracy: 0.7448\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8299 - val_loss: 0.5688 - val_accuracy: 0.7448\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8264 - val_loss: 0.5684 - val_accuracy: 0.7448\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8264 - val_loss: 0.5688 - val_accuracy: 0.7448\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8264 - val_loss: 0.5684 - val_accuracy: 0.7448\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8247 - val_loss: 0.5686 - val_accuracy: 0.7448\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8299 - val_loss: 0.5690 - val_accuracy: 0.7448\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8264 - val_loss: 0.5695 - val_accuracy: 0.7448\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8264 - val_loss: 0.5690 - val_accuracy: 0.7448\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8316 - val_loss: 0.5690 - val_accuracy: 0.7448\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8247 - val_loss: 0.5701 - val_accuracy: 0.7448\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8281 - val_loss: 0.5700 - val_accuracy: 0.7448\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8264 - val_loss: 0.5703 - val_accuracy: 0.7448\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8299 - val_loss: 0.5696 - val_accuracy: 0.7448\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8281 - val_loss: 0.5704 - val_accuracy: 0.7448\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8247 - val_loss: 0.5703 - val_accuracy: 0.7448\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8299 - val_loss: 0.5698 - val_accuracy: 0.7448\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8247 - val_loss: 0.5701 - val_accuracy: 0.7448\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8264 - val_loss: 0.5704 - val_accuracy: 0.7448\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8281 - val_loss: 0.5706 - val_accuracy: 0.7448\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8299 - val_loss: 0.5700 - val_accuracy: 0.7448\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8247 - val_loss: 0.5700 - val_accuracy: 0.7448\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8281 - val_loss: 0.5709 - val_accuracy: 0.7448\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8229 - val_loss: 0.5699 - val_accuracy: 0.7448\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8299 - val_loss: 0.5707 - val_accuracy: 0.7448\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8299 - val_loss: 0.5697 - val_accuracy: 0.7448\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3863 - accuracy: 0.8247 - val_loss: 0.5708 - val_accuracy: 0.7344\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8247 - val_loss: 0.5707 - val_accuracy: 0.7396\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8264 - val_loss: 0.5715 - val_accuracy: 0.7396\n",
      "Epoch 569/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8316 - val_loss: 0.5715 - val_accuracy: 0.7344\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8264 - val_loss: 0.5716 - val_accuracy: 0.7344\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8316 - val_loss: 0.5714 - val_accuracy: 0.7344\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8264 - val_loss: 0.5707 - val_accuracy: 0.7344\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8281 - val_loss: 0.5718 - val_accuracy: 0.7344\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3854 - accuracy: 0.8247 - val_loss: 0.5720 - val_accuracy: 0.7396\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3856 - accuracy: 0.8212 - val_loss: 0.5715 - val_accuracy: 0.7344\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8229 - val_loss: 0.5722 - val_accuracy: 0.7344\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8247 - val_loss: 0.5710 - val_accuracy: 0.7396\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8247 - val_loss: 0.5712 - val_accuracy: 0.7396\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8281 - val_loss: 0.5718 - val_accuracy: 0.7396\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8247 - val_loss: 0.5721 - val_accuracy: 0.7344\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8229 - val_loss: 0.5728 - val_accuracy: 0.7344\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8247 - val_loss: 0.5716 - val_accuracy: 0.7344\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8281 - val_loss: 0.5730 - val_accuracy: 0.7396\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8247 - val_loss: 0.5734 - val_accuracy: 0.7344\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8247 - val_loss: 0.5728 - val_accuracy: 0.7396\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8316 - val_loss: 0.5737 - val_accuracy: 0.7344\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8264 - val_loss: 0.5736 - val_accuracy: 0.7344\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8247 - val_loss: 0.5720 - val_accuracy: 0.7344\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8281 - val_loss: 0.5725 - val_accuracy: 0.7344\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8264 - val_loss: 0.5739 - val_accuracy: 0.7344\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8281 - val_loss: 0.5726 - val_accuracy: 0.7344\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8281 - val_loss: 0.5720 - val_accuracy: 0.7396\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8299 - val_loss: 0.5723 - val_accuracy: 0.7344\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8264 - val_loss: 0.5731 - val_accuracy: 0.7344\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8281 - val_loss: 0.5734 - val_accuracy: 0.7344\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8299 - val_loss: 0.5729 - val_accuracy: 0.7344\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8299 - val_loss: 0.5738 - val_accuracy: 0.7344\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8299 - val_loss: 0.5736 - val_accuracy: 0.7344\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8299 - val_loss: 0.5730 - val_accuracy: 0.7344\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8264 - val_loss: 0.5726 - val_accuracy: 0.7344\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8299 - val_loss: 0.5735 - val_accuracy: 0.7344\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3841 - accuracy: 0.8299 - val_loss: 0.5729 - val_accuracy: 0.7344\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8264 - val_loss: 0.5741 - val_accuracy: 0.7344\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8247 - val_loss: 0.5735 - val_accuracy: 0.7344\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8281 - val_loss: 0.5741 - val_accuracy: 0.7344\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8281 - val_loss: 0.5729 - val_accuracy: 0.7344\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8316 - val_loss: 0.5725 - val_accuracy: 0.7344\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8299 - val_loss: 0.5714 - val_accuracy: 0.7344\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8264 - val_loss: 0.5723 - val_accuracy: 0.7344\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8281 - val_loss: 0.5717 - val_accuracy: 0.7344\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8333 - val_loss: 0.5723 - val_accuracy: 0.7344\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8333 - val_loss: 0.5720 - val_accuracy: 0.7344\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8264 - val_loss: 0.5722 - val_accuracy: 0.7344\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8316 - val_loss: 0.5729 - val_accuracy: 0.7344\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8281 - val_loss: 0.5719 - val_accuracy: 0.7344\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8299 - val_loss: 0.5718 - val_accuracy: 0.7344\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8299 - val_loss: 0.5721 - val_accuracy: 0.7344\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8299 - val_loss: 0.5729 - val_accuracy: 0.7344\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8299 - val_loss: 0.5727 - val_accuracy: 0.7344\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8264 - val_loss: 0.5726 - val_accuracy: 0.7344\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8264 - val_loss: 0.5733 - val_accuracy: 0.7344\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8299 - val_loss: 0.5728 - val_accuracy: 0.7344\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8316 - val_loss: 0.5732 - val_accuracy: 0.7344\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8299 - val_loss: 0.5740 - val_accuracy: 0.7344\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8316 - val_loss: 0.5734 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8299 - val_loss: 0.5729 - val_accuracy: 0.7344\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8281 - val_loss: 0.5728 - val_accuracy: 0.7344\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8316 - val_loss: 0.5731 - val_accuracy: 0.7344\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8299 - val_loss: 0.5740 - val_accuracy: 0.7344\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8281 - val_loss: 0.5730 - val_accuracy: 0.7344\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8281 - val_loss: 0.5747 - val_accuracy: 0.7344\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8264 - val_loss: 0.5743 - val_accuracy: 0.7344\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8333 - val_loss: 0.5734 - val_accuracy: 0.7344\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8299 - val_loss: 0.5741 - val_accuracy: 0.7344\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8316 - val_loss: 0.5746 - val_accuracy: 0.7344\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8264 - val_loss: 0.5749 - val_accuracy: 0.7344\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8264 - val_loss: 0.5739 - val_accuracy: 0.7344\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8281 - val_loss: 0.5731 - val_accuracy: 0.7344\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8299 - val_loss: 0.5735 - val_accuracy: 0.7344\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8299 - val_loss: 0.5746 - val_accuracy: 0.7448\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8264 - val_loss: 0.5739 - val_accuracy: 0.7344\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8299 - val_loss: 0.5729 - val_accuracy: 0.7344\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8351 - val_loss: 0.5741 - val_accuracy: 0.7448\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8351 - val_loss: 0.5747 - val_accuracy: 0.7448\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8316 - val_loss: 0.5743 - val_accuracy: 0.7448\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8333 - val_loss: 0.5741 - val_accuracy: 0.7448\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8333 - val_loss: 0.5737 - val_accuracy: 0.7448\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8351 - val_loss: 0.5742 - val_accuracy: 0.7448\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8351 - val_loss: 0.5743 - val_accuracy: 0.7448\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8333 - val_loss: 0.5745 - val_accuracy: 0.7448\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8351 - val_loss: 0.5747 - val_accuracy: 0.7448\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8316 - val_loss: 0.5753 - val_accuracy: 0.7448\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8333 - val_loss: 0.5760 - val_accuracy: 0.7448\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8351 - val_loss: 0.5751 - val_accuracy: 0.7448\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8333 - val_loss: 0.5739 - val_accuracy: 0.7448\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8385 - val_loss: 0.5738 - val_accuracy: 0.7448\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8368 - val_loss: 0.5738 - val_accuracy: 0.7396\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8333 - val_loss: 0.5755 - val_accuracy: 0.7448\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8351 - val_loss: 0.5767 - val_accuracy: 0.7448\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8299 - val_loss: 0.5750 - val_accuracy: 0.7448\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8385 - val_loss: 0.5763 - val_accuracy: 0.7448\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8351 - val_loss: 0.5760 - val_accuracy: 0.7448\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8333 - val_loss: 0.5753 - val_accuracy: 0.7448\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8351 - val_loss: 0.5762 - val_accuracy: 0.7448\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8368 - val_loss: 0.5769 - val_accuracy: 0.7448\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8351 - val_loss: 0.5755 - val_accuracy: 0.7396\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3818 - accuracy: 0.8316 - val_loss: 0.5754 - val_accuracy: 0.7396\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8368 - val_loss: 0.5752 - val_accuracy: 0.7396\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8368 - val_loss: 0.5752 - val_accuracy: 0.7396\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8368 - val_loss: 0.5751 - val_accuracy: 0.7396\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8333 - val_loss: 0.5743 - val_accuracy: 0.7396\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8368 - val_loss: 0.5731 - val_accuracy: 0.7396\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8385 - val_loss: 0.5752 - val_accuracy: 0.7396\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8351 - val_loss: 0.5746 - val_accuracy: 0.7396\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8351 - val_loss: 0.5741 - val_accuracy: 0.7396\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8351 - val_loss: 0.5754 - val_accuracy: 0.7396\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8351 - val_loss: 0.5764 - val_accuracy: 0.7396\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8368 - val_loss: 0.5759 - val_accuracy: 0.7396\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8351 - val_loss: 0.5758 - val_accuracy: 0.7396\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8333 - val_loss: 0.5760 - val_accuracy: 0.7396\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8351 - val_loss: 0.5743 - val_accuracy: 0.7396\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8351 - val_loss: 0.5745 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8351 - val_loss: 0.5749 - val_accuracy: 0.7396\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8403 - val_loss: 0.5732 - val_accuracy: 0.7396\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8351 - val_loss: 0.5734 - val_accuracy: 0.7396\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8368 - val_loss: 0.5749 - val_accuracy: 0.7396\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8351 - val_loss: 0.5743 - val_accuracy: 0.7396\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3811 - accuracy: 0.8351 - val_loss: 0.5751 - val_accuracy: 0.7396\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8368 - val_loss: 0.5746 - val_accuracy: 0.7396\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8385 - val_loss: 0.5753 - val_accuracy: 0.7396\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8368 - val_loss: 0.5756 - val_accuracy: 0.7396\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8351 - val_loss: 0.5749 - val_accuracy: 0.7396\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8368 - val_loss: 0.5746 - val_accuracy: 0.7396\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8368 - val_loss: 0.5741 - val_accuracy: 0.7396\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8368 - val_loss: 0.5739 - val_accuracy: 0.7396\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8368 - val_loss: 0.5741 - val_accuracy: 0.7396\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8351 - val_loss: 0.5738 - val_accuracy: 0.7396\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8385 - val_loss: 0.5747 - val_accuracy: 0.7396\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8403 - val_loss: 0.5753 - val_accuracy: 0.7396\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8333 - val_loss: 0.5757 - val_accuracy: 0.7344\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8351 - val_loss: 0.5754 - val_accuracy: 0.7396\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3809 - accuracy: 0.8351 - val_loss: 0.5760 - val_accuracy: 0.7344\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8368 - val_loss: 0.5758 - val_accuracy: 0.7396\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8368 - val_loss: 0.5747 - val_accuracy: 0.7344\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8351 - val_loss: 0.5764 - val_accuracy: 0.7344\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8351 - val_loss: 0.5769 - val_accuracy: 0.7344\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8368 - val_loss: 0.5763 - val_accuracy: 0.7396\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8368 - val_loss: 0.5755 - val_accuracy: 0.7344\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3804 - accuracy: 0.8368 - val_loss: 0.5761 - val_accuracy: 0.7344\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8351 - val_loss: 0.5776 - val_accuracy: 0.7344\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8368 - val_loss: 0.5757 - val_accuracy: 0.7344\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8403 - val_loss: 0.5769 - val_accuracy: 0.7344\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8351 - val_loss: 0.5748 - val_accuracy: 0.7344\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8368 - val_loss: 0.5757 - val_accuracy: 0.7344\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8368 - val_loss: 0.5751 - val_accuracy: 0.7396\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8368 - val_loss: 0.5749 - val_accuracy: 0.7344\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8351 - val_loss: 0.5745 - val_accuracy: 0.7344\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8351 - val_loss: 0.5765 - val_accuracy: 0.7344\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3803 - accuracy: 0.8368 - val_loss: 0.5761 - val_accuracy: 0.7344\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8385 - val_loss: 0.5756 - val_accuracy: 0.7344\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8403 - val_loss: 0.5754 - val_accuracy: 0.7396\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8368 - val_loss: 0.5747 - val_accuracy: 0.7344\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8385 - val_loss: 0.5762 - val_accuracy: 0.7344\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8368 - val_loss: 0.5759 - val_accuracy: 0.7344\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8351 - val_loss: 0.5767 - val_accuracy: 0.7344\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8351 - val_loss: 0.5773 - val_accuracy: 0.7344\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8351 - val_loss: 0.5766 - val_accuracy: 0.7344\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8385 - val_loss: 0.5766 - val_accuracy: 0.7344\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3802 - accuracy: 0.8368 - val_loss: 0.5761 - val_accuracy: 0.7344\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8385 - val_loss: 0.5763 - val_accuracy: 0.7344\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8368 - val_loss: 0.5764 - val_accuracy: 0.7344\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8368 - val_loss: 0.5771 - val_accuracy: 0.7344\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8333 - val_loss: 0.5766 - val_accuracy: 0.7344\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8368 - val_loss: 0.5784 - val_accuracy: 0.7344\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8368 - val_loss: 0.5771 - val_accuracy: 0.7344\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8368 - val_loss: 0.5765 - val_accuracy: 0.7344\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3799 - accuracy: 0.8351 - val_loss: 0.5773 - val_accuracy: 0.7344\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8403 - val_loss: 0.5755 - val_accuracy: 0.7344\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8333 - val_loss: 0.5769 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8333 - val_loss: 0.5768 - val_accuracy: 0.7344\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8333 - val_loss: 0.5773 - val_accuracy: 0.7344\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8385 - val_loss: 0.5763 - val_accuracy: 0.7344\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8351 - val_loss: 0.5772 - val_accuracy: 0.7344\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8368 - val_loss: 0.5768 - val_accuracy: 0.7344\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8368 - val_loss: 0.5766 - val_accuracy: 0.7344\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8333 - val_loss: 0.5765 - val_accuracy: 0.7344\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8385 - val_loss: 0.5776 - val_accuracy: 0.7344\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8351 - val_loss: 0.5769 - val_accuracy: 0.7344\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.8351 - val_loss: 0.5759 - val_accuracy: 0.7344\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8368 - val_loss: 0.5767 - val_accuracy: 0.7344\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8368 - val_loss: 0.5761 - val_accuracy: 0.7344\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8333 - val_loss: 0.5766 - val_accuracy: 0.7344\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8333 - val_loss: 0.5774 - val_accuracy: 0.7344\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8385 - val_loss: 0.5778 - val_accuracy: 0.7344\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8351 - val_loss: 0.5766 - val_accuracy: 0.7344\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8333 - val_loss: 0.5783 - val_accuracy: 0.7344\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8351 - val_loss: 0.5784 - val_accuracy: 0.7344\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8351 - val_loss: 0.5789 - val_accuracy: 0.7344\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8385 - val_loss: 0.5785 - val_accuracy: 0.7344\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3794 - accuracy: 0.8351 - val_loss: 0.5772 - val_accuracy: 0.7344\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.8368 - val_loss: 0.5772 - val_accuracy: 0.7292\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8368 - val_loss: 0.5759 - val_accuracy: 0.7344\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.8385 - val_loss: 0.5773 - val_accuracy: 0.7344\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8368 - val_loss: 0.5750 - val_accuracy: 0.7344\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8368 - val_loss: 0.5763 - val_accuracy: 0.7344\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8368 - val_loss: 0.5768 - val_accuracy: 0.7344\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8351 - val_loss: 0.5752 - val_accuracy: 0.7344\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8368 - val_loss: 0.5765 - val_accuracy: 0.7344\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8368 - val_loss: 0.5760 - val_accuracy: 0.7292\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8351 - val_loss: 0.5766 - val_accuracy: 0.7292\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8368 - val_loss: 0.5755 - val_accuracy: 0.7292\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8385 - val_loss: 0.5764 - val_accuracy: 0.7292\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8351 - val_loss: 0.5777 - val_accuracy: 0.7292\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8316 - val_loss: 0.5769 - val_accuracy: 0.7292\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8351 - val_loss: 0.5758 - val_accuracy: 0.7292\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8403 - val_loss: 0.5780 - val_accuracy: 0.7292\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8351 - val_loss: 0.5779 - val_accuracy: 0.7292\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8368 - val_loss: 0.5780 - val_accuracy: 0.7292\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8368 - val_loss: 0.5770 - val_accuracy: 0.7292\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8368 - val_loss: 0.5774 - val_accuracy: 0.7292\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8368 - val_loss: 0.5770 - val_accuracy: 0.7292\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8368 - val_loss: 0.5777 - val_accuracy: 0.7292\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8385 - val_loss: 0.5769 - val_accuracy: 0.7292\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8385 - val_loss: 0.5777 - val_accuracy: 0.7292\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8368 - val_loss: 0.5784 - val_accuracy: 0.7292\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8351 - val_loss: 0.5781 - val_accuracy: 0.7292\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3794 - accuracy: 0.8368 - val_loss: 0.5774 - val_accuracy: 0.7292\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8368 - val_loss: 0.5774 - val_accuracy: 0.7292\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8351 - val_loss: 0.5786 - val_accuracy: 0.7292\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8351 - val_loss: 0.5771 - val_accuracy: 0.7292\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8385 - val_loss: 0.5770 - val_accuracy: 0.7292\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8368 - val_loss: 0.5764 - val_accuracy: 0.7292\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8368 - val_loss: 0.5759 - val_accuracy: 0.7344\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8333 - val_loss: 0.5782 - val_accuracy: 0.7292\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8368 - val_loss: 0.5796 - val_accuracy: 0.7292\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8385 - val_loss: 0.5783 - val_accuracy: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8385 - val_loss: 0.5785 - val_accuracy: 0.7292\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8351 - val_loss: 0.5781 - val_accuracy: 0.7292\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8333 - val_loss: 0.5774 - val_accuracy: 0.7292\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8333 - val_loss: 0.5780 - val_accuracy: 0.7292\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8368 - val_loss: 0.5795 - val_accuracy: 0.7292\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8385 - val_loss: 0.5774 - val_accuracy: 0.7292\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8385 - val_loss: 0.5791 - val_accuracy: 0.7292\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8351 - val_loss: 0.5777 - val_accuracy: 0.7292\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8368 - val_loss: 0.5792 - val_accuracy: 0.7292\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3787 - accuracy: 0.8385 - val_loss: 0.5775 - val_accuracy: 0.7292\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8368 - val_loss: 0.5772 - val_accuracy: 0.7292\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8368 - val_loss: 0.5792 - val_accuracy: 0.7292\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8368 - val_loss: 0.5786 - val_accuracy: 0.7292\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8368 - val_loss: 0.5797 - val_accuracy: 0.7292\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8368 - val_loss: 0.5785 - val_accuracy: 0.7292\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8368 - val_loss: 0.5790 - val_accuracy: 0.7292\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8351 - val_loss: 0.5781 - val_accuracy: 0.7344\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8385 - val_loss: 0.5778 - val_accuracy: 0.7292\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8351 - val_loss: 0.5788 - val_accuracy: 0.7292\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8368 - val_loss: 0.5800 - val_accuracy: 0.7292\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8385 - val_loss: 0.5799 - val_accuracy: 0.7292\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8385 - val_loss: 0.5781 - val_accuracy: 0.7292\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8385 - val_loss: 0.5784 - val_accuracy: 0.7292\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8385 - val_loss: 0.5785 - val_accuracy: 0.7292\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8368 - val_loss: 0.5788 - val_accuracy: 0.7292\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8385 - val_loss: 0.5797 - val_accuracy: 0.7292\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8385 - val_loss: 0.5785 - val_accuracy: 0.7292\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8351 - val_loss: 0.5779 - val_accuracy: 0.7292\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8368 - val_loss: 0.5781 - val_accuracy: 0.7344\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8368 - val_loss: 0.5790 - val_accuracy: 0.7344\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8333 - val_loss: 0.5798 - val_accuracy: 0.7292\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8368 - val_loss: 0.5784 - val_accuracy: 0.7292\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8351 - val_loss: 0.5783 - val_accuracy: 0.7344\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8333 - val_loss: 0.5782 - val_accuracy: 0.7292\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.8351 - val_loss: 0.5799 - val_accuracy: 0.7292\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8368 - val_loss: 0.5787 - val_accuracy: 0.7292\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8385 - val_loss: 0.5776 - val_accuracy: 0.7292\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8385 - val_loss: 0.5787 - val_accuracy: 0.7292\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8385 - val_loss: 0.5793 - val_accuracy: 0.7344\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8351 - val_loss: 0.5795 - val_accuracy: 0.7344\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8368 - val_loss: 0.5808 - val_accuracy: 0.7396\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8316 - val_loss: 0.5787 - val_accuracy: 0.7344\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8368 - val_loss: 0.5800 - val_accuracy: 0.7344\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8351 - val_loss: 0.5794 - val_accuracy: 0.7344\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8368 - val_loss: 0.5783 - val_accuracy: 0.7344\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8385 - val_loss: 0.5810 - val_accuracy: 0.7344\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8385 - val_loss: 0.5808 - val_accuracy: 0.7344\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8351 - val_loss: 0.5800 - val_accuracy: 0.7344\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8351 - val_loss: 0.5800 - val_accuracy: 0.7344\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8368 - val_loss: 0.5797 - val_accuracy: 0.7344\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8385 - val_loss: 0.5790 - val_accuracy: 0.7344\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8351 - val_loss: 0.5795 - val_accuracy: 0.7344\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8368 - val_loss: 0.5785 - val_accuracy: 0.7344\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8368 - val_loss: 0.5787 - val_accuracy: 0.7344\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3777 - accuracy: 0.8385 - val_loss: 0.5797 - val_accuracy: 0.7344\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8333 - val_loss: 0.5793 - val_accuracy: 0.7344\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8351 - val_loss: 0.5800 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8351 - val_loss: 0.5799 - val_accuracy: 0.7344\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8351 - val_loss: 0.5804 - val_accuracy: 0.7344\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8351 - val_loss: 0.5792 - val_accuracy: 0.7344\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8351 - val_loss: 0.5804 - val_accuracy: 0.7344\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8385 - val_loss: 0.5817 - val_accuracy: 0.7344\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8333 - val_loss: 0.5803 - val_accuracy: 0.7344\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8368 - val_loss: 0.5809 - val_accuracy: 0.7344\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8351 - val_loss: 0.5797 - val_accuracy: 0.7344\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8351 - val_loss: 0.5796 - val_accuracy: 0.7344\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8368 - val_loss: 0.5811 - val_accuracy: 0.7344\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8351 - val_loss: 0.5811 - val_accuracy: 0.7344\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8368 - val_loss: 0.5811 - val_accuracy: 0.7344\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3767 - accuracy: 0.8385 - val_loss: 0.5786 - val_accuracy: 0.7396\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8351 - val_loss: 0.5813 - val_accuracy: 0.7344\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8351 - val_loss: 0.5812 - val_accuracy: 0.7344\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8316 - val_loss: 0.5801 - val_accuracy: 0.7396\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8351 - val_loss: 0.5807 - val_accuracy: 0.7344\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8333 - val_loss: 0.5805 - val_accuracy: 0.7396\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8351 - val_loss: 0.5803 - val_accuracy: 0.7396\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8351 - val_loss: 0.5810 - val_accuracy: 0.7396\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3774 - accuracy: 0.8351 - val_loss: 0.5818 - val_accuracy: 0.7396\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8385 - val_loss: 0.5816 - val_accuracy: 0.7396\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8351 - val_loss: 0.5807 - val_accuracy: 0.7396\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3767 - accuracy: 0.8385 - val_loss: 0.5802 - val_accuracy: 0.7396\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8385 - val_loss: 0.5813 - val_accuracy: 0.7344\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8368 - val_loss: 0.5814 - val_accuracy: 0.7344\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.8368 - val_loss: 0.5811 - val_accuracy: 0.7396\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8368 - val_loss: 0.5815 - val_accuracy: 0.7396\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8368 - val_loss: 0.5823 - val_accuracy: 0.7344\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8351 - val_loss: 0.5825 - val_accuracy: 0.7344\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8351 - val_loss: 0.5811 - val_accuracy: 0.7396\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8368 - val_loss: 0.5820 - val_accuracy: 0.7396\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8368 - val_loss: 0.5807 - val_accuracy: 0.7396\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8368 - val_loss: 0.5812 - val_accuracy: 0.7396\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8351 - val_loss: 0.5819 - val_accuracy: 0.7396\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8351 - val_loss: 0.5807 - val_accuracy: 0.7396\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8351 - val_loss: 0.5808 - val_accuracy: 0.7396\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8351 - val_loss: 0.5811 - val_accuracy: 0.7396\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8368 - val_loss: 0.5811 - val_accuracy: 0.7344\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8385 - val_loss: 0.5808 - val_accuracy: 0.7396\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3767 - accuracy: 0.8351 - val_loss: 0.5815 - val_accuracy: 0.7396\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8385 - val_loss: 0.5824 - val_accuracy: 0.7396\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.8403 - val_loss: 0.5829 - val_accuracy: 0.7344\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8368 - val_loss: 0.5814 - val_accuracy: 0.7344\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8368 - val_loss: 0.5821 - val_accuracy: 0.7344\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8385 - val_loss: 0.5824 - val_accuracy: 0.7396\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.8333 - val_loss: 0.5811 - val_accuracy: 0.7344\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8385 - val_loss: 0.5830 - val_accuracy: 0.7396\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8385 - val_loss: 0.5823 - val_accuracy: 0.7344\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8333 - val_loss: 0.5817 - val_accuracy: 0.7344\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8385 - val_loss: 0.5824 - val_accuracy: 0.7344\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.8368 - val_loss: 0.5826 - val_accuracy: 0.7396\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.8351 - val_loss: 0.5829 - val_accuracy: 0.7396\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8333 - val_loss: 0.5825 - val_accuracy: 0.7396\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8385 - val_loss: 0.5838 - val_accuracy: 0.7396\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3763 - accuracy: 0.8368 - val_loss: 0.5834 - val_accuracy: 0.7396\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8351 - val_loss: 0.5822 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8368 - val_loss: 0.5822 - val_accuracy: 0.7344\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8368 - val_loss: 0.5821 - val_accuracy: 0.7344\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8351 - val_loss: 0.5812 - val_accuracy: 0.7344\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3763 - accuracy: 0.8351 - val_loss: 0.5822 - val_accuracy: 0.7344\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8351 - val_loss: 0.5814 - val_accuracy: 0.7344\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8368 - val_loss: 0.5831 - val_accuracy: 0.7344\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8385 - val_loss: 0.5822 - val_accuracy: 0.7344\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8385 - val_loss: 0.5829 - val_accuracy: 0.7344\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8351 - val_loss: 0.5827 - val_accuracy: 0.7344\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8385 - val_loss: 0.5829 - val_accuracy: 0.7344\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8385 - val_loss: 0.5826 - val_accuracy: 0.7344\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8333 - val_loss: 0.5822 - val_accuracy: 0.7344\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8368 - val_loss: 0.5815 - val_accuracy: 0.7344\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8351 - val_loss: 0.5817 - val_accuracy: 0.7344\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3757 - accuracy: 0.8403 - val_loss: 0.5831 - val_accuracy: 0.7344\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3756 - accuracy: 0.8351 - val_loss: 0.5842 - val_accuracy: 0.7344\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8351 - val_loss: 0.5825 - val_accuracy: 0.7344\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8368 - val_loss: 0.5816 - val_accuracy: 0.7344\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8368 - val_loss: 0.5824 - val_accuracy: 0.7344\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8368 - val_loss: 0.5823 - val_accuracy: 0.7344\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8368 - val_loss: 0.5834 - val_accuracy: 0.7344\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8351 - val_loss: 0.5818 - val_accuracy: 0.7344\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8403 - val_loss: 0.5819 - val_accuracy: 0.7344\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8385 - val_loss: 0.5823 - val_accuracy: 0.7344\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8316 - val_loss: 0.5822 - val_accuracy: 0.7344\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3756 - accuracy: 0.8368 - val_loss: 0.5830 - val_accuracy: 0.7344\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8351 - val_loss: 0.5828 - val_accuracy: 0.7344\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8368 - val_loss: 0.5816 - val_accuracy: 0.7344\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8368 - val_loss: 0.5826 - val_accuracy: 0.7344\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8368 - val_loss: 0.5833 - val_accuracy: 0.7344\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3760 - accuracy: 0.8351 - val_loss: 0.5832 - val_accuracy: 0.7344\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8368 - val_loss: 0.5831 - val_accuracy: 0.7344\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8351 - val_loss: 0.5825 - val_accuracy: 0.7344\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8368 - val_loss: 0.5818 - val_accuracy: 0.7344\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3755 - accuracy: 0.8368 - val_loss: 0.5823 - val_accuracy: 0.7344\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8351 - val_loss: 0.5818 - val_accuracy: 0.7344\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8351 - val_loss: 0.5822 - val_accuracy: 0.7344\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8368 - val_loss: 0.5820 - val_accuracy: 0.7344\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.8368 - val_loss: 0.5827 - val_accuracy: 0.7344\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8385 - val_loss: 0.5820 - val_accuracy: 0.7344\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8385 - val_loss: 0.5824 - val_accuracy: 0.7344\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8385 - val_loss: 0.5827 - val_accuracy: 0.7344\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3746 - accuracy: 0.8403 - val_loss: 0.5821 - val_accuracy: 0.7344\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8385 - val_loss: 0.5821 - val_accuracy: 0.7344\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8420 - val_loss: 0.5829 - val_accuracy: 0.7344\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8368 - val_loss: 0.5830 - val_accuracy: 0.7344\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8351 - val_loss: 0.5829 - val_accuracy: 0.7344\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8368 - val_loss: 0.5824 - val_accuracy: 0.7344\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8403 - val_loss: 0.5827 - val_accuracy: 0.7344\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8368 - val_loss: 0.5821 - val_accuracy: 0.7344\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8420 - val_loss: 0.5831 - val_accuracy: 0.7344\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8368 - val_loss: 0.5842 - val_accuracy: 0.7344\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8385 - val_loss: 0.5843 - val_accuracy: 0.7344\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3748 - accuracy: 0.8333 - val_loss: 0.5833 - val_accuracy: 0.7344\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8351 - val_loss: 0.5836 - val_accuracy: 0.7344\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8351 - val_loss: 0.5835 - val_accuracy: 0.7344\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8351 - val_loss: 0.5827 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8368 - val_loss: 0.5828 - val_accuracy: 0.7344\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8333 - val_loss: 0.5820 - val_accuracy: 0.7396\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8385 - val_loss: 0.5829 - val_accuracy: 0.7396\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8403 - val_loss: 0.5834 - val_accuracy: 0.7344\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8368 - val_loss: 0.5841 - val_accuracy: 0.7344\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8385 - val_loss: 0.5834 - val_accuracy: 0.7344\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8351 - val_loss: 0.5833 - val_accuracy: 0.7344\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8368 - val_loss: 0.5836 - val_accuracy: 0.7344\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8368 - val_loss: 0.5823 - val_accuracy: 0.7344\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3743 - accuracy: 0.8385 - val_loss: 0.5839 - val_accuracy: 0.7344\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8368 - val_loss: 0.5838 - val_accuracy: 0.7344\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8351 - val_loss: 0.5834 - val_accuracy: 0.7344\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8333 - val_loss: 0.5831 - val_accuracy: 0.7344\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8385 - val_loss: 0.5832 - val_accuracy: 0.7344\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8385 - val_loss: 0.5831 - val_accuracy: 0.7344\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8368 - val_loss: 0.5830 - val_accuracy: 0.7344\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3743 - accuracy: 0.8368 - val_loss: 0.5837 - val_accuracy: 0.7344\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8351 - val_loss: 0.5836 - val_accuracy: 0.7396\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8385 - val_loss: 0.5838 - val_accuracy: 0.7396\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8368 - val_loss: 0.5846 - val_accuracy: 0.7344\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8316 - val_loss: 0.5832 - val_accuracy: 0.7396\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8333 - val_loss: 0.5833 - val_accuracy: 0.7344\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8368 - val_loss: 0.5835 - val_accuracy: 0.7344\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8385 - val_loss: 0.5841 - val_accuracy: 0.7344\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8351 - val_loss: 0.5851 - val_accuracy: 0.7344\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8351 - val_loss: 0.5844 - val_accuracy: 0.7344\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8333 - val_loss: 0.5845 - val_accuracy: 0.7344\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8385 - val_loss: 0.5851 - val_accuracy: 0.7344\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8351 - val_loss: 0.5842 - val_accuracy: 0.7344\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8351 - val_loss: 0.5850 - val_accuracy: 0.7344\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8368 - val_loss: 0.5859 - val_accuracy: 0.7344\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8351 - val_loss: 0.5860 - val_accuracy: 0.7344\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8333 - val_loss: 0.5845 - val_accuracy: 0.7344\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8333 - val_loss: 0.5851 - val_accuracy: 0.7344\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8351 - val_loss: 0.5847 - val_accuracy: 0.7344\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8333 - val_loss: 0.5862 - val_accuracy: 0.7344\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8368 - val_loss: 0.5856 - val_accuracy: 0.7344\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8368 - val_loss: 0.5862 - val_accuracy: 0.7344\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8385 - val_loss: 0.5859 - val_accuracy: 0.7344\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8368 - val_loss: 0.5852 - val_accuracy: 0.7344\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8368 - val_loss: 0.5853 - val_accuracy: 0.7344\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8385 - val_loss: 0.5855 - val_accuracy: 0.7344\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8351 - val_loss: 0.5855 - val_accuracy: 0.7344\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8368 - val_loss: 0.5863 - val_accuracy: 0.7344\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8368 - val_loss: 0.5862 - val_accuracy: 0.7344\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8368 - val_loss: 0.5858 - val_accuracy: 0.7344\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8351 - val_loss: 0.5858 - val_accuracy: 0.7344\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8368 - val_loss: 0.5859 - val_accuracy: 0.7344\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8368 - val_loss: 0.5867 - val_accuracy: 0.7344\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8368 - val_loss: 0.5877 - val_accuracy: 0.7344\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8368 - val_loss: 0.5872 - val_accuracy: 0.7344\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3735 - accuracy: 0.8333 - val_loss: 0.5870 - val_accuracy: 0.7344\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8351 - val_loss: 0.5877 - val_accuracy: 0.7344\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2838 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8368 - val_loss: 0.5875 - val_accuracy: 0.7344\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8333 - val_loss: 0.5873 - val_accuracy: 0.7344\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8368 - val_loss: 0.5876 - val_accuracy: 0.7344\n",
      "Epoch 1024/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8351 - val_loss: 0.5875 - val_accuracy: 0.7344\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8351 - val_loss: 0.5882 - val_accuracy: 0.7344\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8368 - val_loss: 0.5872 - val_accuracy: 0.7344\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8368 - val_loss: 0.5886 - val_accuracy: 0.7344\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8368 - val_loss: 0.5877 - val_accuracy: 0.7344\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8333 - val_loss: 0.5877 - val_accuracy: 0.7344\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8403 - val_loss: 0.5891 - val_accuracy: 0.7344\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8333 - val_loss: 0.5895 - val_accuracy: 0.7344\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8368 - val_loss: 0.5881 - val_accuracy: 0.7344\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8333 - val_loss: 0.5881 - val_accuracy: 0.7344\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3731 - accuracy: 0.8368 - val_loss: 0.5891 - val_accuracy: 0.7344\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8368 - val_loss: 0.5883 - val_accuracy: 0.7344\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8368 - val_loss: 0.5888 - val_accuracy: 0.7344\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3729 - accuracy: 0.8333 - val_loss: 0.5901 - val_accuracy: 0.7344\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3730 - accuracy: 0.8351 - val_loss: 0.5886 - val_accuracy: 0.7344\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8385 - val_loss: 0.5896 - val_accuracy: 0.7344\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8351 - val_loss: 0.5894 - val_accuracy: 0.7396\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8385 - val_loss: 0.5901 - val_accuracy: 0.7344\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8403 - val_loss: 0.5908 - val_accuracy: 0.7344\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8368 - val_loss: 0.5899 - val_accuracy: 0.7344\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3726 - accuracy: 0.8385 - val_loss: 0.5900 - val_accuracy: 0.7344\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8368 - val_loss: 0.5907 - val_accuracy: 0.7344\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8333 - val_loss: 0.5895 - val_accuracy: 0.7344\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8368 - val_loss: 0.5902 - val_accuracy: 0.7344\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8368 - val_loss: 0.5909 - val_accuracy: 0.7344\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.8333 - val_loss: 0.5899 - val_accuracy: 0.7344\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8333 - val_loss: 0.5903 - val_accuracy: 0.7344\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8368 - val_loss: 0.5901 - val_accuracy: 0.7344\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8385 - val_loss: 0.5907 - val_accuracy: 0.7344\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.8368 - val_loss: 0.5899 - val_accuracy: 0.7344\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8351 - val_loss: 0.5901 - val_accuracy: 0.7344\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8385 - val_loss: 0.5897 - val_accuracy: 0.7344\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8351 - val_loss: 0.5903 - val_accuracy: 0.7344\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8351 - val_loss: 0.5897 - val_accuracy: 0.7344\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8368 - val_loss: 0.5904 - val_accuracy: 0.7344\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8351 - val_loss: 0.5902 - val_accuracy: 0.7344\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8368 - val_loss: 0.5900 - val_accuracy: 0.7344\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8385 - val_loss: 0.5906 - val_accuracy: 0.7344\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8333 - val_loss: 0.5907 - val_accuracy: 0.7344\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8368 - val_loss: 0.5909 - val_accuracy: 0.7344\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8385 - val_loss: 0.5916 - val_accuracy: 0.7344\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8351 - val_loss: 0.5912 - val_accuracy: 0.7344\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8368 - val_loss: 0.5909 - val_accuracy: 0.7344\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8351 - val_loss: 0.5917 - val_accuracy: 0.7344\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8351 - val_loss: 0.5918 - val_accuracy: 0.7344\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8368 - val_loss: 0.5908 - val_accuracy: 0.7344\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8368 - val_loss: 0.5909 - val_accuracy: 0.7344\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8351 - val_loss: 0.5917 - val_accuracy: 0.7344\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8368 - val_loss: 0.5925 - val_accuracy: 0.7344\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8351 - val_loss: 0.5924 - val_accuracy: 0.7344\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8351 - val_loss: 0.5920 - val_accuracy: 0.7344\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8385 - val_loss: 0.5922 - val_accuracy: 0.7344\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8368 - val_loss: 0.5928 - val_accuracy: 0.7344\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8351 - val_loss: 0.5935 - val_accuracy: 0.7344\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8351 - val_loss: 0.5945 - val_accuracy: 0.7344\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8351 - val_loss: 0.5936 - val_accuracy: 0.7344\n",
      "Epoch 1080/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8351 - val_loss: 0.5923 - val_accuracy: 0.7344\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8368 - val_loss: 0.5930 - val_accuracy: 0.7344\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8351 - val_loss: 0.5922 - val_accuracy: 0.7344\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8368 - val_loss: 0.5939 - val_accuracy: 0.7344\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8351 - val_loss: 0.5923 - val_accuracy: 0.7344\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8368 - val_loss: 0.5926 - val_accuracy: 0.7344\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8351 - val_loss: 0.5932 - val_accuracy: 0.7344\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8368 - val_loss: 0.5929 - val_accuracy: 0.7344\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8351 - val_loss: 0.5939 - val_accuracy: 0.7344\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8351 - val_loss: 0.5923 - val_accuracy: 0.7344\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8368 - val_loss: 0.5929 - val_accuracy: 0.7344\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8351 - val_loss: 0.5918 - val_accuracy: 0.7344\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8351 - val_loss: 0.5917 - val_accuracy: 0.7344\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8368 - val_loss: 0.5931 - val_accuracy: 0.7344\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8368 - val_loss: 0.5940 - val_accuracy: 0.7344\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8351 - val_loss: 0.5944 - val_accuracy: 0.7344\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8385 - val_loss: 0.5941 - val_accuracy: 0.7344\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8351 - val_loss: 0.5931 - val_accuracy: 0.7344\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8351 - val_loss: 0.5926 - val_accuracy: 0.7344\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8368 - val_loss: 0.5936 - val_accuracy: 0.7344\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8368 - val_loss: 0.5948 - val_accuracy: 0.7344\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8368 - val_loss: 0.5953 - val_accuracy: 0.7344\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8368 - val_loss: 0.5947 - val_accuracy: 0.7344\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8333 - val_loss: 0.5945 - val_accuracy: 0.7344\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8368 - val_loss: 0.5944 - val_accuracy: 0.7344\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8368 - val_loss: 0.5942 - val_accuracy: 0.7344\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8351 - val_loss: 0.5948 - val_accuracy: 0.7344\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8333 - val_loss: 0.5958 - val_accuracy: 0.7344\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8385 - val_loss: 0.5978 - val_accuracy: 0.7344\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8368 - val_loss: 0.5976 - val_accuracy: 0.7344\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8333 - val_loss: 0.5953 - val_accuracy: 0.7344\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8351 - val_loss: 0.5954 - val_accuracy: 0.7344\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8368 - val_loss: 0.5951 - val_accuracy: 0.7344\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8351 - val_loss: 0.5953 - val_accuracy: 0.7344\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8333 - val_loss: 0.5957 - val_accuracy: 0.7344\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8351 - val_loss: 0.5958 - val_accuracy: 0.7344\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8351 - val_loss: 0.5965 - val_accuracy: 0.7344\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8316 - val_loss: 0.5939 - val_accuracy: 0.7344\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8351 - val_loss: 0.5944 - val_accuracy: 0.7344\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8368 - val_loss: 0.5945 - val_accuracy: 0.7344\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.8368 - val_loss: 0.5962 - val_accuracy: 0.7344\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8351 - val_loss: 0.5966 - val_accuracy: 0.7344\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8351 - val_loss: 0.5963 - val_accuracy: 0.7344\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8333 - val_loss: 0.5973 - val_accuracy: 0.7344\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8368 - val_loss: 0.5966 - val_accuracy: 0.7344\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8368 - val_loss: 0.5962 - val_accuracy: 0.7344\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8368 - val_loss: 0.5972 - val_accuracy: 0.7344\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3701 - accuracy: 0.8368 - val_loss: 0.5962 - val_accuracy: 0.7344\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.8368 - val_loss: 0.5981 - val_accuracy: 0.7344\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8368 - val_loss: 0.5956 - val_accuracy: 0.7344\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8368 - val_loss: 0.5957 - val_accuracy: 0.7344\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8385 - val_loss: 0.5971 - val_accuracy: 0.7344\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8351 - val_loss: 0.5965 - val_accuracy: 0.7344\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3697 - accuracy: 0.8385 - val_loss: 0.5977 - val_accuracy: 0.7344\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8368 - val_loss: 0.5973 - val_accuracy: 0.7344\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8368 - val_loss: 0.5978 - val_accuracy: 0.7344\n",
      "Epoch 1136/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8385 - val_loss: 0.5971 - val_accuracy: 0.7344\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8368 - val_loss: 0.5966 - val_accuracy: 0.7344\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8385 - val_loss: 0.5959 - val_accuracy: 0.7344\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8351 - val_loss: 0.5971 - val_accuracy: 0.7344\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8351 - val_loss: 0.5977 - val_accuracy: 0.7344\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8351 - val_loss: 0.5989 - val_accuracy: 0.7344\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8351 - val_loss: 0.5986 - val_accuracy: 0.7344\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8368 - val_loss: 0.5984 - val_accuracy: 0.7344\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8403 - val_loss: 0.5965 - val_accuracy: 0.7344\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8368 - val_loss: 0.5967 - val_accuracy: 0.7344\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8351 - val_loss: 0.5974 - val_accuracy: 0.7344\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3699 - accuracy: 0.8385 - val_loss: 0.5987 - val_accuracy: 0.7344\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8333 - val_loss: 0.6000 - val_accuracy: 0.7344\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8368 - val_loss: 0.5988 - val_accuracy: 0.7344\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8368 - val_loss: 0.6010 - val_accuracy: 0.7344\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8368 - val_loss: 0.6002 - val_accuracy: 0.7344\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8351 - val_loss: 0.5996 - val_accuracy: 0.7344\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8385 - val_loss: 0.5990 - val_accuracy: 0.7344\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8385 - val_loss: 0.5988 - val_accuracy: 0.7344\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8368 - val_loss: 0.5989 - val_accuracy: 0.7344\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8368 - val_loss: 0.5980 - val_accuracy: 0.7344\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8403 - val_loss: 0.5981 - val_accuracy: 0.7344\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8420 - val_loss: 0.6000 - val_accuracy: 0.7344\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8385 - val_loss: 0.5998 - val_accuracy: 0.7344\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8368 - val_loss: 0.6015 - val_accuracy: 0.7344\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8403 - val_loss: 0.6004 - val_accuracy: 0.7344\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8403 - val_loss: 0.5997 - val_accuracy: 0.7344\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8385 - val_loss: 0.6000 - val_accuracy: 0.7344\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8403 - val_loss: 0.5995 - val_accuracy: 0.7344\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3698 - accuracy: 0.8385 - val_loss: 0.6014 - val_accuracy: 0.7344\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8403 - val_loss: 0.6010 - val_accuracy: 0.7344\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8385 - val_loss: 0.6011 - val_accuracy: 0.7344\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8403 - val_loss: 0.6004 - val_accuracy: 0.7344\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.8385 - val_loss: 0.6011 - val_accuracy: 0.7344\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8403 - val_loss: 0.6008 - val_accuracy: 0.7344\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8385 - val_loss: 0.6000 - val_accuracy: 0.7344\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8385 - val_loss: 0.6013 - val_accuracy: 0.7344\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8385 - val_loss: 0.6013 - val_accuracy: 0.7344\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8385 - val_loss: 0.6006 - val_accuracy: 0.7344\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8403 - val_loss: 0.6022 - val_accuracy: 0.7344\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8403 - val_loss: 0.6017 - val_accuracy: 0.7396\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8420 - val_loss: 0.6013 - val_accuracy: 0.7396\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8420 - val_loss: 0.6019 - val_accuracy: 0.7396\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8403 - val_loss: 0.6015 - val_accuracy: 0.7396\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8403 - val_loss: 0.6019 - val_accuracy: 0.7396\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8420 - val_loss: 0.6018 - val_accuracy: 0.7344\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8403 - val_loss: 0.6036 - val_accuracy: 0.7344\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8420 - val_loss: 0.6028 - val_accuracy: 0.7396\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8420 - val_loss: 0.6023 - val_accuracy: 0.7396\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8403 - val_loss: 0.6037 - val_accuracy: 0.7344\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3688 - accuracy: 0.8403 - val_loss: 0.6038 - val_accuracy: 0.7292\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8438 - val_loss: 0.6015 - val_accuracy: 0.7396\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8368 - val_loss: 0.6029 - val_accuracy: 0.7344\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3688 - accuracy: 0.8420 - val_loss: 0.6032 - val_accuracy: 0.7344\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8438 - val_loss: 0.6019 - val_accuracy: 0.7396\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8420 - val_loss: 0.6019 - val_accuracy: 0.7396\n",
      "Epoch 1192/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8385 - val_loss: 0.6044 - val_accuracy: 0.7344\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8438 - val_loss: 0.6034 - val_accuracy: 0.7344\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8438 - val_loss: 0.6020 - val_accuracy: 0.7396\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8385 - val_loss: 0.6022 - val_accuracy: 0.7396\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3684 - accuracy: 0.8403 - val_loss: 0.6020 - val_accuracy: 0.7396\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8385 - val_loss: 0.6012 - val_accuracy: 0.7396\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8368 - val_loss: 0.6022 - val_accuracy: 0.7344\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8420 - val_loss: 0.6011 - val_accuracy: 0.7344\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.8403 - val_loss: 0.6027 - val_accuracy: 0.7344\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8455 - val_loss: 0.6027 - val_accuracy: 0.7292\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.8420 - val_loss: 0.6027 - val_accuracy: 0.7344\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8403 - val_loss: 0.6022 - val_accuracy: 0.7344\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8420 - val_loss: 0.6020 - val_accuracy: 0.7344\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8403 - val_loss: 0.6016 - val_accuracy: 0.7396\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8420 - val_loss: 0.6029 - val_accuracy: 0.7344\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8403 - val_loss: 0.6045 - val_accuracy: 0.7344\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.8438 - val_loss: 0.6037 - val_accuracy: 0.7344\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3675 - accuracy: 0.8455 - val_loss: 0.6023 - val_accuracy: 0.7396\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8438 - val_loss: 0.6018 - val_accuracy: 0.7396\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8385 - val_loss: 0.6025 - val_accuracy: 0.7344\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8420 - val_loss: 0.6025 - val_accuracy: 0.7344\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8420 - val_loss: 0.6017 - val_accuracy: 0.7448\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8403 - val_loss: 0.6025 - val_accuracy: 0.7396\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3673 - accuracy: 0.8420 - val_loss: 0.6032 - val_accuracy: 0.7396\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8420 - val_loss: 0.6043 - val_accuracy: 0.7396\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8403 - val_loss: 0.6028 - val_accuracy: 0.7396\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8420 - val_loss: 0.6026 - val_accuracy: 0.7396\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8403 - val_loss: 0.6025 - val_accuracy: 0.7344\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8438 - val_loss: 0.6023 - val_accuracy: 0.7344\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8403 - val_loss: 0.6020 - val_accuracy: 0.7344\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8438 - val_loss: 0.6024 - val_accuracy: 0.7396\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8420 - val_loss: 0.6021 - val_accuracy: 0.7396\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8455 - val_loss: 0.6027 - val_accuracy: 0.7344\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3663 - accuracy: 0.8403 - val_loss: 0.6028 - val_accuracy: 0.7396\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8403 - val_loss: 0.6031 - val_accuracy: 0.7448\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8472 - val_loss: 0.6011 - val_accuracy: 0.7396\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8420 - val_loss: 0.6016 - val_accuracy: 0.7448\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8385 - val_loss: 0.6035 - val_accuracy: 0.7396\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8472 - val_loss: 0.6017 - val_accuracy: 0.7396\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8455 - val_loss: 0.6016 - val_accuracy: 0.7396\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8403 - val_loss: 0.6021 - val_accuracy: 0.7448\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8420 - val_loss: 0.6038 - val_accuracy: 0.7396\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8420 - val_loss: 0.6037 - val_accuracy: 0.7396\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8455 - val_loss: 0.6030 - val_accuracy: 0.7396\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8472 - val_loss: 0.6027 - val_accuracy: 0.7448\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8438 - val_loss: 0.6029 - val_accuracy: 0.7396\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8438 - val_loss: 0.6033 - val_accuracy: 0.7396\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8490 - val_loss: 0.6032 - val_accuracy: 0.7396\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3653 - accuracy: 0.8438 - val_loss: 0.6027 - val_accuracy: 0.7396\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8438 - val_loss: 0.6042 - val_accuracy: 0.7396\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8455 - val_loss: 0.6035 - val_accuracy: 0.7396\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8438 - val_loss: 0.6036 - val_accuracy: 0.7396\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3650 - accuracy: 0.8455 - val_loss: 0.6042 - val_accuracy: 0.7396\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3655 - accuracy: 0.8438 - val_loss: 0.6041 - val_accuracy: 0.7396\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8420 - val_loss: 0.6037 - val_accuracy: 0.7396\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8438 - val_loss: 0.6043 - val_accuracy: 0.7396\n",
      "Epoch 1248/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3650 - accuracy: 0.8455 - val_loss: 0.6052 - val_accuracy: 0.7396\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3647 - accuracy: 0.8438 - val_loss: 0.6045 - val_accuracy: 0.7396\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8438 - val_loss: 0.6049 - val_accuracy: 0.7396\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8490 - val_loss: 0.6032 - val_accuracy: 0.7396\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8420 - val_loss: 0.6043 - val_accuracy: 0.7396\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8490 - val_loss: 0.6035 - val_accuracy: 0.7396\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8420 - val_loss: 0.6046 - val_accuracy: 0.7396\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8455 - val_loss: 0.6053 - val_accuracy: 0.7396\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3642 - accuracy: 0.8438 - val_loss: 0.6054 - val_accuracy: 0.7396\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8438 - val_loss: 0.6056 - val_accuracy: 0.7396\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8455 - val_loss: 0.6060 - val_accuracy: 0.7396\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8420 - val_loss: 0.6063 - val_accuracy: 0.7396\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8420 - val_loss: 0.6053 - val_accuracy: 0.7396\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8438 - val_loss: 0.6061 - val_accuracy: 0.7396\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8438 - val_loss: 0.6054 - val_accuracy: 0.7396\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8472 - val_loss: 0.6052 - val_accuracy: 0.7396\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8438 - val_loss: 0.6064 - val_accuracy: 0.7396\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8472 - val_loss: 0.6048 - val_accuracy: 0.7396\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8472 - val_loss: 0.6058 - val_accuracy: 0.7396\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8455 - val_loss: 0.6079 - val_accuracy: 0.7448\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8490 - val_loss: 0.6067 - val_accuracy: 0.7396\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8472 - val_loss: 0.6065 - val_accuracy: 0.7448\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8472 - val_loss: 0.6062 - val_accuracy: 0.7448\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8455 - val_loss: 0.6071 - val_accuracy: 0.7448\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8455 - val_loss: 0.6081 - val_accuracy: 0.7448\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8490 - val_loss: 0.6077 - val_accuracy: 0.7448\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8490 - val_loss: 0.6077 - val_accuracy: 0.7396\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8472 - val_loss: 0.6084 - val_accuracy: 0.7396\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8472 - val_loss: 0.6082 - val_accuracy: 0.7396\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8490 - val_loss: 0.6072 - val_accuracy: 0.7396\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8490 - val_loss: 0.6069 - val_accuracy: 0.7396\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8472 - val_loss: 0.6087 - val_accuracy: 0.7448\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8472 - val_loss: 0.6070 - val_accuracy: 0.7448\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8490 - val_loss: 0.6090 - val_accuracy: 0.7448\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8472 - val_loss: 0.6083 - val_accuracy: 0.7448\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3615 - accuracy: 0.8490 - val_loss: 0.6090 - val_accuracy: 0.7448\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8490 - val_loss: 0.6084 - val_accuracy: 0.7448\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8472 - val_loss: 0.6087 - val_accuracy: 0.7448\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8490 - val_loss: 0.6074 - val_accuracy: 0.7448\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8507 - val_loss: 0.6102 - val_accuracy: 0.7448\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8472 - val_loss: 0.6100 - val_accuracy: 0.7448\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8472 - val_loss: 0.6090 - val_accuracy: 0.7448\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8490 - val_loss: 0.6094 - val_accuracy: 0.7448\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8490 - val_loss: 0.6107 - val_accuracy: 0.7448\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8490 - val_loss: 0.6112 - val_accuracy: 0.7448\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8472 - val_loss: 0.6116 - val_accuracy: 0.7448\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8507 - val_loss: 0.6116 - val_accuracy: 0.7448\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8490 - val_loss: 0.6107 - val_accuracy: 0.7448\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8507 - val_loss: 0.6100 - val_accuracy: 0.7448\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8490 - val_loss: 0.6091 - val_accuracy: 0.7448\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8490 - val_loss: 0.6086 - val_accuracy: 0.7448\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8490 - val_loss: 0.6091 - val_accuracy: 0.7448\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8472 - val_loss: 0.6106 - val_accuracy: 0.7448\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8490 - val_loss: 0.6101 - val_accuracy: 0.7448\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8490 - val_loss: 0.6136 - val_accuracy: 0.7448\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.8472 - val_loss: 0.6145 - val_accuracy: 0.7448\n",
      "Epoch 1304/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8507 - val_loss: 0.6126 - val_accuracy: 0.7448\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8490 - val_loss: 0.6125 - val_accuracy: 0.7448\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8507 - val_loss: 0.6150 - val_accuracy: 0.7448\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8507 - val_loss: 0.6145 - val_accuracy: 0.7448\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8507 - val_loss: 0.6119 - val_accuracy: 0.7448\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8507 - val_loss: 0.6121 - val_accuracy: 0.7448\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8507 - val_loss: 0.6130 - val_accuracy: 0.7448\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8524 - val_loss: 0.6111 - val_accuracy: 0.7448\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8507 - val_loss: 0.6130 - val_accuracy: 0.7448\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8524 - val_loss: 0.6125 - val_accuracy: 0.7448\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8507 - val_loss: 0.6120 - val_accuracy: 0.7448\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8507 - val_loss: 0.6122 - val_accuracy: 0.7448\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8507 - val_loss: 0.6128 - val_accuracy: 0.7448\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8507 - val_loss: 0.6130 - val_accuracy: 0.7448\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8507 - val_loss: 0.6135 - val_accuracy: 0.7448\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8524 - val_loss: 0.6142 - val_accuracy: 0.7448\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8507 - val_loss: 0.6156 - val_accuracy: 0.7448\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8542 - val_loss: 0.6138 - val_accuracy: 0.7448\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8524 - val_loss: 0.6137 - val_accuracy: 0.7448\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8507 - val_loss: 0.6161 - val_accuracy: 0.7448\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8507 - val_loss: 0.6161 - val_accuracy: 0.7448\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8524 - val_loss: 0.6162 - val_accuracy: 0.7448\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8507 - val_loss: 0.6164 - val_accuracy: 0.7448\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3595 - accuracy: 0.8542 - val_loss: 0.6158 - val_accuracy: 0.7448\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8507 - val_loss: 0.6151 - val_accuracy: 0.7448\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8542 - val_loss: 0.6157 - val_accuracy: 0.7448\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8524 - val_loss: 0.6143 - val_accuracy: 0.7448\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8524 - val_loss: 0.6162 - val_accuracy: 0.7448\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8524 - val_loss: 0.6150 - val_accuracy: 0.7448\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8507 - val_loss: 0.6156 - val_accuracy: 0.7448\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8542 - val_loss: 0.6157 - val_accuracy: 0.7448\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8524 - val_loss: 0.6160 - val_accuracy: 0.7448\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8542 - val_loss: 0.6176 - val_accuracy: 0.7448\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8524 - val_loss: 0.6148 - val_accuracy: 0.7448\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8542 - val_loss: 0.6162 - val_accuracy: 0.7448\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8559 - val_loss: 0.6150 - val_accuracy: 0.7448\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8542 - val_loss: 0.6161 - val_accuracy: 0.7448\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8542 - val_loss: 0.6155 - val_accuracy: 0.7448\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3589 - accuracy: 0.8542 - val_loss: 0.6164 - val_accuracy: 0.7448\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8524 - val_loss: 0.6159 - val_accuracy: 0.7448\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8524 - val_loss: 0.6157 - val_accuracy: 0.7448\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8524 - val_loss: 0.6189 - val_accuracy: 0.7448\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8524 - val_loss: 0.6186 - val_accuracy: 0.7448\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8559 - val_loss: 0.6153 - val_accuracy: 0.7448\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8507 - val_loss: 0.6177 - val_accuracy: 0.7448\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8507 - val_loss: 0.6161 - val_accuracy: 0.7448\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8524 - val_loss: 0.6176 - val_accuracy: 0.7448\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8524 - val_loss: 0.6175 - val_accuracy: 0.7448\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8524 - val_loss: 0.6182 - val_accuracy: 0.7448\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8542 - val_loss: 0.6175 - val_accuracy: 0.7448\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8524 - val_loss: 0.6174 - val_accuracy: 0.7448\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8524 - val_loss: 0.6190 - val_accuracy: 0.7448\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.8559 - val_loss: 0.6172 - val_accuracy: 0.7448\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8507 - val_loss: 0.6186 - val_accuracy: 0.7448\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8542 - val_loss: 0.6175 - val_accuracy: 0.7448\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8524 - val_loss: 0.6174 - val_accuracy: 0.7448\n",
      "Epoch 1360/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8524 - val_loss: 0.6172 - val_accuracy: 0.7448\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.8524 - val_loss: 0.6193 - val_accuracy: 0.7448\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8524 - val_loss: 0.6199 - val_accuracy: 0.7448\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8524 - val_loss: 0.6159 - val_accuracy: 0.7448\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8524 - val_loss: 0.6188 - val_accuracy: 0.7448\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8524 - val_loss: 0.6204 - val_accuracy: 0.7448\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8507 - val_loss: 0.6205 - val_accuracy: 0.7448\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8507 - val_loss: 0.6185 - val_accuracy: 0.7448\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8524 - val_loss: 0.6194 - val_accuracy: 0.7448\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8542 - val_loss: 0.6191 - val_accuracy: 0.7448\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8524 - val_loss: 0.6200 - val_accuracy: 0.7448\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8524 - val_loss: 0.6212 - val_accuracy: 0.7448\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8524 - val_loss: 0.6210 - val_accuracy: 0.7448\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8524 - val_loss: 0.6189 - val_accuracy: 0.7448\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8507 - val_loss: 0.6207 - val_accuracy: 0.7448\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8507 - val_loss: 0.6211 - val_accuracy: 0.7448\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8524 - val_loss: 0.6202 - val_accuracy: 0.7448\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8524 - val_loss: 0.6215 - val_accuracy: 0.7448\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8524 - val_loss: 0.6228 - val_accuracy: 0.7448\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8507 - val_loss: 0.6210 - val_accuracy: 0.7448\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8524 - val_loss: 0.6204 - val_accuracy: 0.7448\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8524 - val_loss: 0.6236 - val_accuracy: 0.7448\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8507 - val_loss: 0.6234 - val_accuracy: 0.7448\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8524 - val_loss: 0.6240 - val_accuracy: 0.7448\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8507 - val_loss: 0.6253 - val_accuracy: 0.7448\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8524 - val_loss: 0.6253 - val_accuracy: 0.7448\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8507 - val_loss: 0.6239 - val_accuracy: 0.7448\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8524 - val_loss: 0.6237 - val_accuracy: 0.7448\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8524 - val_loss: 0.6226 - val_accuracy: 0.7396\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8524 - val_loss: 0.6234 - val_accuracy: 0.7448\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8524 - val_loss: 0.6232 - val_accuracy: 0.7448\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3568 - accuracy: 0.8507 - val_loss: 0.6228 - val_accuracy: 0.7448\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8524 - val_loss: 0.6244 - val_accuracy: 0.7448\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8524 - val_loss: 0.6228 - val_accuracy: 0.7344\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8524 - val_loss: 0.6223 - val_accuracy: 0.7344\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8507 - val_loss: 0.6235 - val_accuracy: 0.7396\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8524 - val_loss: 0.6215 - val_accuracy: 0.7344\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8507 - val_loss: 0.6208 - val_accuracy: 0.7344\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8524 - val_loss: 0.6231 - val_accuracy: 0.7344\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8507 - val_loss: 0.6209 - val_accuracy: 0.7344\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8490 - val_loss: 0.6225 - val_accuracy: 0.7344\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8507 - val_loss: 0.6226 - val_accuracy: 0.7344\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8490 - val_loss: 0.6233 - val_accuracy: 0.7344\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8490 - val_loss: 0.6222 - val_accuracy: 0.7344\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8507 - val_loss: 0.6229 - val_accuracy: 0.7344\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8524 - val_loss: 0.6225 - val_accuracy: 0.7344\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8542 - val_loss: 0.6238 - val_accuracy: 0.7344\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8490 - val_loss: 0.6244 - val_accuracy: 0.7344\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8490 - val_loss: 0.6249 - val_accuracy: 0.7344\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8490 - val_loss: 0.6246 - val_accuracy: 0.7344\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8490 - val_loss: 0.6245 - val_accuracy: 0.7344\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.8490 - val_loss: 0.6250 - val_accuracy: 0.7344\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8490 - val_loss: 0.6254 - val_accuracy: 0.7344\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8490 - val_loss: 0.6254 - val_accuracy: 0.7344\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3555 - accuracy: 0.8490 - val_loss: 0.6229 - val_accuracy: 0.7344\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8490 - val_loss: 0.6222 - val_accuracy: 0.7344\n",
      "Epoch 1416/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8490 - val_loss: 0.6242 - val_accuracy: 0.7344\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8542 - val_loss: 0.6262 - val_accuracy: 0.7292\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8507 - val_loss: 0.6256 - val_accuracy: 0.7344\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8490 - val_loss: 0.6240 - val_accuracy: 0.7344\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8490 - val_loss: 0.6250 - val_accuracy: 0.7344\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8524 - val_loss: 0.6229 - val_accuracy: 0.7292\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8490 - val_loss: 0.6237 - val_accuracy: 0.7292\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8507 - val_loss: 0.6249 - val_accuracy: 0.7344\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.8490 - val_loss: 0.6233 - val_accuracy: 0.7344\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8490 - val_loss: 0.6229 - val_accuracy: 0.7292\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8507 - val_loss: 0.6234 - val_accuracy: 0.7292\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8507 - val_loss: 0.6240 - val_accuracy: 0.7344\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8507 - val_loss: 0.6236 - val_accuracy: 0.7292\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8507 - val_loss: 0.6245 - val_accuracy: 0.7292\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8490 - val_loss: 0.6233 - val_accuracy: 0.7292\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8490 - val_loss: 0.6219 - val_accuracy: 0.7292\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8507 - val_loss: 0.6235 - val_accuracy: 0.7292\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8507 - val_loss: 0.6242 - val_accuracy: 0.7292\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8490 - val_loss: 0.6235 - val_accuracy: 0.7292\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8490 - val_loss: 0.6247 - val_accuracy: 0.7292\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8524 - val_loss: 0.6244 - val_accuracy: 0.7292\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8507 - val_loss: 0.6242 - val_accuracy: 0.7292\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8507 - val_loss: 0.6266 - val_accuracy: 0.7292\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8472 - val_loss: 0.6252 - val_accuracy: 0.7292\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8507 - val_loss: 0.6247 - val_accuracy: 0.7292\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8524 - val_loss: 0.6243 - val_accuracy: 0.7292\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8490 - val_loss: 0.6244 - val_accuracy: 0.7292\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8524 - val_loss: 0.6243 - val_accuracy: 0.7292\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8490 - val_loss: 0.6253 - val_accuracy: 0.7292\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8507 - val_loss: 0.6237 - val_accuracy: 0.7292\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3543 - accuracy: 0.8524 - val_loss: 0.6248 - val_accuracy: 0.7292\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8507 - val_loss: 0.6235 - val_accuracy: 0.7292\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8507 - val_loss: 0.6238 - val_accuracy: 0.7292\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8507 - val_loss: 0.6228 - val_accuracy: 0.7292\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8490 - val_loss: 0.6237 - val_accuracy: 0.7292\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8524 - val_loss: 0.6226 - val_accuracy: 0.7292\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8490 - val_loss: 0.6249 - val_accuracy: 0.7292\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8490 - val_loss: 0.6242 - val_accuracy: 0.7292\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8507 - val_loss: 0.6227 - val_accuracy: 0.7292\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8490 - val_loss: 0.6263 - val_accuracy: 0.7292\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8524 - val_loss: 0.6261 - val_accuracy: 0.7292\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8490 - val_loss: 0.6258 - val_accuracy: 0.7292\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8507 - val_loss: 0.6268 - val_accuracy: 0.7292\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8524 - val_loss: 0.6273 - val_accuracy: 0.7292\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8490 - val_loss: 0.6269 - val_accuracy: 0.7292\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8507 - val_loss: 0.6261 - val_accuracy: 0.7292\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8490 - val_loss: 0.6263 - val_accuracy: 0.7292\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8490 - val_loss: 0.6280 - val_accuracy: 0.7292\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8507 - val_loss: 0.6279 - val_accuracy: 0.7292\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8490 - val_loss: 0.6274 - val_accuracy: 0.7292\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8472 - val_loss: 0.6301 - val_accuracy: 0.7240\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.8542 - val_loss: 0.6284 - val_accuracy: 0.7292\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3538 - accuracy: 0.8490 - val_loss: 0.6292 - val_accuracy: 0.7292\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.8507 - val_loss: 0.6300 - val_accuracy: 0.7292\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8507 - val_loss: 0.6275 - val_accuracy: 0.7292\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.8490 - val_loss: 0.6289 - val_accuracy: 0.7240\n",
      "Epoch 1472/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8524 - val_loss: 0.6283 - val_accuracy: 0.7292\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8507 - val_loss: 0.6301 - val_accuracy: 0.7292\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8507 - val_loss: 0.6295 - val_accuracy: 0.7292\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8490 - val_loss: 0.6285 - val_accuracy: 0.7292\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8524 - val_loss: 0.6272 - val_accuracy: 0.7292\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8490 - val_loss: 0.6289 - val_accuracy: 0.7292\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8507 - val_loss: 0.6289 - val_accuracy: 0.7292\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8490 - val_loss: 0.6292 - val_accuracy: 0.7292\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8524 - val_loss: 0.6278 - val_accuracy: 0.7292\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8490 - val_loss: 0.6318 - val_accuracy: 0.7292\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8507 - val_loss: 0.6330 - val_accuracy: 0.7292\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8507 - val_loss: 0.6314 - val_accuracy: 0.7292\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8490 - val_loss: 0.6336 - val_accuracy: 0.7292\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8507 - val_loss: 0.6322 - val_accuracy: 0.7292\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3529 - accuracy: 0.8507 - val_loss: 0.6330 - val_accuracy: 0.7292\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8507 - val_loss: 0.6335 - val_accuracy: 0.7292\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8507 - val_loss: 0.6332 - val_accuracy: 0.7292\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8507 - val_loss: 0.6323 - val_accuracy: 0.7292\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8507 - val_loss: 0.6323 - val_accuracy: 0.7292\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8524 - val_loss: 0.6320 - val_accuracy: 0.7292\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8507 - val_loss: 0.6315 - val_accuracy: 0.7292\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8490 - val_loss: 0.6340 - val_accuracy: 0.7292\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8507 - val_loss: 0.6328 - val_accuracy: 0.7292\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8490 - val_loss: 0.6333 - val_accuracy: 0.7292\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3532 - accuracy: 0.8507 - val_loss: 0.6355 - val_accuracy: 0.7292\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8507 - val_loss: 0.6347 - val_accuracy: 0.7240\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8524 - val_loss: 0.6363 - val_accuracy: 0.7240\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8507 - val_loss: 0.6371 - val_accuracy: 0.7188\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8507 - val_loss: 0.6360 - val_accuracy: 0.7240\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_3.add(Dense(6, activation=\"relu\"))\n",
    "model_3.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_3.compile('rmsprop', \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_3 = model_3.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "ax.plot(range(n), (run_hist_3.history[\"loss\"]),'g.', label=\"Train Loss3\")\n",
    "ax.plot(range(n), (run_hist_3.history[\"val_loss\"]),'c.', label=\"Validation Loss3\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations3')\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4)\n",
    "ax.plot(range(n), (run_hist_3.history[\"accuracy\"]),'m.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_3.history[\"val_accuracy\"]),'w.', label=\"Validation Acc\")\n",
    "ax.legend()\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.740\n",
      "roc-auc is 0.819\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
