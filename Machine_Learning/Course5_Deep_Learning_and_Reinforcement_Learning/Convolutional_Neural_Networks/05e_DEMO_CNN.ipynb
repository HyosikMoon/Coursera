{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part e: CNN DEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a CNN to classify images in the CIFAR-10 Dataset\n",
    "\n",
    "We will work with the CIFAR-10 Dataset.  This is a well-known dataset for image classification, which consists of 60000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The 10 classes are:\n",
    "\n",
    "<ol start=\"0\">\n",
    "<li> airplane\n",
    "<li>  automobile\n",
    "<li> bird\n",
    "<li>  cat\n",
    "<li> deer\n",
    "<li> dog\n",
    "<li>  frog\n",
    "<li>  horse\n",
    "<li>  ship\n",
    "<li>  truck\n",
    "</ol>\n",
    "\n",
    "For details about CIFAR-10 see:\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "For a compilation of published performance results on CIFAR 10, see:\n",
    "http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n",
    "\n",
    "---\n",
    "\n",
    "### Building Convolutional Neural Nets\n",
    "\n",
    "In this exercise we will build and train our first convolutional neural networks.  In the first part, we walk through the different layers and how they are configured.  In the second part, you will build your own model, train it, and compare the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "#from tensorflow.keras.datasets import cifar10\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "#from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Each image is a 32 x 32 x 3 numpy array\n",
    "x_train[444].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([ [ [1,2], [2,22], [3,3], [4,4] ], [ [1,2], [2,22], [3,3], [4,4] ], [ [1,2], [2,22], [3,3], [4,4] ] ]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[135, 163, 168],\n",
       "        [134, 160, 164],\n",
       "        [135, 160, 163],\n",
       "        ...,\n",
       "        [146, 169, 173],\n",
       "        [151, 166, 173],\n",
       "        [153, 168, 175]],\n",
       "\n",
       "       [[140, 166, 173],\n",
       "        [136, 164, 171],\n",
       "        [136, 165, 172],\n",
       "        ...,\n",
       "        [158, 174, 171],\n",
       "        [168, 179, 176],\n",
       "        [187, 197, 194]],\n",
       "\n",
       "       [[141, 166, 173],\n",
       "        [136, 163, 171],\n",
       "        [135, 164, 173],\n",
       "        ...,\n",
       "        [199, 207, 196],\n",
       "        [217, 222, 209],\n",
       "        [232, 237, 224]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 28,  21,  18],\n",
       "        [ 28,  20,  17],\n",
       "        [ 38,  30,  27],\n",
       "        ...,\n",
       "        [ 21,  21,  20],\n",
       "        [ 18,  24,  14],\n",
       "        [ 34,  28,  18]],\n",
       "\n",
       "       [[ 56,  44,  39],\n",
       "        [ 68,  56,  51],\n",
       "        [ 76,  65,  59],\n",
       "        ...,\n",
       "        [ 26,  20,  17],\n",
       "        [ 32,  27,  18],\n",
       "        [ 43,  31,  22]],\n",
       "\n",
       "       [[ 97,  79,  68],\n",
       "        [102,  85,  74],\n",
       "        [105,  88,  77],\n",
       "        ...,\n",
       "        [ 66,  51,  43],\n",
       "        [ 74,  56,  47],\n",
       "        [ 86,  67,  57]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[444]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Let's look at one of the images\n",
    "\n",
    "print(y_train[444])\n",
    "plt.imshow(x_train[444]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as ts\n",
    "from keras.utils.np_utils import to_categorical\n",
    "num_classes = 10\n",
    "\n",
    "y_train = ts.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = ts.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now instead of classes described by an integer between 0-9 we have a vector with a 1 in the (Pythonic) 9th position\n",
    "y_train[444]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, let's make everything float and scale\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Layers for CNNs\n",
    "- Previously we built Neural Networks using primarily the Dense, Activation and Dropout Layers.\n",
    "\n",
    "- Here we will describe how to use some of the CNN-specific layers provided by Keras\n",
    "\n",
    "### Conv2D\n",
    "\n",
    "```python\n",
    "keras.layers.convolutional.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
    "```\n",
    "\n",
    "A few parameters explained:\n",
    "- `filters`: the number of filter used per location.  In other words, the depth of the output.\n",
    "- `kernel_size`: an (x,y) tuple giving the height and width of the kernel to be used\n",
    "- `strides`: and (x,y) tuple giving the stride in each dimension.  Default is `(1,1)`\n",
    "- `input_shape`: required only for the first layer\n",
    "\n",
    "Note, the size of the output will be determined by the kernel_size, strides\n",
    "\n",
    "### MaxPooling2D\n",
    "`keras.layers.pooling.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)`\n",
    "\n",
    "- `pool_size`: the (x,y) size of the grid to be pooled.\n",
    "- `strides`: Assumed to be the `pool_size` unless otherwise specified\n",
    "\n",
    "### Flatten\n",
    "Turns its input into a one-dimensional vector (per instance).  Usually used when transitioning between convolutional layers and fully connected layers.\n",
    "\n",
    "---\n",
    "\n",
    "## First CNN\n",
    "Below we will build our first CNN.  For demonstration purposes (so that it will train quickly) it is not very deep and has relatively few parameters.  We use strides of 2 in the first two convolutional layers which quickly reduces the dimensions of the output.  After a MaxPooling layer, we flatten, and then have a single fully connected layer before our final classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 16, 16, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 6, 6, 32)          25632     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               147968    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 181,162\n",
      "Trainable params: 181,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's build a CNN using Keras' Sequential capabilities\n",
    "\n",
    "model_1 = Sequential()\n",
    "\n",
    "\n",
    "## 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## 2x2 max pooling reduces to 3 x 3 x 32\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_1.add(Dropout(0.25))\n",
    "\n",
    "## Flatten turns 3x3x32 into 288x1\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(512))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(num_classes))\n",
    "model_1.add(Activation('softmax'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 6, 6, 64)          102464    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               295424    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 407,882\n",
      "Trainable params: 407,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Conv2D(64, (5, 5), strides=(2,2), padding='same', input_shape=x_train.shape[1:]))\n",
    "model_2.add(Activation('relu'))\n",
    "\n",
    "model_2.add(Conv2D(64, (5,5), strides=(2,2)))\n",
    "model_2.add(Activation('relu'))\n",
    "\n",
    "model_2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(512))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(num_classes))\n",
    "model_2.add(Activation('softmax'))\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1563/1563 [==============================] - 36s 22ms/step - loss: 1.0823 - accuracy: 0.6229 - val_loss: 1.0449 - val_accuracy: 0.6330\n",
      "Epoch 2/15\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 1.0276 - accuracy: 0.6464 - val_loss: 0.9925 - val_accuracy: 0.6579\n",
      "Epoch 3/15\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 1.0087 - accuracy: 0.6531 - val_loss: 1.0528 - val_accuracy: 0.6453\n",
      "Epoch 4/15\n",
      "1187/1563 [=====================>........] - ETA: 7s - loss: 1.0055 - accuracy: 0.6546"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-a3ff971b1922>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jiwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1156\u001b[0m                 _r=1):\n\u001b[0;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jiwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jiwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jiwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jiwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\jiwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jiwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "opt = keras.optimizers.RMSprop(lr = 0.0005, decay=1e-6)\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model_2.fit(x_train, y_train, batch_size=batch_size, epochs=15, validation_data=(x_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have 181K parameters, even though this is a \"small\" model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jiwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1563/1563 [==============================] - 31s 13ms/step - loss: 1.9301 - accuracy: 0.2852 - val_loss: 1.4541 - val_accuracy: 0.4702\n",
      "Epoch 2/15\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.4969 - accuracy: 0.4608 - val_loss: 1.2834 - val_accuracy: 0.5399\n",
      "Epoch 3/15\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.3691 - accuracy: 0.5094 - val_loss: 1.2447 - val_accuracy: 0.5503\n",
      "Epoch 4/15\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.2962 - accuracy: 0.5368 - val_loss: 1.1756 - val_accuracy: 0.5794\n",
      "Epoch 5/15\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.2341 - accuracy: 0.5641 - val_loss: 1.1166 - val_accuracy: 0.6089\n",
      "Epoch 6/15\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.2079 - accuracy: 0.5727 - val_loss: 1.1296 - val_accuracy: 0.6004\n",
      "Epoch 7/15\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.1703 - accuracy: 0.5841 - val_loss: 1.0711 - val_accuracy: 0.6180\n",
      "Epoch 8/15\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.1387 - accuracy: 0.5975 - val_loss: 1.1656 - val_accuracy: 0.5998\n",
      "Epoch 9/15\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.1203 - accuracy: 0.6106 - val_loss: 1.1261 - val_accuracy: 0.6067\n",
      "Epoch 10/15\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.1203 - accuracy: 0.6088 - val_loss: 1.1072 - val_accuracy: 0.6182\n",
      "Epoch 11/15\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.1063 - accuracy: 0.6165 - val_loss: 1.0834 - val_accuracy: 0.6196\n",
      "Epoch 12/15\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.1046 - accuracy: 0.6183 - val_loss: 1.3487 - val_accuracy: 0.5672\n",
      "Epoch 13/15\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.0951 - accuracy: 0.6227 - val_loss: 1.1493 - val_accuracy: 0.6166\n",
      "Epoch 14/15\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.0803 - accuracy: 0.6279 - val_loss: 1.0834 - val_accuracy: 0.6408\n",
      "Epoch 15/15\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.0741 - accuracy: 0.6273 - val_loss: 1.0109 - val_accuracy: 0.6593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cf0e385640>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0005, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_1.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=15,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Our previous model had the structure:\n",
    "\n",
    "Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n",
    "\n",
    "(with appropriate activation functions and dropouts)\n",
    "\n",
    "1. Build a more complicated model with the following pattern:\n",
    "- Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n",
    "\n",
    "- Use strides of 1 for all convolutional layers.\n",
    "\n",
    "2. How many parameters does your model have?  How does that compare to the previous model?\n",
    "\n",
    "3. Train it for 5 epochs.  What do you notice about the training time, loss and accuracy numbers (on both the training and validation sets)?\n",
    "\n",
    "5. Try different structures and run times, and see how accurate your model can be.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a CNN using Keras' Sequential capabilities\n",
    "\n",
    "model_3 = Sequential()\n",
    "\n",
    "model_3.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(Conv2D(32, (3, 3)))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_3.add(Dropout(0.25))\n",
    "\n",
    "model_3.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(Conv2D(64, (3, 3)))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_3.add(Dropout(0.25))\n",
    "\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(512))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(Dropout(0.5))\n",
    "model_3.add(Dense(num_classes))\n",
    "model_3.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Check number of parameters\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt_2 = keras.optimizers.RMSprop(lr=0.0005)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model_3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt_2,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 110s 69ms/step - loss: 1.7917 - accuracy: 0.3406 - val_loss: 1.2641 - val_accuracy: 0.5417\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 104s 67ms/step - loss: 1.2065 - accuracy: 0.5739 - val_loss: 1.1798 - val_accuracy: 0.5909\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 1.0218 - accuracy: 0.6401 - val_loss: 0.9618 - val_accuracy: 0.6681\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 109s 70ms/step - loss: 0.9178 - accuracy: 0.6788 - val_loss: 0.8941 - val_accuracy: 0.6921\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 107s 68ms/step - loss: 0.8528 - accuracy: 0.6999 - val_loss: 0.8108 - val_accuracy: 0.7288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cf0e526eb0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=5,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 13s 7ms/step - loss: 2.0053 - accuracy: 0.2543 - val_loss: 1.5716 - val_accuracy: 0.4335\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.6142 - accuracy: 0.4128 - val_loss: 1.4441 - val_accuracy: 0.4812\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5261 - accuracy: 0.4500 - val_loss: 1.4295 - val_accuracy: 0.4873\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4672 - accuracy: 0.4734 - val_loss: 1.3673 - val_accuracy: 0.5136\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4316 - accuracy: 0.4849 - val_loss: 1.3552 - val_accuracy: 0.5227\n"
     ]
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "\n",
    "\n",
    "## 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_4.add(Conv2D(16, (5, 5), strides = (2,2), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_4.add(Activation('relu'))\n",
    "\n",
    "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_4.add(Conv2D(16, (5, 5), strides = (2,2)))\n",
    "model_4.add(Activation('relu'))\n",
    "\n",
    "## 2x2 max pooling reduces to 3 x 3 x 32\n",
    "model_4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_4.add(Dropout(0.25))\n",
    "\n",
    "## Flatten turns 3x3x32 into 288x1\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(288))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Dense(num_classes))\n",
    "model_4.add(Activation('softmax'))\n",
    "\n",
    "model_4.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "M4 = model_4.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=5,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'weakref' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-c94fc4ba5d2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# pickle.dump(model_1, open('cnn_model_1.p', 'wb'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# pickle.dump(model_2, open('cnn_model_2.p', 'wb'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cnn_model_4.p'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle 'weakref' object"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# pickle.dump(model_1, open('cnn_model_1.p', 'wb'))\n",
    "# pickle.dump(model_2, open('cnn_model_2.p', 'wb'))\n",
    "pickle.dump(M4, open('cnn_model_4.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-21b41e9564bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load cnn models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cnn_model_1.p'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# model_2 = pickle.load(open('cnn_model_2.p', 'rb'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# model_3 = pickle.load(open('cnn_model_3.p', 'rb'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "# load cnn models\n",
    "import pickle\n",
    "model_1 = pickle.load(open('cnn_model_1.p', 'rb'))\n",
    "# model_2 = pickle.load(open('cnn_model_2.p', 'rb'))\n",
    "# model_3 = pickle.load(open('cnn_model_3.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-38d62e0e91d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model_1' is not defined"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
