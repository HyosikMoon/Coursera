{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4020b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56ce698",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.env?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "09e0466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 20000\n",
    "\n",
    "life_memory = []\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    old_observation = env.reset()\n",
    "    done = False\n",
    "    tot_reward = 0\n",
    "    ep_memory = []\n",
    "    while not done:\n",
    "        new_action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(new_action)\n",
    "        tot_reward += reward\n",
    "        \n",
    "        ep_memory.append({\n",
    "            \"obs0\": old_observation[0],\n",
    "            \"obs1\": old_observation[1],\n",
    "            \"obs2\": old_observation[2],\n",
    "            \"obs3\": old_observation[3],\n",
    "            \"action\": new_action,\n",
    "            \"reward\": reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        old_observation = observation\n",
    "        \n",
    "    for ep_mem in ep_memory:\n",
    "        ep_mem[\"tot_reward\"] = tot_reward\n",
    "        \n",
    "    life_memory.extend(ep_memory)\n",
    "    \n",
    "memory_df = pandas.DataFrame(life_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c0715606",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_df.groupby(\"episode\").reward.sum().mean()\n",
    "memory_df[\"comb_reward\"] = .5*memory_df.reward + memory_df.tot_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ec3e170b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs0</th>\n",
       "      <th>obs1</th>\n",
       "      <th>obs2</th>\n",
       "      <th>obs3</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>episode</th>\n",
       "      <th>tot_reward</th>\n",
       "      <th>comb_reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020155</td>\n",
       "      <td>0.022310</td>\n",
       "      <td>-0.033537</td>\n",
       "      <td>-0.047698</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.217897</td>\n",
       "      <td>-0.034491</td>\n",
       "      <td>-0.350770</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024959</td>\n",
       "      <td>0.023282</td>\n",
       "      <td>-0.041506</td>\n",
       "      <td>-0.069160</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.218973</td>\n",
       "      <td>-0.042890</td>\n",
       "      <td>-0.374644</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029804</td>\n",
       "      <td>0.024486</td>\n",
       "      <td>-0.050383</td>\n",
       "      <td>-0.095787</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442627</th>\n",
       "      <td>-0.001106</td>\n",
       "      <td>-0.551411</td>\n",
       "      <td>0.078975</td>\n",
       "      <td>0.917054</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19999</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442628</th>\n",
       "      <td>-0.012134</td>\n",
       "      <td>-0.747506</td>\n",
       "      <td>0.097316</td>\n",
       "      <td>1.233476</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19999</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442629</th>\n",
       "      <td>-0.027084</td>\n",
       "      <td>-0.943735</td>\n",
       "      <td>0.121985</td>\n",
       "      <td>1.554992</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19999</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442630</th>\n",
       "      <td>-0.045959</td>\n",
       "      <td>-0.750268</td>\n",
       "      <td>0.153085</td>\n",
       "      <td>1.302723</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19999</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442631</th>\n",
       "      <td>-0.060964</td>\n",
       "      <td>-0.946964</td>\n",
       "      <td>0.179139</td>\n",
       "      <td>1.639148</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19999</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442632 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
       "0       0.020155  0.022310 -0.033537 -0.047698       1     1.0        0   \n",
       "1       0.020601  0.217897 -0.034491 -0.350770       0     1.0        0   \n",
       "2       0.024959  0.023282 -0.041506 -0.069160       1     1.0        0   \n",
       "3       0.025424  0.218973 -0.042890 -0.374644       0     1.0        0   \n",
       "4       0.029804  0.024486 -0.050383 -0.095787       1     1.0        0   \n",
       "...          ...       ...       ...       ...     ...     ...      ...   \n",
       "442627 -0.001106 -0.551411  0.078975  0.917054       0     1.0    19999   \n",
       "442628 -0.012134 -0.747506  0.097316  1.233476       0     1.0    19999   \n",
       "442629 -0.027084 -0.943735  0.121985  1.554992       1     1.0    19999   \n",
       "442630 -0.045959 -0.750268  0.153085  1.302723       0     1.0    19999   \n",
       "442631 -0.060964 -0.946964  0.179139  1.639148       0     1.0    19999   \n",
       "\n",
       "        tot_reward  comb_reward  \n",
       "0             37.0         37.5  \n",
       "1             37.0         37.5  \n",
       "2             37.0         37.5  \n",
       "3             37.0         37.5  \n",
       "4             37.0         37.5  \n",
       "...            ...          ...  \n",
       "442627        10.0         10.5  \n",
       "442628        10.0         10.5  \n",
       "442629        10.0         10.5  \n",
       "442630        10.0         10.5  \n",
       "442631        10.0         10.5  \n",
       "\n",
       "[442632 rows x 9 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "38cb2507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:06:34.983846s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "import datetime\n",
    "\n",
    "n = datetime.datetime.now\n",
    "t = n()\n",
    "\n",
    "RandomForest = RandomForestRegressor()\n",
    "RandomForest.fit(memory_df[[\"obs0\", \"obs1\", \"obs2\", \"obs3\", \"action\"]], memory_df.comb_reward)\n",
    "print(f\"Training time: {n() - t}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9677653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoost = AdaBoostRegressor()\n",
    "AdaBoost.fit(memory_df[[\"obs0\", \"obs1\", \"obs2\", \"obs3\", \"action\"]], memory_df.comb_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1c77271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExtraTrees = ExtraTreesRegressor()\n",
    "ExtraTrees.fit(memory_df[[\"obs0\", \"obs1\", \"obs2\", \"obs3\", \"action\"]], memory_df.comb_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ec5a7ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:01.277858s\n"
     ]
    }
   ],
   "source": [
    "t = n()\n",
    "num_episodes = 100\n",
    "a_life_memory = []\n",
    "a_env = gym.make('CartPole-v0')\n",
    "for i in range(num_episodes):\n",
    "    a_old_observation = a_env.reset()\n",
    "    a_done = False\n",
    "    a_tot_reward = 0\n",
    "    a_em_memory = []\n",
    "    \n",
    "    while not a_done:\n",
    "        pred_in = [list(a_old_observation) + [i] for i in range(2)]\n",
    "        a_new_action = np.argmax(AdaBoost.predict(pred_in))\n",
    "        a_observation, a_reward, a_done, a_info = a_env.step(a_new_action)\n",
    "        a_tot_reward += a_reward\n",
    "        \n",
    "        a_em_memory.append({\n",
    "            \"obs0\": a_old_observation[0],\n",
    "            \"obs1\": a_old_observation[1],\n",
    "            \"obs2\": a_old_observation[2],\n",
    "            \"obs3\": a_old_observation[3],\n",
    "            \"action\": a_new_action,\n",
    "            \"reward\": a_reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        \n",
    "        a_old_observation = a_observation\n",
    "\n",
    "    for a_em in a_em_memory:\n",
    "        a_em[\"tot_reward\"] = a_tot_reward\n",
    "        \n",
    "    a_life_memory.extend(a_em_memory)\n",
    "a_memory_df = pandas.DataFrame(a_life_memory)\n",
    "print(f\"Training time: {n() - t}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7540e8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929, 8)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_memory_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26063d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8e3c65ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:01:39.444469s\n"
     ]
    }
   ],
   "source": [
    "t = n()\n",
    "num_episodes = 100\n",
    "r_life_memory = []\n",
    "r_env = gym.make('CartPole-v0')\n",
    "for i in range(num_episodes):\n",
    "    r_old_observation = r_env.reset()\n",
    "    r_done = False\n",
    "    r_tot_reward = 0\n",
    "    r_em_memory = []\n",
    "    while not r_done:\n",
    "        pred_in = [list(r_old_observation) + [i] for i in range(2)]\n",
    "        r_new_action = np.argmax(RandomForest.predict(pred_in))\n",
    "        r_observation, r_reward, r_done, r_info = r_env.step(r_new_action)\n",
    "        r_tot_reward += r_reward\n",
    "        \n",
    "        r_em_memory.append({\n",
    "            \"obs0\": r_old_observation[0],\n",
    "            \"obs1\": r_old_observation[1],\n",
    "            \"obs2\": r_old_observation[2],\n",
    "            \"obs3\": r_old_observation[3],\n",
    "            \"action\": r_new_action,\n",
    "            \"reward\": r_reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        \n",
    "        r_old_observation = r_observation\n",
    "        \n",
    "    for r_em in r_em_memory:\n",
    "        r_em[\"tot_reward\"] = r_tot_reward\n",
    "        \n",
    "    r_life_memory.extend(r_em_memory)\n",
    "r_memory_df = pandas.DataFrame(r_life_memory)\n",
    "print(f\"Training time: {n() - t}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7126a344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16125, 8)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(r_life_memory).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "612c6d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161.25"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_memory_df.groupby(\"episode\").reward.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bcc4ff4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:01:20.116766s\n"
     ]
    }
   ],
   "source": [
    "t = n()\n",
    "e_life_memory = []\n",
    "e_env = gym.make('CartPole-v0')\n",
    "for i in range(num_episodes):\n",
    "    e_old_observation = e_env.reset()\n",
    "    e_done = False\n",
    "    e_tot_reward = 0\n",
    "    e_em_memory = []\n",
    "    while not e_done:\n",
    "        pred_in = [list(e_old_observation) + [i] for i in range(2)]\n",
    "        e_new_action = np.argmax(ExtraTrees.predict(pred_in))\n",
    "        e_observation, e_reward, e_done, e_info = e_env.step(e_new_action)\n",
    "        e_tot_reward += e_reward\n",
    "        e_em_memory.append({\n",
    "            \"obs0\": e_old_observation[0],\n",
    "            \"obs1\": e_old_observation[1],\n",
    "            \"obs2\": e_old_observation[2],\n",
    "            \"obs3\": e_old_observation[3],\n",
    "            \"action\": e_new_action,\n",
    "            \"reward\": e_reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        \n",
    "        e_old_observation = e_observation\n",
    "\n",
    "    for e_em in e_em_memory:\n",
    "        e_em[\"tot_reward\"] = e_tot_reward\n",
    "    e_life_memory.extend(e_em_memory)\n",
    "e_memory_df = pandas.DataFrame(e_life_memory)\n",
    "print(f\"Training time: {n() - t}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1568ec4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.03719052,  0.20216305,  0.01937592, -0.24454289]), 1.0, False, {})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_env.reset()\n",
    "e_env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e0467558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(ExtraTrees.predict([[ 0.03719052,  0.20216305,  0.01937592, -0.24454289, 1], [ 0.03719052,  0.20216305,  0.01937592, -0.24454289, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2189b699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161.25"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_memory_df.groupby(\"episode\").reward.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0b47dfb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    72\n",
       "True     28\n",
       "Name: reward, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r_memory_df.groupby(\"episode\").reward.sum() >= 200).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "619692ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.35"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_memory_df.groupby(\"episode\").reward.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8c79dd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    100\n",
       "Name: reward, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a_memory_df.groupby(\"episode\").reward.sum() >= 200).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4e3c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125.45"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_memory_df.groupby(\"episode\").reward.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "98dbe905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    88\n",
       "True     12\n",
       "Name: reward, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(e_memory_df.groupby(\"episode\").reward.sum() >= 200).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754bd40f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
