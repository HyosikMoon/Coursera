{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part i: Reinforcement Learning DEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Example\n",
    "\n",
    "In this example from Reinforcement Learning, the task is to use tools from Machine Learning to predict how an agent should act. We will then use those predictions to drive the behavior of the agent. Ideally, our intelligent agent should get a much better score than a random agent.\n",
    "\n",
    "## Key concepts:\n",
    "\n",
    "- **Observation**: These are the states of the game. It describes where the agent currently is.\n",
    "- **Action**: These are the moves that the agent makes.\n",
    "- **Episode**: One full game played from beginning (`env.reset()`) to end (when `done == True`).\n",
    "- **Step**: Part of a game that includes one action. The game transitions from one observation to the next.\n",
    "\n",
    "## Setup\n",
    "\n",
    "This exaple uses the Python library [OpenAI Gym](https://gym.openai.com/docs/).\n",
    "\n",
    "If you want to install everything (gym can run atari games.) follow [these instructions](https://github.com/openai/gym#installing-everything).\n",
    "\n",
    "Now we can build an environment using OpenAI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pandas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first part of the game uses the environment FrozenLake-V0\n",
    "\n",
    "This is a small world with 16 tiles. \n",
    "\n",
    "    SFFF\n",
    "    FHFH\n",
    "    FFFH\n",
    "    HFFG\n",
    "\n",
    "The game starts at the S tile. The object of the game is to get to the goal (G) without landing in a hole (H)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Build an environment with gym.make()\n",
    "env = gym.make('FrozenLake-v0') # build a fresh environment\n",
    "\n",
    "# Start a new game with env.reset()\n",
    "current_observation = env.reset() # this starts a new \"episode\" and returns the initial observation\n",
    "\n",
    "#the current observation is just the current location\n",
    "print(current_observation) # observations are just a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "# we can print the environment if we want to look at it\n",
    "env.render() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our action space: Discrete(4)\n",
      "our new action: 3\n"
     ]
    }
   ],
   "source": [
    "# the action space for this environment includes four discrete actions\n",
    "\n",
    "print(f\"our action space: {env.action_space}\")\n",
    "\n",
    "new_action = env.action_space.sample() # we can randomly sample actions\n",
    "\n",
    "print(f\"our new action: {new_action}\") # run this cell a few times to get an idea of the action space\n",
    "# what does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation: 1, reward: 0.0, done: False, info: {'prob': 0.3333333333333333}\n",
      "  (Up)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "# now we act! do this with the step function\n",
    "\n",
    "new_action = env.action_space.sample()\n",
    "\n",
    "observation, reward, done, info = env.step(new_action)\n",
    "\n",
    "# here's a look at what we get back\n",
    "print(f\"observation: {observation}, reward: {reward}, done: {done}, info: {info}\")\n",
    "\n",
    "env.render() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation: 1, reward: 0.0, done: False, info: {'prob': 0.3333333333333333}\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "observation: 1, reward: 0.0, done: False, info: {'prob': 0.3333333333333333}\n",
      "  (Left)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "observation: 5, reward: 0.0, done: True, info: {'prob': 0.3333333333333333}\n",
      "  (Down)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "observation: 5, reward: 0, done: True, info: {'prob': 1.0}\n",
      "  (Up)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "observation: 5, reward: 0, done: True, info: {'prob': 1.0}\n",
      "  (Down)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "# we can put this process into a for-loop and see how the game progresses\n",
    "\n",
    "current_observation = env.reset() # start a new game\n",
    "\n",
    "for i in range(5): # run 5 moves\n",
    "\n",
    "    new_action = env.action_space.sample() # same a new action\n",
    "\n",
    "    observation, reward, done, info = env.step(new_action) # step through the action and get the outputs\n",
    "\n",
    "    # here's a look at what we get back\n",
    "    print(f\"observation: {observation}, reward: {reward}, done: {done}, info: {info}\")\n",
    "\n",
    "    env.render() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can guess what each of the outputs mean. \n",
    "\n",
    "**Observation** refers to the number of the tile. The tiles appear to be numbered\n",
    "\n",
    "    0 1 2 3\n",
    "    4 5 ...\n",
    "    \n",
    "**Reward** refers to the outcome of the game. We get 1 if we win, zero otherwise.\n",
    "\n",
    "**Done** tells us if the game is still going. It goes to true when we win or fall into a hole.\n",
    "\n",
    "**info** gives extra info about the world. Here, it's probabilities. Can you guess what this means here? Perhaps the world is a bit noisy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before action: \n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "After action: \n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Before action: \n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "After action: \n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "Before action: \n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "After action: \n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "\u001b[41mH\u001b[0mFFG\n"
     ]
    }
   ],
   "source": [
    "# Here's how to simulate an entire episode\n",
    "# We're going to stop rendering it every time to save space\n",
    "# try running this a few. Does it ever win?\n",
    "\n",
    "current_observation = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:   \n",
    "    print(\"Before action: \")\n",
    "    env.render()\n",
    "    new_action = env.action_space.sample()\n",
    "    new_observation, reward, done, info = env.step(new_action)\n",
    "#     print(f\"action:{new_action} observation: {new_observation}, reward: {reward}, done: {done}, info: {info}\")\n",
    "    print(\"After action: \")\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to think about:\n",
    "- What things do you notice about how the environment and actions work?\n",
    "- What do you think the actions mean?\n",
    "- When the agent performs the same action from the same place (same observation), does the same outcome happen every time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment has some squares that always end the game (`H` in the render), some that don't (`F`), and one that is presumably the reward, if you get to it.\n",
    "\n",
    "The actions seem like up, down, left right. But they also seem stochastic. There seems to be a 1/3 chance of going into 3 different squares with each action. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Gather data\n",
    "\n",
    "We want to build an intelligent actor but first we have to gather data on which actions are useful.\n",
    "\n",
    "Use the above code as reference. Run a *random* agent through 1,000 or more episodes and collect data on each step.\n",
    "\n",
    "I recommend you store this data in a pandas dataframe. Each row should be a step. Your features should include the following features or similar \n",
    "\n",
    "- `observation` the observation at the beginning of the step (before acting!)\n",
    "- `action` the action randomly sampled\n",
    "- `current_reward` the reward received after the action was performed\n",
    "\n",
    "After you generate this data, it is recommended that you compute a column (e.g. `total_reward` that is the total reward for the entire episode).\n",
    "\n",
    "At the end of the data gathering, you should be able to use pandas (or similar) to calculate the average total reward *per episode* of the random agent. The average score should be 1-2%, meaning that the agent very rarely wins.\n",
    "\n",
    "\n",
    "## Hints\n",
    "\n",
    "- `initial_observation = env.reset()` starts a new episode and returns the initial observation.\n",
    "- `new_observation, reward, done, info = env.step(new_action)` executes one action and returns the following observation. You may look at the documentation for the step method if you are curious about what it does. \n",
    "- `done != True` until the game is finished.\n",
    "- we are trying to maximize the reward *per episode*. Our first game gives 0 reward unless the agent travels to the goal.\n",
    "- `env.action_space.n` gives the number of possible actions in the environment. `env.action_space.sample()` allows the agent to randomly sample an action.\n",
    "- `env.observation_space.n` gives the number of possible states in the environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 0:00:20.344418s\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "now = datetime.datetime.now\n",
    "t = now()\n",
    "\n",
    "env = gym.make('FrozenLake-v0')\n",
    "\n",
    "num_episodes = 70000\n",
    "\n",
    "life_memory = []\n",
    "for i in range(num_episodes):\n",
    "    \n",
    "    # start a new episode and record all the memories\n",
    "    old_observation = env.reset()\n",
    "    done = False\n",
    "    tot_reward = 0\n",
    "    ep_memory = []\n",
    "    while not done:\n",
    "        new_action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(new_action)\n",
    "        tot_reward += reward\n",
    "        \n",
    "        ep_memory.append({\n",
    "            \"observation\": old_observation,\n",
    "            \"action\": new_action,\n",
    "            \"reward\": reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        old_observation = observation\n",
    "        \n",
    "    # incorporate total reward\n",
    "    num_steps = len(ep_memory)\n",
    "    for i, ep_mem in enumerate(ep_memory):\n",
    "        ep_mem[\"tot_reward\"] = tot_reward\n",
    "        ep_mem[\"decay_reward\"] = i*tot_reward/num_steps\n",
    "        \n",
    "    life_memory.extend(ep_memory)\n",
    "\n",
    "print(f\"Training time {now() - t}s\")    \n",
    "memory_df = pandas.DataFrame(life_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>episode</th>\n",
       "      <th>tot_reward</th>\n",
       "      <th>decay_reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536022</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536023</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536024</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536025</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536026</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536027 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        observation  action  reward  episode  tot_reward  decay_reward\n",
       "0                 0       3     0.0        0         0.0           0.0\n",
       "1                 0       3     0.0        0         0.0           0.0\n",
       "2                 1       0     0.0        0         0.0           0.0\n",
       "3                 0       3     0.0        1         0.0           0.0\n",
       "4                 1       3     0.0        1         0.0           0.0\n",
       "...             ...     ...     ...      ...         ...           ...\n",
       "536022            0       2     0.0    69999         0.0           0.0\n",
       "536023            0       3     0.0    69999         0.0           0.0\n",
       "536024            1       1     0.0    69999         0.0           0.0\n",
       "536025            2       2     0.0    69999         0.0           0.0\n",
       "536026            6       0     0.0    69999         0.0           0.0\n",
       "\n",
       "[536027 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'observation': 0, 'action': 2, 'reward': 0.0, 'episode': 69999, 'tot_reward': 0.0, 'decay_reward': 0.0}\n",
      "1 {'observation': 0, 'action': 3, 'reward': 0.0, 'episode': 69999, 'tot_reward': 0.0, 'decay_reward': 0.0}\n",
      "2 {'observation': 1, 'action': 1, 'reward': 0.0, 'episode': 69999, 'tot_reward': 0.0, 'decay_reward': 0.0}\n",
      "3 {'observation': 2, 'action': 2, 'reward': 0.0, 'episode': 69999, 'tot_reward': 0.0, 'decay_reward': 0.0}\n",
      "4 {'observation': 6, 'action': 0, 'reward': 0.0, 'episode': 69999, 'tot_reward': 0.0, 'decay_reward': 0.0}\n"
     ]
    }
   ],
   "source": [
    "for i, ep_mem in enumerate(ep_memory):\n",
    "    print(i, ep_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>episode</th>\n",
       "      <th>tot_reward</th>\n",
       "      <th>decay_reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>536027.000000</td>\n",
       "      <td>536027.000000</td>\n",
       "      <td>536027.000000</td>\n",
       "      <td>536027.000000</td>\n",
       "      <td>536027.000000</td>\n",
       "      <td>536027.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.228974</td>\n",
       "      <td>1.502307</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>35066.785250</td>\n",
       "      <td>0.023719</td>\n",
       "      <td>0.010949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.996511</td>\n",
       "      <td>1.118274</td>\n",
       "      <td>0.042632</td>\n",
       "      <td>20195.101145</td>\n",
       "      <td>0.152172</td>\n",
       "      <td>0.083088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17587.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52654.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         observation         action         reward        episode  \\\n",
       "count  536027.000000  536027.000000  536027.000000  536027.000000   \n",
       "mean        2.228974       1.502307       0.001821   35066.785250   \n",
       "std         2.996511       1.118274       0.042632   20195.101145   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       1.000000       0.000000   17587.500000   \n",
       "50%         1.000000       2.000000       0.000000   35102.000000   \n",
       "75%         4.000000       3.000000       0.000000   52654.000000   \n",
       "max        14.000000       3.000000       1.000000   69999.000000   \n",
       "\n",
       "          tot_reward   decay_reward  \n",
       "count  536027.000000  536027.000000  \n",
       "mean        0.023719       0.010949  \n",
       "std         0.152172       0.083088  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       0.979167  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(536027, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory_df.groupby(\"episode\").apply(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>episode</th>\n",
       "      <th>tot_reward</th>\n",
       "      <th>decay_reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535919</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535920</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535921</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535922</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535923</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12714 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        observation  action  reward  episode  tot_reward  decay_reward\n",
       "412               0       3     0.0       57         1.0      0.000000\n",
       "413               1       2     0.0       57         1.0      0.111111\n",
       "414               2       0     0.0       57         1.0      0.222222\n",
       "415               2       3     0.0       57         1.0      0.333333\n",
       "416               1       3     0.0       57         1.0      0.444444\n",
       "...             ...     ...     ...      ...         ...           ...\n",
       "535919            8       1     0.0    69988         1.0      0.642857\n",
       "535920            8       3     0.0    69988         1.0      0.714286\n",
       "535921            9       3     0.0    69988         1.0      0.785714\n",
       "535922           10       0     0.0    69988         1.0      0.857143\n",
       "535923           14       2     1.0    69988         1.0      0.928571\n",
       "\n",
       "[12714 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_df[memory_df.tot_reward == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         1\n",
       "3         0\n",
       "4         1\n",
       "         ..\n",
       "536022    0\n",
       "536023    0\n",
       "536024    1\n",
       "536025    2\n",
       "536026    6\n",
       "Name: observation, Length: 536027, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_df.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "episode\n",
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "69995    0.0\n",
       "69996    0.0\n",
       "69997    0.0\n",
       "69998    0.0\n",
       "69999    0.0\n",
       "Name: reward, Length: 70000, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_df.groupby(\"episode\").reward.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013942857142857142"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_df.groupby(\"episode\").reward.sum().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Predict\n",
    "\n",
    "Now that you have a bunch of data, put it into a format that you can model. The goal here is to guide the behavior of our agent. Our agent will be given an observation and need to decide between the possible actions given that observation and the prediction of the model. \n",
    "\n",
    "Remember, you're a data scientist! Be creative. \n",
    "\n",
    "It might be helpful to work backwards. Ultimately, you will write something like:\n",
    "\n",
    "```\n",
    "def convert_to_row(obs, act):\n",
    "    # expertly written code\n",
    "    return row_of_obs_act\n",
    "    \n",
    "rows = [convert_to_row(current_obs, act) for act in possible_actions]\n",
    "\n",
    "pred_outcome = model.predict(rows)\n",
    "```\n",
    "\n",
    "So, you will need to design a quantity that you can ask your model to predict for every possible action-observation pair. Think a bit about what this quantity should be. Should the model try to predict the immediate reward for each action? If so, how would it know where to go at the beginning of each episode when all moves give zero reward but when some moves bring it closer to the goal than others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "# from sklearn.svm import SVR\n",
    "\n",
    "# model = ExtraTreesRegressor(n_estimators=50)\n",
    "# # model = SVR()\n",
    "# y = 0.5*memory_df.reward + 0.1*memory_df.decay_reward + memory_df.tot_reward\n",
    "# x = memory_df[[\"observation\", \"action\"]]\n",
    "# model.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Act\n",
    "\n",
    "Now that you have a model that predicts the desired behavior, let's act on it! Modify the code you used to gather data so that you replace the random decision with an intelligent one.\n",
    "\n",
    "We started out winning ~1.5% of the games with the random agent. How well can you do? You should be able to get your model to do at least 10x better (so 15%). Can you get ~50%?\n",
    "\n",
    "If you're having trouble, tune your model. Try different representations of the observation and action spaces. Try different models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:00s\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now\n",
    "t = now()\n",
    "print(f\"Training time: {now() - t}s\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now = datetime.datetime.now\n",
    "# t = now()\n",
    "\n",
    "# model = RandomForestRegressor()\n",
    "# y = 1*memory_df.reward + memory_df.tot_reward + .1*memory_df.decay_reward\n",
    "# x = memory_df[[\"observation\", \"action\"]]\n",
    "# model.fit(x, y)\n",
    "\n",
    "# num_episodes = 3000\n",
    "# random_per = 0\n",
    "\n",
    "# life_memory = []\n",
    "# for i in range(num_episodes):\n",
    "    \n",
    "#     # start a new episode and record all the memories\n",
    "#     old_observation = env.reset()\n",
    "#     done = False\n",
    "#     tot_reward = 0\n",
    "#     ep_memory = []\n",
    "#     while not done:      \n",
    "#         if np.random.rand() < random_per:\n",
    "#             new_action = env.action_space.sample()\n",
    "#         else:\n",
    "#             pred_in = [[old_observation,i] for i in range(4)]\n",
    "#             new_action = np.argmax(model.predict(pred_in))\n",
    "#         observation, reward, done, info = env.step(new_action)\n",
    "#         tot_reward += reward\n",
    "        \n",
    "#         ep_memory.append({\n",
    "#             \"observation\": old_observation,\n",
    "#             \"action\": new_action,\n",
    "#             \"reward\": reward,\n",
    "#             \"episode\": i,\n",
    "#         })\n",
    "#         old_observation = observation\n",
    "        \n",
    "#     # incorporate total reward\n",
    "#     for ep_mem in ep_memory:\n",
    "#         ep_mem[\"tot_reward\"] = tot_reward\n",
    "        \n",
    "#     life_memory.extend(ep_memory)\n",
    "# print(f\"Training time: {now() - t}\")    \n",
    "# memory_df2 = pandas.DataFrame(life_memory)\n",
    "\n",
    "# # rf.fit(memory_df[[\"observation\", \"action\"]], memory_df[\"comb_reward\"])\n",
    "\n",
    "# # score\n",
    "# # much better!\n",
    "# memory_df2.groupby(\"episode\").reward.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 0:05:44.834588s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.704"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Practice\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "now = datetime.datetime.now\n",
    "t = now()\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "y = 1*memory_df.reward + memory_df.tot_reward + .1*memory_df.decay_reward\n",
    "x = memory_df[[\"observation\", \"action\"]]\n",
    "model.fit(x, y)\n",
    "\n",
    "num_episodes = 500\n",
    "random_per = 0\n",
    "life_memory = []\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    old_observation = env.reset()\n",
    "    done = False\n",
    "    tot_reward = 0\n",
    "    ep_memory = []\n",
    "    while not done:\n",
    "        if np.random.rand() < random_per:\n",
    "            new_action = env.action_space.sample()\n",
    "        else:\n",
    "            pred_in = [[old_observation, i] for i in range(4)]\n",
    "            new_action = np.argmax(model.predict(pred_in))\n",
    "        observation, reward, done, info = env.step(new_action)\n",
    "        tot_reward += reward\n",
    "        \n",
    "        ep_memory.append({\n",
    "            \"observation\": old_observation,\n",
    "            \"action\": new_action, \n",
    "            \"reward\": reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        old_observation = observation\n",
    "        \n",
    "    for ep_mem in ep_memory:\n",
    "        ep_mem[\"tot_reward\"] = tot_reward\n",
    "    \n",
    "    life_memory.extend(ep_memory)\n",
    "\n",
    "print(f\"Training time {now() - t}s\")\n",
    "memory_df2 = pd.DataFrame(life_memory)\n",
    "\n",
    "np.mean(memory_df2.groupby(\"episode\").reward.sum())\n",
    "# memory_df2.groupby(\"episode\").reward.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>episode</th>\n",
       "      <th>tot_reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19455</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19456</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19457</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19458</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19459</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>499</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19460 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       observation  action  reward  episode  tot_reward\n",
       "0                0       0     0.0        0         0.0\n",
       "1                0       0     0.0        0         0.0\n",
       "2                0       0     0.0        0         0.0\n",
       "3                4       0     0.0        0         0.0\n",
       "4                8       3     0.0        0         0.0\n",
       "...            ...     ...     ...      ...         ...\n",
       "19455            8       3     0.0      499         1.0\n",
       "19456            8       3     0.0      499         1.0\n",
       "19457            9       1     0.0      499         1.0\n",
       "19458           13       2     0.0      499         1.0\n",
       "19459           14       1     1.0      499         1.0\n",
       "\n",
       "[19460 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = .1*memory_df.reward + 1*memory_df.decay_reward + 1*memory_df.tot_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension: Pole cart\n",
    "\n",
    "If time permits, try your hand at pole cart (`env = gym.make('CartPole-v0')`).\n",
    "\n",
    "Notice that the observation space is quite different. It's no longer discrete--instead we have 4 continuous values. You'll have to store these differently from how you did with Frozenlake.\n",
    "\n",
    "My random actor actually does surprisingly well (avg ~22). But my intelligent agent is able to score ~99. Can you beat me? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pole cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.env?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.751"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can build a toy world!\n",
    "num_episodes = 1000\n",
    "\n",
    "life_memory = []\n",
    "for i in range(num_episodes):\n",
    "    \n",
    "    # start a new episode and record all the memories\n",
    "    old_observation = env.reset()\n",
    "    done = False\n",
    "    tot_reward = 0\n",
    "    ep_memory = []\n",
    "    while not done:\n",
    "        new_action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(new_action)\n",
    "        tot_reward += reward\n",
    "        \n",
    "        ep_memory.append({\n",
    "            \"obs0\": old_observation[0],\n",
    "            \"obs1\": old_observation[1],\n",
    "            \"obs2\": old_observation[2],\n",
    "            \"obs3\": old_observation[3],\n",
    "            \"action\": new_action,\n",
    "            \"reward\": reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        old_observation = observation\n",
    "        \n",
    "    # incorporate total reward\n",
    "    for ep_mem in ep_memory:\n",
    "        ep_mem[\"tot_reward\"] = tot_reward\n",
    "        \n",
    "    life_memory.extend(ep_memory)\n",
    "    \n",
    "memory_df = pandas.DataFrame(life_memory)\n",
    "\n",
    "memory_df.groupby(\"episode\").reward.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs0</th>\n",
       "      <th>obs1</th>\n",
       "      <th>obs2</th>\n",
       "      <th>obs3</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>episode</th>\n",
       "      <th>tot_reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.009359</td>\n",
       "      <td>0.047097</td>\n",
       "      <td>-0.022057</td>\n",
       "      <td>0.015836</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.008417</td>\n",
       "      <td>-0.147701</td>\n",
       "      <td>-0.021740</td>\n",
       "      <td>0.301479</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.011371</td>\n",
       "      <td>-0.342507</td>\n",
       "      <td>-0.015711</td>\n",
       "      <td>0.587227</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.018221</td>\n",
       "      <td>-0.147168</td>\n",
       "      <td>-0.003966</td>\n",
       "      <td>0.289637</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.021164</td>\n",
       "      <td>0.048010</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>-0.004294</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21746</th>\n",
       "      <td>0.094145</td>\n",
       "      <td>-0.354251</td>\n",
       "      <td>-0.199186</td>\n",
       "      <td>0.136198</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21747</th>\n",
       "      <td>0.087060</td>\n",
       "      <td>-0.156916</td>\n",
       "      <td>-0.196462</td>\n",
       "      <td>-0.212125</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21748</th>\n",
       "      <td>0.083921</td>\n",
       "      <td>-0.348766</td>\n",
       "      <td>-0.200704</td>\n",
       "      <td>0.012725</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21749</th>\n",
       "      <td>0.076946</td>\n",
       "      <td>-0.151417</td>\n",
       "      <td>-0.200450</td>\n",
       "      <td>-0.335969</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21750</th>\n",
       "      <td>0.073918</td>\n",
       "      <td>0.045909</td>\n",
       "      <td>-0.207169</td>\n",
       "      <td>-0.684570</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21751 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
       "0     -0.009359  0.047097 -0.022057  0.015836       0     1.0        0   \n",
       "1     -0.008417 -0.147701 -0.021740  0.301479       0     1.0        0   \n",
       "2     -0.011371 -0.342507 -0.015711  0.587227       1     1.0        0   \n",
       "3     -0.018221 -0.147168 -0.003966  0.289637       1     1.0        0   \n",
       "4     -0.021164  0.048010  0.001827 -0.004294       0     1.0        0   \n",
       "...         ...       ...       ...       ...     ...     ...      ...   \n",
       "21746  0.094145 -0.354251 -0.199186  0.136198       1     1.0      999   \n",
       "21747  0.087060 -0.156916 -0.196462 -0.212125       0     1.0      999   \n",
       "21748  0.083921 -0.348766 -0.200704  0.012725       1     1.0      999   \n",
       "21749  0.076946 -0.151417 -0.200450 -0.335969       1     1.0      999   \n",
       "21750  0.073918  0.045909 -0.207169 -0.684570       0     1.0      999   \n",
       "\n",
       "       tot_reward  \n",
       "0            21.0  \n",
       "1            21.0  \n",
       "2            21.0  \n",
       "3            21.0  \n",
       "4            21.0  \n",
       "...           ...  \n",
       "21746        25.0  \n",
       "21747        25.0  \n",
       "21748        25.0  \n",
       "21749        25.0  \n",
       "21750        25.0  \n",
       "\n",
       "[21751 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs0</th>\n",
       "      <th>obs1</th>\n",
       "      <th>obs2</th>\n",
       "      <th>obs3</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>episode</th>\n",
       "      <th>tot_reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21751.000000</td>\n",
       "      <td>21751.000000</td>\n",
       "      <td>21751.000000</td>\n",
       "      <td>21751.000000</td>\n",
       "      <td>21751.000000</td>\n",
       "      <td>21751.0</td>\n",
       "      <td>21751.000000</td>\n",
       "      <td>21751.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.018099</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.020843</td>\n",
       "      <td>0.495517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>497.780148</td>\n",
       "      <td>28.161142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.086541</td>\n",
       "      <td>0.535357</td>\n",
       "      <td>0.093025</td>\n",
       "      <td>0.791504</td>\n",
       "      <td>0.499991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.625136</td>\n",
       "      <td>15.604871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.914600</td>\n",
       "      <td>-2.256016</td>\n",
       "      <td>-0.209377</td>\n",
       "      <td>-2.766460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.039968</td>\n",
       "      <td>-0.370245</td>\n",
       "      <td>-0.052440</td>\n",
       "      <td>-0.488695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>250.500000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002352</td>\n",
       "      <td>-0.010875</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.041763</td>\n",
       "      <td>0.345232</td>\n",
       "      <td>0.056567</td>\n",
       "      <td>0.550996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>747.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.764300</td>\n",
       "      <td>2.308623</td>\n",
       "      <td>0.209434</td>\n",
       "      <td>2.760805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               obs0          obs1          obs2          obs3        action  \\\n",
       "count  21751.000000  21751.000000  21751.000000  21751.000000  21751.000000   \n",
       "mean      -0.000117     -0.018099      0.001839      0.020843      0.495517   \n",
       "std        0.086541      0.535357      0.093025      0.791504      0.499991   \n",
       "min       -0.914600     -2.256016     -0.209377     -2.766460      0.000000   \n",
       "25%       -0.039968     -0.370245     -0.052440     -0.488695      0.000000   \n",
       "50%        0.002352     -0.010875      0.000935      0.011560      0.000000   \n",
       "75%        0.041763      0.345232      0.056567      0.550996      1.000000   \n",
       "max        0.764300      2.308623      0.209434      2.760805      1.000000   \n",
       "\n",
       "        reward       episode    tot_reward  \n",
       "count  21751.0  21751.000000  21751.000000  \n",
       "mean       1.0    497.780148     28.161142  \n",
       "std        0.0    289.625136     15.604871  \n",
       "min        1.0      0.000000      8.000000  \n",
       "25%        1.0    250.500000     17.000000  \n",
       "50%        1.0    494.000000     23.000000  \n",
       "75%        1.0    747.000000     36.000000  \n",
       "max        1.0    999.000000     95.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(n_estimators=50)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "\n",
    "model = ExtraTreesRegressor(n_estimators=50)\n",
    "\n",
    "memory_df[\"comb_reward\"] = .5*memory_df.reward + memory_df.tot_reward\n",
    "model.fit(memory_df[[\"obs0\", \"obs1\", \"obs2\", \"obs3\", \"action\"]], memory_df.comb_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs0</th>\n",
       "      <th>obs1</th>\n",
       "      <th>obs2</th>\n",
       "      <th>obs3</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>episode</th>\n",
       "      <th>tot_reward</th>\n",
       "      <th>comb_reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.009359</td>\n",
       "      <td>0.047097</td>\n",
       "      <td>-0.022057</td>\n",
       "      <td>0.015836</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.008417</td>\n",
       "      <td>-0.147701</td>\n",
       "      <td>-0.021740</td>\n",
       "      <td>0.301479</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.011371</td>\n",
       "      <td>-0.342507</td>\n",
       "      <td>-0.015711</td>\n",
       "      <td>0.587227</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.018221</td>\n",
       "      <td>-0.147168</td>\n",
       "      <td>-0.003966</td>\n",
       "      <td>0.289637</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.021164</td>\n",
       "      <td>0.048010</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>-0.004294</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21746</th>\n",
       "      <td>0.094145</td>\n",
       "      <td>-0.354251</td>\n",
       "      <td>-0.199186</td>\n",
       "      <td>0.136198</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21747</th>\n",
       "      <td>0.087060</td>\n",
       "      <td>-0.156916</td>\n",
       "      <td>-0.196462</td>\n",
       "      <td>-0.212125</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21748</th>\n",
       "      <td>0.083921</td>\n",
       "      <td>-0.348766</td>\n",
       "      <td>-0.200704</td>\n",
       "      <td>0.012725</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21749</th>\n",
       "      <td>0.076946</td>\n",
       "      <td>-0.151417</td>\n",
       "      <td>-0.200450</td>\n",
       "      <td>-0.335969</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21750</th>\n",
       "      <td>0.073918</td>\n",
       "      <td>0.045909</td>\n",
       "      <td>-0.207169</td>\n",
       "      <td>-0.684570</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21751 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
       "0     -0.009359  0.047097 -0.022057  0.015836       0     1.0        0   \n",
       "1     -0.008417 -0.147701 -0.021740  0.301479       0     1.0        0   \n",
       "2     -0.011371 -0.342507 -0.015711  0.587227       1     1.0        0   \n",
       "3     -0.018221 -0.147168 -0.003966  0.289637       1     1.0        0   \n",
       "4     -0.021164  0.048010  0.001827 -0.004294       0     1.0        0   \n",
       "...         ...       ...       ...       ...     ...     ...      ...   \n",
       "21746  0.094145 -0.354251 -0.199186  0.136198       1     1.0      999   \n",
       "21747  0.087060 -0.156916 -0.196462 -0.212125       0     1.0      999   \n",
       "21748  0.083921 -0.348766 -0.200704  0.012725       1     1.0      999   \n",
       "21749  0.076946 -0.151417 -0.200450 -0.335969       1     1.0      999   \n",
       "21750  0.073918  0.045909 -0.207169 -0.684570       0     1.0      999   \n",
       "\n",
       "       tot_reward  comb_reward  \n",
       "0            21.0         21.5  \n",
       "1            21.0         21.5  \n",
       "2            21.0         21.5  \n",
       "3            21.0         21.5  \n",
       "4            21.0         21.5  \n",
       "...           ...          ...  \n",
       "21746        25.0         25.5  \n",
       "21747        25.0         25.5  \n",
       "21748        25.0         25.5  \n",
       "21749        25.0         25.5  \n",
       "21750        25.0         25.5  \n",
       "\n",
       "[21751 rows x 9 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.env?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0:01:41.950757s\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "n = datetime.datetime.now\n",
    "t = n()\n",
    "\n",
    "num_episodes = 100\n",
    "random_per = 0\n",
    "\n",
    "life_memory = []\n",
    "for i in range(num_episodes):\n",
    "    \n",
    "    # start a new episode and record all the memories\n",
    "    old_observation = env.reset()\n",
    "    done = False\n",
    "    tot_reward = 0\n",
    "    ep_memory = []\n",
    "    while not done:\n",
    "        \n",
    "        \n",
    "        if np.random.rand() < random_per:\n",
    "            new_action = env.action_space.sample()\n",
    "        else:\n",
    "            pred_in = [list(old_observation)+[i] for i in range(2)]\n",
    "            new_action = np.argmax(model.predict(pred_in))\n",
    "        observation, reward, done, info = env.step(new_action)\n",
    "        tot_reward += reward\n",
    "        \n",
    "        ep_memory.append({\n",
    "            \"obs0\": old_observation[0],\n",
    "            \"obs1\": old_observation[1],\n",
    "            \"obs2\": old_observation[2],\n",
    "            \"obs3\": old_observation[3],\n",
    "            \"action\": new_action,\n",
    "            \"reward\": reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        old_observation = observation\n",
    "        \n",
    "    # incorporate total reward\n",
    "    for ep_mem in ep_memory:\n",
    "        ep_mem[\"tot_reward\"] = tot_reward\n",
    "        \n",
    "    life_memory.extend(ep_memory)\n",
    "    \n",
    "memory_df2 = pandas.DataFrame(life_memory)\n",
    "memory_df2[\"comb_reward\"] = memory_df2.reward + memory_df2.tot_reward\n",
    "\n",
    "# score\n",
    "# much better!\n",
    "memory_df2.groupby(\"episode\").reward.sum().mean()\n",
    "\n",
    "print(f\"training time: {n() - t}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs0</th>\n",
       "      <th>obs1</th>\n",
       "      <th>obs2</th>\n",
       "      <th>obs3</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>episode</th>\n",
       "      <th>tot_reward</th>\n",
       "      <th>comb_reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009780</td>\n",
       "      <td>0.009512</td>\n",
       "      <td>0.036042</td>\n",
       "      <td>-0.044225</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009970</td>\n",
       "      <td>0.204099</td>\n",
       "      <td>0.035158</td>\n",
       "      <td>-0.325322</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014052</td>\n",
       "      <td>0.008495</td>\n",
       "      <td>0.028651</td>\n",
       "      <td>-0.021762</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014222</td>\n",
       "      <td>0.203194</td>\n",
       "      <td>0.028216</td>\n",
       "      <td>-0.305270</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018286</td>\n",
       "      <td>0.007682</td>\n",
       "      <td>0.022111</td>\n",
       "      <td>-0.003823</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11609</th>\n",
       "      <td>-0.730055</td>\n",
       "      <td>-1.531049</td>\n",
       "      <td>0.079357</td>\n",
       "      <td>0.951753</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99</td>\n",
       "      <td>71.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11610</th>\n",
       "      <td>-0.760676</td>\n",
       "      <td>-1.727144</td>\n",
       "      <td>0.098392</td>\n",
       "      <td>1.268276</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99</td>\n",
       "      <td>71.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11611</th>\n",
       "      <td>-0.795219</td>\n",
       "      <td>-1.923375</td>\n",
       "      <td>0.123757</td>\n",
       "      <td>1.590080</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99</td>\n",
       "      <td>71.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11612</th>\n",
       "      <td>-0.833686</td>\n",
       "      <td>-2.119730</td>\n",
       "      <td>0.155559</td>\n",
       "      <td>1.918652</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99</td>\n",
       "      <td>71.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11613</th>\n",
       "      <td>-0.876081</td>\n",
       "      <td>-1.926586</td>\n",
       "      <td>0.193932</td>\n",
       "      <td>1.677984</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99</td>\n",
       "      <td>71.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11614 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
       "0      0.009780  0.009512  0.036042 -0.044225       1     1.0        0   \n",
       "1      0.009970  0.204099  0.035158 -0.325322       0     1.0        0   \n",
       "2      0.014052  0.008495  0.028651 -0.021762       1     1.0        0   \n",
       "3      0.014222  0.203194  0.028216 -0.305270       0     1.0        0   \n",
       "4      0.018286  0.007682  0.022111 -0.003823       0     1.0        0   \n",
       "...         ...       ...       ...       ...     ...     ...      ...   \n",
       "11609 -0.730055 -1.531049  0.079357  0.951753       0     1.0       99   \n",
       "11610 -0.760676 -1.727144  0.098392  1.268276       0     1.0       99   \n",
       "11611 -0.795219 -1.923375  0.123757  1.590080       0     1.0       99   \n",
       "11612 -0.833686 -2.119730  0.155559  1.918652       1     1.0       99   \n",
       "11613 -0.876081 -1.926586  0.193932  1.677984       0     1.0       99   \n",
       "\n",
       "       tot_reward  comb_reward  \n",
       "0            88.0         89.0  \n",
       "1            88.0         89.0  \n",
       "2            88.0         89.0  \n",
       "3            88.0         89.0  \n",
       "4            88.0         89.0  \n",
       "...           ...          ...  \n",
       "11609        71.0         72.0  \n",
       "11610        71.0         72.0  \n",
       "11611        71.0         72.0  \n",
       "11612        71.0         72.0  \n",
       "11613        71.0         72.0  \n",
       "\n",
       "[11614 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "0   0.009780  0.009512  0.036042 -0.044225       1     1.0        0   \n",
      "1   0.009970  0.204099  0.035158 -0.325322       0     1.0        0   \n",
      "2   0.014052  0.008495  0.028651 -0.021762       1     1.0        0   \n",
      "3   0.014222  0.203194  0.028216 -0.305270       0     1.0        0   \n",
      "4   0.018286  0.007682  0.022111 -0.003823       0     1.0        0   \n",
      "..       ...       ...       ...       ...     ...     ...      ...   \n",
      "83 -0.558270 -1.314114  0.085314  1.076235       0     1.0        0   \n",
      "84 -0.584553 -1.510253  0.106839  1.394425       1     1.0        0   \n",
      "85 -0.614758 -1.316611  0.134727  1.136968       0     1.0        0   \n",
      "86 -0.641090 -1.513213  0.157467  1.468689       0     1.0        0   \n",
      "87 -0.671354 -1.709872  0.186840  1.806132       0     1.0        0   \n",
      "\n",
      "    tot_reward  comb_reward  \n",
      "0         88.0         89.0  \n",
      "1         88.0         89.0  \n",
      "2         88.0         89.0  \n",
      "3         88.0         89.0  \n",
      "4         88.0         89.0  \n",
      "..         ...          ...  \n",
      "83        88.0         89.0  \n",
      "84        88.0         89.0  \n",
      "85        88.0         89.0  \n",
      "86        88.0         89.0  \n",
      "87        88.0         89.0  \n",
      "\n",
      "[88 rows x 9 columns]\n",
      "         obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "88   0.039138  0.040534  0.039218  0.019996       1     1.0        1   \n",
      "89   0.039948  0.235072  0.039618 -0.260060       1     1.0        1   \n",
      "90   0.044650  0.429607  0.034417 -0.539988       0     1.0        1   \n",
      "91   0.053242  0.234019  0.023617 -0.236663       1     1.0        1   \n",
      "92   0.057922  0.428795  0.018884 -0.521804       1     1.0        1   \n",
      "..        ...       ...       ...       ...     ...     ...      ...   \n",
      "221 -0.716693 -1.659327  0.049105  1.414638       0     1.0        1   \n",
      "222 -0.749879 -1.855022  0.077398  1.722257       0     1.0        1   \n",
      "223 -0.786980 -2.050940  0.111843  2.037987       1     1.0        1   \n",
      "224 -0.827999 -1.857133  0.152603  1.781906       0     1.0        1   \n",
      "225 -0.865141 -2.053607  0.188241  2.117883       1     1.0        1   \n",
      "\n",
      "     tot_reward  comb_reward  \n",
      "88        138.0        139.0  \n",
      "89        138.0        139.0  \n",
      "90        138.0        139.0  \n",
      "91        138.0        139.0  \n",
      "92        138.0        139.0  \n",
      "..          ...          ...  \n",
      "221       138.0        139.0  \n",
      "222       138.0        139.0  \n",
      "223       138.0        139.0  \n",
      "224       138.0        139.0  \n",
      "225       138.0        139.0  \n",
      "\n",
      "[138 rows x 9 columns]\n",
      "         obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "226 -0.041354  0.020813 -0.008288  0.010642       0     1.0        2   \n",
      "227 -0.040938 -0.174189 -0.008075  0.300698       1     1.0        2   \n",
      "228 -0.044421  0.021047 -0.002061  0.005480       0     1.0        2   \n",
      "229 -0.044000 -0.174045 -0.001952  0.297511       0     1.0        2   \n",
      "230 -0.047481 -0.369139  0.003998  0.589578       1     1.0        2   \n",
      "..        ...       ...       ...       ...     ...     ...      ...   \n",
      "417  0.641916  1.359964 -0.048228 -1.450046       1     1.0        2   \n",
      "418  0.669115  1.555645 -0.077229 -1.757399       1     1.0        2   \n",
      "419  0.700228  1.751552 -0.112377 -2.073067       1     1.0        2   \n",
      "420  0.735259  1.947622 -0.153838 -2.398285       1     1.0        2   \n",
      "421  0.774211  2.143718 -0.201804 -2.734007       1     1.0        2   \n",
      "\n",
      "     tot_reward  comb_reward  \n",
      "226       196.0        197.0  \n",
      "227       196.0        197.0  \n",
      "228       196.0        197.0  \n",
      "229       196.0        197.0  \n",
      "230       196.0        197.0  \n",
      "..          ...          ...  \n",
      "417       196.0        197.0  \n",
      "418       196.0        197.0  \n",
      "419       196.0        197.0  \n",
      "420       196.0        197.0  \n",
      "421       196.0        197.0  \n",
      "\n",
      "[196 rows x 9 columns]\n",
      "         obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "422  0.038835  0.008902  0.046400  0.031981       0     1.0        3   \n",
      "423  0.039013 -0.186854  0.047039  0.338935       1     1.0        3   \n",
      "424  0.035276  0.007569  0.053818  0.061449       1     1.0        3   \n",
      "425  0.035427  0.201879  0.055047 -0.213780       1     1.0        3   \n",
      "426  0.039465  0.396173  0.050772 -0.488603       0     1.0        3   \n",
      "..        ...       ...       ...       ...     ...     ...      ...   \n",
      "497  0.899729  1.687741 -0.069325 -0.900117       1     1.0        3   \n",
      "498  0.933484  1.883731 -0.087327 -1.213760       1     1.0        3   \n",
      "499  0.971159  2.079864 -0.111602 -1.532481       1     1.0        3   \n",
      "500  1.012756  2.276140 -0.142252 -1.857806       1     1.0        3   \n",
      "501  1.058279  2.472509 -0.179408 -2.191065       1     1.0        3   \n",
      "\n",
      "     tot_reward  comb_reward  \n",
      "422        80.0         81.0  \n",
      "423        80.0         81.0  \n",
      "424        80.0         81.0  \n",
      "425        80.0         81.0  \n",
      "426        80.0         81.0  \n",
      "..          ...          ...  \n",
      "497        80.0         81.0  \n",
      "498        80.0         81.0  \n",
      "499        80.0         81.0  \n",
      "500        80.0         81.0  \n",
      "501        80.0         81.0  \n",
      "\n",
      "[80 rows x 9 columns]\n",
      "         obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "502 -0.040076  0.000529 -0.040364 -0.016020       1     1.0        4   \n",
      "503 -0.040065  0.196206 -0.040684 -0.321160       0     1.0        4   \n",
      "504 -0.036141  0.001686 -0.047108 -0.041580       0     1.0        4   \n",
      "505 -0.036107 -0.192730 -0.047939  0.235876       1     1.0        4   \n",
      "506 -0.039962  0.003043 -0.043222 -0.071535       1     1.0        4   \n",
      "..        ...       ...       ...       ...     ...     ...      ...   \n",
      "565 -0.654141 -1.310909  0.101854  0.836263       0     1.0        4   \n",
      "566 -0.680359 -1.507263  0.118579  1.159162       0     1.0        4   \n",
      "567 -0.710504 -1.703714  0.141762  1.486548       0     1.0        4   \n",
      "568 -0.744579 -1.900250  0.171493  1.819934       0     1.0        4   \n",
      "569 -0.782584 -2.096813  0.207892  2.160626       1     1.0        4   \n",
      "\n",
      "     tot_reward  comb_reward  \n",
      "502        68.0         69.0  \n",
      "503        68.0         69.0  \n",
      "504        68.0         69.0  \n",
      "505        68.0         69.0  \n",
      "506        68.0         69.0  \n",
      "..          ...          ...  \n",
      "565        68.0         69.0  \n",
      "566        68.0         69.0  \n",
      "567        68.0         69.0  \n",
      "568        68.0         69.0  \n",
      "569        68.0         69.0  \n",
      "\n",
      "[68 rows x 9 columns]\n",
      "         obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "570  0.014364 -0.009144  0.002646 -0.036300       1     1.0        5   \n",
      "571  0.014181  0.185939  0.001920 -0.328147       0     1.0        5   \n",
      "572  0.017900 -0.009210 -0.004642 -0.034859       1     1.0        5   \n",
      "573  0.017715  0.185978 -0.005340 -0.329003       0     1.0        5   \n",
      "574  0.021435 -0.009067 -0.011920 -0.038009       1     1.0        5   \n",
      "..        ...       ...       ...       ...     ...     ...      ...   \n",
      "765 -0.047418  0.167324  0.035954  0.082520       0     1.0        5   \n",
      "766 -0.044072 -0.028295  0.037604  0.386326       1     1.0        5   \n",
      "767 -0.044638  0.166274  0.045331  0.105733       1     1.0        5   \n",
      "768 -0.041312  0.360718  0.047445 -0.172311       1     1.0        5   \n",
      "769 -0.034098  0.555130  0.043999 -0.449657       1     1.0        5   \n",
      "\n",
      "     tot_reward  comb_reward  \n",
      "570       200.0        201.0  \n",
      "571       200.0        201.0  \n",
      "572       200.0        201.0  \n",
      "573       200.0        201.0  \n",
      "574       200.0        201.0  \n",
      "..          ...          ...  \n",
      "765       200.0        201.0  \n",
      "766       200.0        201.0  \n",
      "767       200.0        201.0  \n",
      "768       200.0        201.0  \n",
      "769       200.0        201.0  \n",
      "\n",
      "[200 rows x 9 columns]\n",
      "         obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "770 -0.014021  0.034775 -0.024721 -0.048671       1     1.0        6   \n",
      "771 -0.013326  0.230243 -0.025695 -0.349050       1     1.0        6   \n",
      "772 -0.008721  0.425721 -0.032676 -0.649724       0     1.0        6   \n",
      "773 -0.000207  0.231069 -0.045670 -0.367507       0     1.0        6   \n",
      "774  0.004415  0.036624 -0.053021 -0.089567       0     1.0        6   \n",
      "..        ...       ...       ...       ...     ...     ...      ...   \n",
      "841 -0.580267 -1.287966  0.088206  1.052448       0     1.0        6   \n",
      "842 -0.606026 -1.484140  0.109255  1.371463       1     1.0        6   \n",
      "843 -0.635709 -1.290540  0.136685  1.114853       0     1.0        6   \n",
      "844 -0.661520 -1.487166  0.158982  1.447101       0     1.0        6   \n",
      "845 -0.691263 -1.683846  0.187924  1.784944       0     1.0        6   \n",
      "\n",
      "     tot_reward  comb_reward  \n",
      "770        76.0         77.0  \n",
      "771        76.0         77.0  \n",
      "772        76.0         77.0  \n",
      "773        76.0         77.0  \n",
      "774        76.0         77.0  \n",
      "..          ...          ...  \n",
      "841        76.0         77.0  \n",
      "842        76.0         77.0  \n",
      "843        76.0         77.0  \n",
      "844        76.0         77.0  \n",
      "845        76.0         77.0  \n",
      "\n",
      "[76 rows x 9 columns]\n",
      "         obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "846 -0.048449 -0.035718 -0.038069  0.021622       0     1.0        7   \n",
      "847 -0.049164 -0.230274 -0.037636  0.302055       1     1.0        7   \n",
      "848 -0.053769 -0.034636 -0.031595 -0.002256       0     1.0        7   \n",
      "849 -0.054462 -0.229291 -0.031640  0.280293       1     1.0        7   \n",
      "850 -0.059048 -0.033732 -0.026034 -0.022199       0     1.0        7   \n",
      "..        ...       ...       ...       ...     ...     ...      ...   \n",
      "935 -0.516259 -1.372046  0.092196  1.423527       1     1.0        7   \n",
      "936 -0.543700 -1.178177  0.120667  1.161026       0     1.0        7   \n",
      "937 -0.567263 -1.374646  0.143887  1.488977       1     1.0        7   \n",
      "938 -0.594756 -1.181540  0.173667  1.244468       0     1.0        7   \n",
      "939 -0.618387 -1.378412  0.198556  1.586135       0     1.0        7   \n",
      "\n",
      "     tot_reward  comb_reward  \n",
      "846        94.0         95.0  \n",
      "847        94.0         95.0  \n",
      "848        94.0         95.0  \n",
      "849        94.0         95.0  \n",
      "850        94.0         95.0  \n",
      "..          ...          ...  \n",
      "935        94.0         95.0  \n",
      "936        94.0         95.0  \n",
      "937        94.0         95.0  \n",
      "938        94.0         95.0  \n",
      "939        94.0         95.0  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "940  -0.022899 -0.002000 -0.026444  0.033869       0     1.0        8   \n",
      "941  -0.022939 -0.196733 -0.025767  0.318092       0     1.0        8   \n",
      "942  -0.026874 -0.391479 -0.019405  0.602539       1     1.0        8   \n",
      "943  -0.034704 -0.196091 -0.007354  0.303808       0     1.0        8   \n",
      "944  -0.038625 -0.391107 -0.001278  0.594162       1     1.0        8   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "1013 -0.129182  0.226606 -0.103824 -1.001849       1     1.0        8   \n",
      "1014 -0.124650  0.422950 -0.123861 -1.325249       0     1.0        8   \n",
      "1015 -0.116191  0.229591 -0.150366 -1.073754       1     1.0        8   \n",
      "1016 -0.111599  0.426345 -0.171841 -1.409597       1     1.0        8   \n",
      "1017 -0.103072  0.623131 -0.200033 -1.750701       0     1.0        8   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "940         78.0         79.0  \n",
      "941         78.0         79.0  \n",
      "942         78.0         79.0  \n",
      "943         78.0         79.0  \n",
      "944         78.0         79.0  \n",
      "...          ...          ...  \n",
      "1013        78.0         79.0  \n",
      "1014        78.0         79.0  \n",
      "1015        78.0         79.0  \n",
      "1016        78.0         79.0  \n",
      "1017        78.0         79.0  \n",
      "\n",
      "[78 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "1018  0.006568  0.027731 -0.044520  0.000857       1     1.0        9   \n",
      "1019  0.007122  0.223462 -0.044503 -0.305534       1     1.0        9   \n",
      "1020  0.011592  0.419189 -0.050614 -0.611913       1     1.0        9   \n",
      "1021  0.019975  0.614980 -0.062852 -0.920098       1     1.0        9   \n",
      "1022  0.032275  0.810893 -0.081254 -1.231853       0     1.0        9   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "1081 -0.609465 -1.285952  0.116646  0.904442       0     1.0        9   \n",
      "1082 -0.635184 -1.482444  0.134735  1.231394       1     1.0        9   \n",
      "1083 -0.664832 -1.289287  0.159363  0.983777       0     1.0        9   \n",
      "1084 -0.690618 -1.486144  0.179039  1.321975       0     1.0        9   \n",
      "1085 -0.720341 -1.683018  0.205478  1.664923       0     1.0        9   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "1018        68.0         69.0  \n",
      "1019        68.0         69.0  \n",
      "1020        68.0         69.0  \n",
      "1021        68.0         69.0  \n",
      "1022        68.0         69.0  \n",
      "...          ...          ...  \n",
      "1081        68.0         69.0  \n",
      "1082        68.0         69.0  \n",
      "1083        68.0         69.0  \n",
      "1084        68.0         69.0  \n",
      "1085        68.0         69.0  \n",
      "\n",
      "[68 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "1086  0.021225  0.030331 -0.020873  0.024116       0     1.0       10   \n",
      "1087  0.021832 -0.164485 -0.020390  0.310141       1     1.0       10   \n",
      "1088  0.018542  0.030921 -0.014187  0.011098       0     1.0       10   \n",
      "1089  0.019161 -0.163995 -0.013965  0.299271       1     1.0       10   \n",
      "1090  0.015881  0.031324 -0.007980  0.002217       0     1.0       10   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "1165 -0.150954 -0.157854  0.139255  0.165271       0     1.0       10   \n",
      "1166 -0.154111 -0.354666  0.142561  0.498440       0     1.0       10   \n",
      "1167 -0.161204 -0.551480  0.152529  0.832437       0     1.0       10   \n",
      "1168 -0.172234 -0.748320  0.169178  1.168939       0     1.0       10   \n",
      "1169 -0.187200 -0.945189  0.192557  1.509529       1     1.0       10   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "1086        84.0         85.0  \n",
      "1087        84.0         85.0  \n",
      "1088        84.0         85.0  \n",
      "1089        84.0         85.0  \n",
      "1090        84.0         85.0  \n",
      "...          ...          ...  \n",
      "1165        84.0         85.0  \n",
      "1166        84.0         85.0  \n",
      "1167        84.0         85.0  \n",
      "1168        84.0         85.0  \n",
      "1169        84.0         85.0  \n",
      "\n",
      "[84 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "1170  0.043576 -0.047893 -0.000976  0.035209       0     1.0       11   \n",
      "1171  0.042618 -0.243001 -0.000272  0.327584       1     1.0       11   \n",
      "1172  0.037758 -0.047875  0.006280  0.034815       0     1.0       11   \n",
      "1173  0.036801 -0.243087  0.006976  0.329473       1     1.0       11   \n",
      "1174  0.031939 -0.048065  0.013565  0.038998       0     1.0       11   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "1259  0.676537  1.648266 -0.056946 -1.278424       1     1.0       11   \n",
      "1260  0.709503  1.844066 -0.082515 -1.588381       1     1.0       11   \n",
      "1261  0.746384  2.040065 -0.114282 -1.905612       1     1.0       11   \n",
      "1262  0.787185  2.236221 -0.152394 -2.231452       1     1.0       11   \n",
      "1263  0.831910  2.432427 -0.197023 -2.566981       1     1.0       11   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "1170        94.0         95.0  \n",
      "1171        94.0         95.0  \n",
      "1172        94.0         95.0  \n",
      "1173        94.0         95.0  \n",
      "1174        94.0         95.0  \n",
      "...          ...          ...  \n",
      "1259        94.0         95.0  \n",
      "1260        94.0         95.0  \n",
      "1261        94.0         95.0  \n",
      "1262        94.0         95.0  \n",
      "1263        94.0         95.0  \n",
      "\n",
      "[94 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "1264 -0.031910 -0.035733 -0.046419  0.046782       0     1.0       12   \n",
      "1265 -0.032625 -0.230160 -0.045483  0.324466       1     1.0       12   \n",
      "1266 -0.037228 -0.034421 -0.038994  0.017793       0     1.0       12   \n",
      "1267 -0.037917 -0.228963 -0.038638  0.297923       1     1.0       12   \n",
      "1268 -0.042496 -0.033312 -0.032680 -0.006691       0     1.0       12   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "1443 -0.563556 -1.370365  0.120662  1.414782       1     1.0       12   \n",
      "1444 -0.590963 -1.176926  0.148958  1.162123       1     1.0       12   \n",
      "1445 -0.614502 -0.984025  0.172200  0.919606       1     1.0       12   \n",
      "1446 -0.634182 -0.791596  0.190592  0.685609       1     1.0       12   \n",
      "1447 -0.650014 -0.599559  0.204305  0.458465       1     1.0       12   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "1264       184.0        185.0  \n",
      "1265       184.0        185.0  \n",
      "1266       184.0        185.0  \n",
      "1267       184.0        185.0  \n",
      "1268       184.0        185.0  \n",
      "...          ...          ...  \n",
      "1443       184.0        185.0  \n",
      "1444       184.0        185.0  \n",
      "1445       184.0        185.0  \n",
      "1446       184.0        185.0  \n",
      "1447       184.0        185.0  \n",
      "\n",
      "[184 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "1448 -0.007281  0.012369 -0.046816 -0.001945       1     1.0       13   \n",
      "1449 -0.007034  0.208130 -0.046855 -0.309024       0     1.0       13   \n",
      "1450 -0.002871  0.013706 -0.053036 -0.031478       0     1.0       13   \n",
      "1451 -0.002597 -0.180617 -0.053665  0.244011       1     1.0       13   \n",
      "1452 -0.006209  0.015229 -0.048785 -0.065105       1     1.0       13   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "1505 -0.647512 -1.290987  0.104394  0.671660       0     1.0       13   \n",
      "1506 -0.673331 -1.487393  0.117828  0.995302       0     1.0       13   \n",
      "1507 -0.703079 -1.683877  0.137734  1.322546       0     1.0       13   \n",
      "1508 -0.736757 -1.880444  0.164185  1.654970       0     1.0       13   \n",
      "1509 -0.774366 -2.077058  0.197284  1.993977       1     1.0       13   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "1448        62.0         63.0  \n",
      "1449        62.0         63.0  \n",
      "1450        62.0         63.0  \n",
      "1451        62.0         63.0  \n",
      "1452        62.0         63.0  \n",
      "...          ...          ...  \n",
      "1505        62.0         63.0  \n",
      "1506        62.0         63.0  \n",
      "1507        62.0         63.0  \n",
      "1508        62.0         63.0  \n",
      "1509        62.0         63.0  \n",
      "\n",
      "[62 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "1510  0.045798  0.025511  0.038861  0.027692       0     1.0       14   \n",
      "1511  0.046309 -0.170146  0.039415  0.332379       1     1.0       14   \n",
      "1512  0.042906  0.024394  0.046063  0.052381       0     1.0       14   \n",
      "1513  0.043393 -0.171357  0.047110  0.359234       1     1.0       14   \n",
      "1514  0.039966  0.023064  0.054295  0.081770       1     1.0       14   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "1585  0.540141  0.977726 -0.112139 -0.924622       0     1.0       14   \n",
      "1586  0.559696  0.784283 -0.130631 -0.669179       1     1.0       14   \n",
      "1587  0.575382  0.980956 -0.144015 -0.999972       1     1.0       14   \n",
      "1588  0.595001  1.177678 -0.164014 -1.334195       1     1.0       14   \n",
      "1589  0.618554  1.374443 -0.190698 -1.673385       1     1.0       14   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "1510        80.0         81.0  \n",
      "1511        80.0         81.0  \n",
      "1512        80.0         81.0  \n",
      "1513        80.0         81.0  \n",
      "1514        80.0         81.0  \n",
      "...          ...          ...  \n",
      "1585        80.0         81.0  \n",
      "1586        80.0         81.0  \n",
      "1587        80.0         81.0  \n",
      "1588        80.0         81.0  \n",
      "1589        80.0         81.0  \n",
      "\n",
      "[80 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "1590 -0.029985  0.048705 -0.027253 -0.030591       1     1.0       15   \n",
      "1591 -0.029010  0.244207 -0.027865 -0.331746       0     1.0       15   \n",
      "1592 -0.024126  0.049493 -0.034500 -0.047979       1     1.0       15   \n",
      "1593 -0.023136  0.245092 -0.035459 -0.351344       0     1.0       15   \n",
      "1594 -0.018235  0.050492 -0.042486 -0.070050       0     1.0       15   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "1694 -0.793144 -1.845118  0.044713  1.631186       0     1.0       15   \n",
      "1695 -0.830046 -2.040736  0.077337  1.937460       1     1.0       15   \n",
      "1696 -0.870861 -1.846521  0.116086  1.669722       0     1.0       15   \n",
      "1697 -0.907792 -2.042785  0.149481  1.996190       1     1.0       15   \n",
      "1698 -0.948647 -1.849510  0.189404  1.753294       0     1.0       15   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "1590       109.0        110.0  \n",
      "1591       109.0        110.0  \n",
      "1592       109.0        110.0  \n",
      "1593       109.0        110.0  \n",
      "1594       109.0        110.0  \n",
      "...          ...          ...  \n",
      "1694       109.0        110.0  \n",
      "1695       109.0        110.0  \n",
      "1696       109.0        110.0  \n",
      "1697       109.0        110.0  \n",
      "1698       109.0        110.0  \n",
      "\n",
      "[109 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "1699 -0.003174 -0.037045  0.025971 -0.009391       1     1.0       16   \n",
      "1700 -0.003915  0.157695  0.025783 -0.293768       1     1.0       16   \n",
      "1701 -0.000761  0.352440  0.019908 -0.578209       0     1.0       16   \n",
      "1702  0.006288  0.157045  0.008344 -0.279322       0     1.0       16   \n",
      "1703  0.009429 -0.038195  0.002757  0.015981       0     1.0       16   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "1803 -0.665877 -1.547843  0.088840  1.229014       1     1.0       16   \n",
      "1804 -0.696834 -1.353970  0.113420  0.965435       0     1.0       16   \n",
      "1805 -0.723913 -1.550417  0.132729  1.291487       0     1.0       16   \n",
      "1806 -0.754922 -1.746953  0.158559  1.622606       0     1.0       16   \n",
      "1807 -0.789861 -1.943547  0.191011  1.960218       0     1.0       16   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "1699       109.0        110.0  \n",
      "1700       109.0        110.0  \n",
      "1701       109.0        110.0  \n",
      "1702       109.0        110.0  \n",
      "1703       109.0        110.0  \n",
      "...          ...          ...  \n",
      "1803       109.0        110.0  \n",
      "1804       109.0        110.0  \n",
      "1805       109.0        110.0  \n",
      "1806       109.0        110.0  \n",
      "1807       109.0        110.0  \n",
      "\n",
      "[109 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "1808 -0.043510  0.023981 -0.021900  0.044295       0     1.0       17   \n",
      "1809 -0.043030 -0.170820 -0.021014  0.329989       0     1.0       17   \n",
      "1810 -0.046447 -0.365636 -0.014414  0.615972       1     1.0       17   \n",
      "1811 -0.053760 -0.170316 -0.002095  0.318784       1     1.0       17   \n",
      "1812 -0.057166  0.024836  0.004281  0.025441       0     1.0       17   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "2003  0.333080  0.574617  0.084574 -0.067932       1     1.0       17   \n",
      "2004  0.344572  0.768431  0.083215 -0.332779       1     1.0       17   \n",
      "2005  0.359941  0.962276  0.076560 -0.598103       1     1.0       17   \n",
      "2006  0.379186  1.156248  0.064598 -0.865722       1     1.0       17   \n",
      "2007  0.402311  1.350435  0.047283 -1.137415       0     1.0       17   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "1808       200.0        201.0  \n",
      "1809       200.0        201.0  \n",
      "1810       200.0        201.0  \n",
      "1811       200.0        201.0  \n",
      "1812       200.0        201.0  \n",
      "...          ...          ...  \n",
      "2003       200.0        201.0  \n",
      "2004       200.0        201.0  \n",
      "2005       200.0        201.0  \n",
      "2006       200.0        201.0  \n",
      "2007       200.0        201.0  \n",
      "\n",
      "[200 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "2008 -0.031630 -0.005079  0.012752 -0.009955       1     1.0       18   \n",
      "2009 -0.031732  0.189857  0.012553 -0.298587       0     1.0       18   \n",
      "2010 -0.027935 -0.005441  0.006581 -0.001972       1     1.0       18   \n",
      "2011 -0.028043  0.189586  0.006542 -0.292571       0     1.0       18   \n",
      "2012 -0.024252 -0.005629  0.000690  0.002168       1     1.0       18   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "2099 -0.571903 -1.327927  0.075566  1.092605       0     1.0       18   \n",
      "2100 -0.598461 -1.523959  0.097418  1.408009       1     1.0       18   \n",
      "2101 -0.628940 -1.330171  0.125578  1.147301       0     1.0       18   \n",
      "2102 -0.655544 -1.526689  0.148524  1.476579       0     1.0       18   \n",
      "2103 -0.686078 -1.723280  0.178056  1.811725       0     1.0       18   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "2008        96.0         97.0  \n",
      "2009        96.0         97.0  \n",
      "2010        96.0         97.0  \n",
      "2011        96.0         97.0  \n",
      "2012        96.0         97.0  \n",
      "...          ...          ...  \n",
      "2099        96.0         97.0  \n",
      "2100        96.0         97.0  \n",
      "2101        96.0         97.0  \n",
      "2102        96.0         97.0  \n",
      "2103        96.0         97.0  \n",
      "\n",
      "[96 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "2104 -0.033795  0.021715  0.042675  0.040749       1     1.0       19   \n",
      "2105 -0.033361  0.216200  0.043490 -0.238170       0     1.0       19   \n",
      "2106 -0.029037  0.020484  0.038726  0.067907       1     1.0       19   \n",
      "2107 -0.028627  0.215030  0.040085 -0.212310       1     1.0       19   \n",
      "2108 -0.024327  0.409557  0.035838 -0.492084       0     1.0       19   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "2227 -0.643262 -1.672683  0.083764  1.317343       1     1.0       19   \n",
      "2228 -0.676716 -1.478714  0.110111  1.052008       0     1.0       19   \n",
      "2229 -0.706290 -1.675110  0.131151  1.377126       0     1.0       19   \n",
      "2230 -0.739792 -1.871604  0.158694  1.707783       0     1.0       19   \n",
      "2231 -0.777224 -2.068155  0.192849  2.045365       1     1.0       19   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "2104       128.0        129.0  \n",
      "2105       128.0        129.0  \n",
      "2106       128.0        129.0  \n",
      "2107       128.0        129.0  \n",
      "2108       128.0        129.0  \n",
      "...          ...          ...  \n",
      "2227       128.0        129.0  \n",
      "2228       128.0        129.0  \n",
      "2229       128.0        129.0  \n",
      "2230       128.0        129.0  \n",
      "2231       128.0        129.0  \n",
      "\n",
      "[128 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "2232  0.006663 -0.007733  0.040897 -0.009293       1     1.0       20   \n",
      "2233  0.006508  0.186779  0.040711 -0.288798       0     1.0       20   \n",
      "2234  0.010244 -0.008899  0.034935  0.016442       1     1.0       20   \n",
      "2235  0.010066  0.185705  0.035264 -0.265017       1     1.0       20   \n",
      "2236  0.013780  0.380306  0.029964 -0.546372       0     1.0       20   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "2293  0.117615  0.588049 -0.058587 -1.118303       1     1.0       20   \n",
      "2294  0.129376  0.783888 -0.080953 -1.428773       1     1.0       20   \n",
      "2295  0.145054  0.979911 -0.109528 -1.745619       1     1.0       20   \n",
      "2296  0.164652  1.176095 -0.144441 -2.070268       1     1.0       20   \n",
      "2297  0.188174  1.372360 -0.185846 -2.403918       1     1.0       20   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "2232        66.0         67.0  \n",
      "2233        66.0         67.0  \n",
      "2234        66.0         67.0  \n",
      "2235        66.0         67.0  \n",
      "2236        66.0         67.0  \n",
      "...          ...          ...  \n",
      "2293        66.0         67.0  \n",
      "2294        66.0         67.0  \n",
      "2295        66.0         67.0  \n",
      "2296        66.0         67.0  \n",
      "2297        66.0         67.0  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "2298 -0.047685  0.000311  0.025963 -0.008997       0     1.0       21   \n",
      "2299 -0.047679 -0.195173  0.025784  0.291763       1     1.0       21   \n",
      "2300 -0.051583 -0.000428  0.031619  0.007322       0     1.0       21   \n",
      "2301 -0.051591 -0.195989  0.031765  0.309811       1     1.0       21   \n",
      "2302 -0.055511 -0.001334  0.037961  0.027313       0     1.0       21   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "2401  0.148183  0.593448 -0.046847 -1.059161       1     1.0       21   \n",
      "2402  0.160052  0.789158 -0.068030 -1.366172       1     1.0       21   \n",
      "2403  0.175835  0.985063 -0.095353 -1.679335       1     1.0       21   \n",
      "2404  0.195537  1.181152 -0.128940 -2.000124       1     1.0       21   \n",
      "2405  0.219160  1.377364 -0.168943 -2.329801       1     1.0       21   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "2298       108.0        109.0  \n",
      "2299       108.0        109.0  \n",
      "2300       108.0        109.0  \n",
      "2301       108.0        109.0  \n",
      "2302       108.0        109.0  \n",
      "...          ...          ...  \n",
      "2401       108.0        109.0  \n",
      "2402       108.0        109.0  \n",
      "2403       108.0        109.0  \n",
      "2404       108.0        109.0  \n",
      "2405       108.0        109.0  \n",
      "\n",
      "[108 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "2406 -0.031614 -0.003854  0.034960 -0.009783       0     1.0       22   \n",
      "2407 -0.031691 -0.199459  0.034764  0.293722       1     1.0       22   \n",
      "2408 -0.035680 -0.004850  0.040639  0.012203       0     1.0       22   \n",
      "2409 -0.035777 -0.200530  0.040883  0.317426       1     1.0       22   \n",
      "2410 -0.039788 -0.006014  0.047231  0.037911       1     1.0       22   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "2473  0.123981  0.589526 -0.074475 -1.066814       1     1.0       22   \n",
      "2474  0.135771  0.785550 -0.095811 -1.381910       1     1.0       22   \n",
      "2475  0.151482  0.981728 -0.123449 -1.702953       1     1.0       22   \n",
      "2476  0.171117  1.178036 -0.157509 -2.031376       1     1.0       22   \n",
      "2477  0.194677  1.374395 -0.198136 -2.368385       1     1.0       22   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "2406        72.0         73.0  \n",
      "2407        72.0         73.0  \n",
      "2408        72.0         73.0  \n",
      "2409        72.0         73.0  \n",
      "2410        72.0         73.0  \n",
      "...          ...          ...  \n",
      "2473        72.0         73.0  \n",
      "2474        72.0         73.0  \n",
      "2475        72.0         73.0  \n",
      "2476        72.0         73.0  \n",
      "2477        72.0         73.0  \n",
      "\n",
      "[72 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "2478  0.008647 -0.044594 -0.024622 -0.034205       0     1.0       23   \n",
      "2479  0.007755 -0.239354 -0.025306  0.250609       1     1.0       23   \n",
      "2480  0.002968 -0.043880 -0.020294 -0.049948       0     1.0       23   \n",
      "2481  0.002091 -0.238705 -0.021293  0.236264       1     1.0       23   \n",
      "2482 -0.002683 -0.043286 -0.016567 -0.063058       0     1.0       23   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "2673 -0.216559  0.890302 -0.070908 -0.601530       0     1.0       23   \n",
      "2674 -0.198753  0.696239 -0.082938 -0.331997       1     1.0       23   \n",
      "2675 -0.184828  0.892438 -0.089578 -0.649640       0     1.0       23   \n",
      "2676 -0.166979  0.698671 -0.102571 -0.386454       1     1.0       23   \n",
      "2677 -0.153006  0.895088 -0.110300 -0.709635       0     1.0       23   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "2478       200.0        201.0  \n",
      "2479       200.0        201.0  \n",
      "2480       200.0        201.0  \n",
      "2481       200.0        201.0  \n",
      "2482       200.0        201.0  \n",
      "...          ...          ...  \n",
      "2673       200.0        201.0  \n",
      "2674       200.0        201.0  \n",
      "2675       200.0        201.0  \n",
      "2676       200.0        201.0  \n",
      "2677       200.0        201.0  \n",
      "\n",
      "[200 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "2678 -0.031387 -0.028070 -0.009223 -0.037245       0     1.0       24   \n",
      "2679 -0.031948 -0.223059 -0.009968  0.252513       1     1.0       24   \n",
      "2680 -0.036409 -0.027796 -0.004917 -0.043297       1     1.0       24   \n",
      "2681 -0.036965  0.167396 -0.005783 -0.337527       0     1.0       24   \n",
      "2682 -0.033617 -0.027643 -0.012534 -0.046673       0     1.0       24   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "2873 -0.440144 -0.960286 -0.051282  0.469719       0     1.0       24   \n",
      "2874 -0.459349 -1.154647 -0.041887  0.745807       1     1.0       24   \n",
      "2875 -0.482442 -0.958973 -0.026971  0.440242       0     1.0       24   \n",
      "2876 -0.501622 -1.153703 -0.018166  0.724303       0     1.0       24   \n",
      "2877 -0.524696 -1.348569 -0.003680  1.011213       1     1.0       24   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "2678       200.0        201.0  \n",
      "2679       200.0        201.0  \n",
      "2680       200.0        201.0  \n",
      "2681       200.0        201.0  \n",
      "2682       200.0        201.0  \n",
      "...          ...          ...  \n",
      "2873       200.0        201.0  \n",
      "2874       200.0        201.0  \n",
      "2875       200.0        201.0  \n",
      "2876       200.0        201.0  \n",
      "2877       200.0        201.0  \n",
      "\n",
      "[200 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "2878  0.046748  0.031943  0.010183 -0.021421       0     1.0       25   \n",
      "2879  0.047387 -0.163324  0.009755  0.274457       1     1.0       25   \n",
      "2880  0.044120  0.031658  0.015244 -0.015133       0     1.0       25   \n",
      "2881  0.044754 -0.163680  0.014941  0.282320       1     1.0       25   \n",
      "2882  0.041480  0.031226  0.020587 -0.005613       0     1.0       25   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "2988 -0.576254 -1.484741  0.092938  1.347465       1     1.0       25   \n",
      "2989 -0.605949 -1.290902  0.119888  1.085246       0     1.0       25   \n",
      "2990 -0.631767 -1.487384  0.141593  1.413016       0     1.0       25   \n",
      "2991 -0.661515 -1.683948  0.169853  1.746401       0     1.0       25   \n",
      "2992 -0.695194 -1.880545  0.204781  2.086750       0     1.0       25   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "2878       115.0        116.0  \n",
      "2879       115.0        116.0  \n",
      "2880       115.0        116.0  \n",
      "2881       115.0        116.0  \n",
      "2882       115.0        116.0  \n",
      "...          ...          ...  \n",
      "2988       115.0        116.0  \n",
      "2989       115.0        116.0  \n",
      "2990       115.0        116.0  \n",
      "2991       115.0        116.0  \n",
      "2992       115.0        116.0  \n",
      "\n",
      "[115 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "2993  0.009556  0.048725 -0.017637 -0.024236       0     1.0       26   \n",
      "2994  0.010530 -0.146139 -0.018122  0.262830       0     1.0       26   \n",
      "2995  0.007607 -0.340998 -0.012865  0.549743       1     1.0       26   \n",
      "2996  0.000787 -0.145698 -0.001870  0.253034       1     1.0       26   \n",
      "2997 -0.002127  0.049451  0.003190 -0.040238       0     1.0       26   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "3115 -0.617275 -1.458179  0.086691  1.127825       0     1.0       26   \n",
      "3116 -0.646438 -1.654323  0.109247  1.446392       1     1.0       26   \n",
      "3117 -0.679525 -1.460701  0.138175  1.189745       0     1.0       26   \n",
      "3118 -0.708739 -1.657316  0.161970  1.522352       0     1.0       26   \n",
      "3119 -0.741885 -1.853982  0.192417  1.860900       0     1.0       26   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "2993       127.0        128.0  \n",
      "2994       127.0        128.0  \n",
      "2995       127.0        128.0  \n",
      "2996       127.0        128.0  \n",
      "2997       127.0        128.0  \n",
      "...          ...          ...  \n",
      "3115       127.0        128.0  \n",
      "3116       127.0        128.0  \n",
      "3117       127.0        128.0  \n",
      "3118       127.0        128.0  \n",
      "3119       127.0        128.0  \n",
      "\n",
      "[127 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "3120 -0.014939  0.003872 -0.036528  0.043015       0     1.0       27   \n",
      "3121 -0.014862 -0.190708 -0.035668  0.323953       0     1.0       27   \n",
      "3122 -0.018676 -0.385304 -0.029189  0.605178       1     1.0       27   \n",
      "3123 -0.026382 -0.189786 -0.017085  0.303446       0     1.0       27   \n",
      "3124 -0.030178 -0.384661 -0.011016  0.590692       1     1.0       27   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "3258 -0.692342 -1.488729  0.097838  0.879933       0     1.0       27   \n",
      "3259 -0.722117 -1.685034  0.115437  1.201701       1     1.0       27   \n",
      "3260 -0.755818 -1.491579  0.139471  0.947312       0     1.0       27   \n",
      "3261 -0.785649 -1.688275  0.158417  1.280363       0     1.0       27   \n",
      "3262 -0.819415 -1.885021  0.184024  1.618166       0     1.0       27   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "3120       143.0        144.0  \n",
      "3121       143.0        144.0  \n",
      "3122       143.0        144.0  \n",
      "3123       143.0        144.0  \n",
      "3124       143.0        144.0  \n",
      "...          ...          ...  \n",
      "3258       143.0        144.0  \n",
      "3259       143.0        144.0  \n",
      "3260       143.0        144.0  \n",
      "3261       143.0        144.0  \n",
      "3262       143.0        144.0  \n",
      "\n",
      "[143 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "3263 -0.008150  0.038569 -0.020099 -0.028805       1     1.0       28   \n",
      "3264 -0.007379  0.233974 -0.020675 -0.327761       0     1.0       28   \n",
      "3265 -0.002699  0.039152 -0.027230 -0.041669       1     1.0       28   \n",
      "3266 -0.001916  0.234654 -0.028064 -0.342817       1     1.0       28   \n",
      "3267  0.002777  0.430164 -0.034920 -0.644216       0     1.0       28   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "3346 -0.688502 -1.668711  0.065994  1.530703       1     1.0       28   \n",
      "3347 -0.721877 -1.474444  0.096608  1.259325       0     1.0       28   \n",
      "3348 -0.751366 -1.670660  0.121794  1.580635       0     1.0       28   \n",
      "3349 -0.784779 -1.867003  0.153407  1.908687       0     1.0       28   \n",
      "3350 -0.822119 -2.063412  0.191581  2.244766       1     1.0       28   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "3263        88.0         89.0  \n",
      "3264        88.0         89.0  \n",
      "3265        88.0         89.0  \n",
      "3266        88.0         89.0  \n",
      "3267        88.0         89.0  \n",
      "...          ...          ...  \n",
      "3346        88.0         89.0  \n",
      "3347        88.0         89.0  \n",
      "3348        88.0         89.0  \n",
      "3349        88.0         89.0  \n",
      "3350        88.0         89.0  \n",
      "\n",
      "[88 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "3351  0.035278  0.048617  0.027447  0.032711       1     1.0       29   \n",
      "3352  0.036250  0.243335  0.028101 -0.251188       0     1.0       29   \n",
      "3353  0.041117  0.047823  0.023077  0.050225       1     1.0       29   \n",
      "3354  0.042073  0.242607  0.024082 -0.235089       0     1.0       29   \n",
      "3355  0.046926  0.047149  0.019380  0.065092       1     1.0       29   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "3438  0.589499  1.000809 -0.086063 -0.916897       1     1.0       29   \n",
      "3439  0.609515  1.196983 -0.104401 -1.235339       1     1.0       29   \n",
      "3440  0.633454  1.393280 -0.129107 -1.558820       1     1.0       29   \n",
      "3441  0.661320  1.589689 -0.160284 -1.888834       1     1.0       29   \n",
      "3442  0.693114  1.786149 -0.198060 -2.226669       1     1.0       29   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "3351        92.0         93.0  \n",
      "3352        92.0         93.0  \n",
      "3353        92.0         93.0  \n",
      "3354        92.0         93.0  \n",
      "3355        92.0         93.0  \n",
      "...          ...          ...  \n",
      "3438        92.0         93.0  \n",
      "3439        92.0         93.0  \n",
      "3440        92.0         93.0  \n",
      "3441        92.0         93.0  \n",
      "3442        92.0         93.0  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "3443  0.032532 -0.045749  0.006925  0.034954       0     1.0       30   \n",
      "3444  0.031617 -0.240970  0.007624  0.329814       1     1.0       30   \n",
      "3445  0.026798 -0.045957  0.014221  0.039545       0     1.0       30   \n",
      "3446  0.025879 -0.241280  0.015011  0.336681       1     1.0       30   \n",
      "3447  0.021053 -0.046375  0.021745  0.048769       1     1.0       30   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "3593 -0.560558 -1.189690  0.138864  1.209872       1     1.0       30   \n",
      "3594 -0.584352 -0.996607  0.163061  0.963731       1     1.0       30   \n",
      "3595 -0.604284 -0.804007  0.182336  0.726391       1     1.0       30   \n",
      "3596 -0.620364 -0.611811  0.196864  0.496187       1     1.0       30   \n",
      "3597 -0.632600 -0.419930  0.206788  0.271429       1     1.0       30   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "3443       155.0        156.0  \n",
      "3444       155.0        156.0  \n",
      "3445       155.0        156.0  \n",
      "3446       155.0        156.0  \n",
      "3447       155.0        156.0  \n",
      "...          ...          ...  \n",
      "3593       155.0        156.0  \n",
      "3594       155.0        156.0  \n",
      "3595       155.0        156.0  \n",
      "3596       155.0        156.0  \n",
      "3597       155.0        156.0  \n",
      "\n",
      "[155 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "3598 -0.012976 -0.003495 -0.032108  0.036242       0     1.0       31   \n",
      "3599 -0.013046 -0.198142 -0.031383  0.318624       0     1.0       31   \n",
      "3600 -0.017009 -0.392804 -0.025010  0.601247       1     1.0       31   \n",
      "3601 -0.024865 -0.197341 -0.012986  0.300793       0     1.0       31   \n",
      "3602 -0.028812 -0.392275 -0.006970  0.589352       1     1.0       31   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "3734 -0.591032 -1.516413  0.092507  1.321937       1     1.0       31   \n",
      "3735 -0.621360 -1.322574  0.118945  1.059579       0     1.0       31   \n",
      "3736 -0.647812 -1.519054  0.140137  1.387103       0     1.0       31   \n",
      "3737 -0.678193 -1.715616  0.167879  1.720123       0     1.0       31   \n",
      "3738 -0.712505 -1.912217  0.202281  2.060003       0     1.0       31   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "3598       141.0        142.0  \n",
      "3599       141.0        142.0  \n",
      "3600       141.0        142.0  \n",
      "3601       141.0        142.0  \n",
      "3602       141.0        142.0  \n",
      "...          ...          ...  \n",
      "3734       141.0        142.0  \n",
      "3735       141.0        142.0  \n",
      "3736       141.0        142.0  \n",
      "3737       141.0        142.0  \n",
      "3738       141.0        142.0  \n",
      "\n",
      "[141 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "3739  0.010171 -0.008679  0.016519  0.010312       1     1.0       32   \n",
      "3740  0.009997  0.186203  0.016725 -0.277114       1     1.0       32   \n",
      "3741  0.013721  0.381082  0.011183 -0.564475       0     1.0       32   \n",
      "3742  0.021343  0.185805 -0.000107 -0.268290       0     1.0       32   \n",
      "3743  0.025059 -0.009315 -0.005473  0.024359       0     1.0       32   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "3824 -0.690691 -1.687362  0.086341  0.940040       0     1.0       32   \n",
      "3825 -0.724438 -1.883535  0.105141  1.258556       0     1.0       32   \n",
      "3826 -0.762109 -2.079834  0.130313  1.582232       1     1.0       32   \n",
      "3827 -0.803705 -1.886481  0.161957  1.332866       0     1.0       32   \n",
      "3828 -0.841435 -2.083232  0.188615  1.671537       1     1.0       32   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "3739        90.0         91.0  \n",
      "3740        90.0         91.0  \n",
      "3741        90.0         91.0  \n",
      "3742        90.0         91.0  \n",
      "3743        90.0         91.0  \n",
      "...          ...          ...  \n",
      "3824        90.0         91.0  \n",
      "3825        90.0         91.0  \n",
      "3826        90.0         91.0  \n",
      "3827        90.0         91.0  \n",
      "3828        90.0         91.0  \n",
      "\n",
      "[90 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "3829  0.012004  0.033827 -0.030025  0.015011       0     1.0       33   \n",
      "3830  0.012680 -0.160852 -0.029724  0.298072       1     1.0       33   \n",
      "3831  0.009463  0.034681 -0.023763 -0.003835       1     1.0       33   \n",
      "3832  0.010157  0.230135 -0.023840 -0.303920       0     1.0       33   \n",
      "3833  0.014759  0.035361 -0.029918 -0.018850       0     1.0       33   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "3925 -0.704169 -1.477089  0.060573  1.253806       0     1.0       33   \n",
      "3926 -0.733711 -1.672932  0.085649  1.564829       0     1.0       33   \n",
      "3927 -0.767169 -1.868967  0.116945  1.882954       0     1.0       33   \n",
      "3928 -0.804549 -2.065152  0.154604  2.209524       1     1.0       33   \n",
      "3929 -0.845852 -1.871814  0.198795  1.968249       0     1.0       33   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "3829       101.0        102.0  \n",
      "3830       101.0        102.0  \n",
      "3831       101.0        102.0  \n",
      "3832       101.0        102.0  \n",
      "3833       101.0        102.0  \n",
      "...          ...          ...  \n",
      "3925       101.0        102.0  \n",
      "3926       101.0        102.0  \n",
      "3927       101.0        102.0  \n",
      "3928       101.0        102.0  \n",
      "3929       101.0        102.0  \n",
      "\n",
      "[101 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "3930  0.008481 -0.033021 -0.003708  0.007488       0     1.0       34   \n",
      "3931  0.007820 -0.228089 -0.003558  0.298999       1     1.0       34   \n",
      "3932  0.003258 -0.032917  0.002422  0.005196       0     1.0       34   \n",
      "3933  0.002600 -0.228074  0.002526  0.298642       1     1.0       34   \n",
      "3934 -0.001961 -0.032988  0.008499  0.006757       1     1.0       34   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "4038  0.589462  0.728902 -0.096274 -0.756842       1     1.0       34   \n",
      "4039  0.604040  0.925210 -0.111411 -1.078201       1     1.0       34   \n",
      "4040  0.622544  1.121613 -0.132975 -1.403665       1     1.0       34   \n",
      "4041  0.644976  1.318112 -0.161048 -1.734791       1     1.0       34   \n",
      "4042  0.671339  1.514663 -0.195744 -2.072947       1     1.0       34   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "3930       113.0        114.0  \n",
      "3931       113.0        114.0  \n",
      "3932       113.0        114.0  \n",
      "3933       113.0        114.0  \n",
      "3934       113.0        114.0  \n",
      "...          ...          ...  \n",
      "4038       113.0        114.0  \n",
      "4039       113.0        114.0  \n",
      "4040       113.0        114.0  \n",
      "4041       113.0        114.0  \n",
      "4042       113.0        114.0  \n",
      "\n",
      "[113 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "4043  0.005303 -0.002973  0.014844  0.039457       1     1.0       35   \n",
      "4044  0.005244  0.191933  0.015633 -0.248506       1     1.0       35   \n",
      "4045  0.009082  0.386829  0.010663 -0.536217       1     1.0       35   \n",
      "4046  0.016819  0.581799 -0.000061 -0.825521       0     1.0       35   \n",
      "4047  0.028455  0.386678 -0.016572 -0.532857       1     1.0       35   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "4143 -0.713264 -1.881528  0.088989  1.367647       1     1.0       35   \n",
      "4144 -0.750895 -1.687626  0.116342  1.104072       0     1.0       35   \n",
      "4145 -0.784647 -1.884069  0.138424  1.430873       0     1.0       35   \n",
      "4146 -0.822329 -2.080602  0.167041  1.763419       1     1.0       35   \n",
      "4147 -0.863941 -1.887717  0.202309  1.527000       0     1.0       35   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "4043       105.0        106.0  \n",
      "4044       105.0        106.0  \n",
      "4045       105.0        106.0  \n",
      "4046       105.0        106.0  \n",
      "4047       105.0        106.0  \n",
      "...          ...          ...  \n",
      "4143       105.0        106.0  \n",
      "4144       105.0        106.0  \n",
      "4145       105.0        106.0  \n",
      "4146       105.0        106.0  \n",
      "4147       105.0        106.0  \n",
      "\n",
      "[105 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "4148  0.002740  0.002006  0.020650  0.001507       1     1.0       36   \n",
      "4149  0.002780  0.196826  0.020680 -0.284590       1     1.0       36   \n",
      "4150  0.006717  0.391647  0.014988 -0.570679       0     1.0       36   \n",
      "4151  0.014550  0.196318  0.003575 -0.273312       1     1.0       36   \n",
      "4152  0.018476  0.391388 -0.001891 -0.564865       0     1.0       36   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "4225 -0.681450 -1.689311  0.100982  1.211777       1     1.0       36   \n",
      "4226 -0.715236 -1.495627  0.125218  0.952370       0     1.0       36   \n",
      "4227 -0.745149 -1.692191  0.144265  1.281625       0     1.0       36   \n",
      "4228 -0.778993 -1.888826  0.169898  1.615780       0     1.0       36   \n",
      "4229 -0.816769 -2.085496  0.202213  1.956248       1     1.0       36   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "4148        82.0         83.0  \n",
      "4149        82.0         83.0  \n",
      "4150        82.0         83.0  \n",
      "4151        82.0         83.0  \n",
      "4152        82.0         83.0  \n",
      "...          ...          ...  \n",
      "4225        82.0         83.0  \n",
      "4226        82.0         83.0  \n",
      "4227        82.0         83.0  \n",
      "4228        82.0         83.0  \n",
      "4229        82.0         83.0  \n",
      "\n",
      "[82 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "4230  0.012879 -0.031313 -0.034302 -0.024895       1     1.0       37   \n",
      "4231  0.012252  0.164284 -0.034800 -0.328200       0     1.0       37   \n",
      "4232  0.015538 -0.030326 -0.041364 -0.046692       1     1.0       37   \n",
      "4233  0.014931  0.165364 -0.042298 -0.352133       0     1.0       37   \n",
      "4234  0.018239 -0.029132 -0.049341 -0.073082       0     1.0       37   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "4324 -0.710086 -1.547654  0.046892  1.332930       0     1.0       37   \n",
      "4325 -0.741039 -1.743335  0.073551  1.639910       0     1.0       37   \n",
      "4326 -0.775906 -1.939238  0.106349  1.954574       0     1.0       37   \n",
      "4327 -0.814691 -2.135316  0.145441  2.278238       1     1.0       37   \n",
      "4328 -0.857397 -1.941814  0.191005  2.033658       0     1.0       37   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "4230        99.0        100.0  \n",
      "4231        99.0        100.0  \n",
      "4232        99.0        100.0  \n",
      "4233        99.0        100.0  \n",
      "4234        99.0        100.0  \n",
      "...          ...          ...  \n",
      "4324        99.0        100.0  \n",
      "4325        99.0        100.0  \n",
      "4326        99.0        100.0  \n",
      "4327        99.0        100.0  \n",
      "4328        99.0        100.0  \n",
      "\n",
      "[99 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "4329  0.017850  0.003901  0.024014  0.021182       1     1.0       38   \n",
      "4330  0.017928  0.198670  0.024437 -0.263828       1     1.0       38   \n",
      "4331  0.021901  0.393435  0.019161 -0.548704       0     1.0       38   \n",
      "4332  0.029770  0.198049  0.008187 -0.250047       0     1.0       38   \n",
      "4333  0.033731  0.002811  0.003186  0.045207       0     1.0       38   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "4436 -0.560161 -1.319382  0.087094  1.134295       0     1.0       38   \n",
      "4437 -0.586548 -1.515529  0.109780  1.452974       1     1.0       38   \n",
      "4438 -0.616859 -1.321913  0.138839  1.196509       0     1.0       38   \n",
      "4439 -0.643297 -1.518532  0.162770  1.529287       0     1.0       38   \n",
      "4440 -0.673668 -1.715200  0.193355  1.868032       0     1.0       38   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "4329       112.0        113.0  \n",
      "4330       112.0        113.0  \n",
      "4331       112.0        113.0  \n",
      "4332       112.0        113.0  \n",
      "4333       112.0        113.0  \n",
      "...          ...          ...  \n",
      "4436       112.0        113.0  \n",
      "4437       112.0        113.0  \n",
      "4438       112.0        113.0  \n",
      "4439       112.0        113.0  \n",
      "4440       112.0        113.0  \n",
      "\n",
      "[112 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "4441  0.006892  0.030775 -0.046354 -0.026547       1     1.0       39   \n",
      "4442  0.007508  0.226530 -0.046885 -0.333487       1     1.0       39   \n",
      "4443  0.012038  0.422287 -0.053555 -0.640579       0     1.0       39   \n",
      "4444  0.020484  0.227951 -0.066366 -0.365231       0     1.0       39   \n",
      "4445  0.025043  0.033832 -0.073671 -0.094190       0     1.0       39   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "4524 -0.673260 -1.669901  0.074597  1.387894       1     1.0       39   \n",
      "4525 -0.706658 -1.475784  0.102355  1.119439       0     1.0       39   \n",
      "4526 -0.736173 -1.672089  0.124744  1.442395       0     1.0       39   \n",
      "4527 -0.769615 -1.868506  0.153592  1.771312       0     1.0       39   \n",
      "4528 -0.806985 -2.064992  0.189018  2.107549       1     1.0       39   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "4441        88.0         89.0  \n",
      "4442        88.0         89.0  \n",
      "4443        88.0         89.0  \n",
      "4444        88.0         89.0  \n",
      "4445        88.0         89.0  \n",
      "...          ...          ...  \n",
      "4524        88.0         89.0  \n",
      "4525        88.0         89.0  \n",
      "4526        88.0         89.0  \n",
      "4527        88.0         89.0  \n",
      "4528        88.0         89.0  \n",
      "\n",
      "[88 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "4529  0.036093  0.041483  0.025351 -0.004841       1     1.0       40   \n",
      "4530  0.036923  0.236232  0.025254 -0.289419       0     1.0       40   \n",
      "4531  0.041647  0.040759  0.019466  0.011121       1     1.0       40   \n",
      "4532  0.042463  0.235597  0.019688 -0.275357       1     1.0       40   \n",
      "4533  0.047175  0.430432  0.014181 -0.561766       1     1.0       40   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "4724 -0.415111 -1.265261 -0.030307  0.740676       1     1.0       40   \n",
      "4725 -0.440416 -1.069734 -0.015493  0.438611       0     1.0       40   \n",
      "4726 -0.461811 -1.264634 -0.006721  0.726370       1     1.0       40   \n",
      "4727 -0.487104 -1.069419  0.007806  0.431579       0     1.0       40   \n",
      "4728 -0.508492 -1.264651  0.016438  0.726713       0     1.0       40   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "4529       200.0        201.0  \n",
      "4530       200.0        201.0  \n",
      "4531       200.0        201.0  \n",
      "4532       200.0        201.0  \n",
      "4533       200.0        201.0  \n",
      "...          ...          ...  \n",
      "4724       200.0        201.0  \n",
      "4725       200.0        201.0  \n",
      "4726       200.0        201.0  \n",
      "4727       200.0        201.0  \n",
      "4728       200.0        201.0  \n",
      "\n",
      "[200 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "4729  0.024166  0.029215 -0.033808 -0.041553       1     1.0       41   \n",
      "4730  0.024750  0.224805 -0.034639 -0.344708       0     1.0       41   \n",
      "4731  0.029246  0.030193 -0.041533 -0.063146       0     1.0       41   \n",
      "4732  0.029850 -0.164310 -0.042796  0.216149       1     1.0       41   \n",
      "4733  0.026564  0.031397 -0.038473 -0.089720       1     1.0       41   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "4924 -0.620356 -1.670872  0.088381  1.361116       1     1.0       41   \n",
      "4925 -0.653774 -1.476962  0.115603  1.097337       0     1.0       41   \n",
      "4926 -0.683313 -1.673401  0.137550  1.423939       0     1.0       41   \n",
      "4927 -0.716781 -1.869929  0.166029  1.756259       0     1.0       41   \n",
      "4928 -0.754180 -2.066498  0.201154  2.095647       1     1.0       41   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "4729       200.0        201.0  \n",
      "4730       200.0        201.0  \n",
      "4731       200.0        201.0  \n",
      "4732       200.0        201.0  \n",
      "4733       200.0        201.0  \n",
      "...          ...          ...  \n",
      "4924       200.0        201.0  \n",
      "4925       200.0        201.0  \n",
      "4926       200.0        201.0  \n",
      "4927       200.0        201.0  \n",
      "4928       200.0        201.0  \n",
      "\n",
      "[200 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "4929  0.013192 -0.014165  0.027242 -0.008220       1     1.0       42   \n",
      "4930  0.012909  0.180556  0.027077 -0.292185       0     1.0       42   \n",
      "4931  0.016520 -0.014942  0.021234  0.008913       1     1.0       42   \n",
      "4932  0.016221  0.179870  0.021412 -0.276995       1     1.0       42   \n",
      "4933  0.019819  0.374680  0.015872 -0.562849       0     1.0       42   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "5124 -0.645665 -1.719225  0.072661  1.502792       1     1.0       42   \n",
      "5125 -0.680050 -1.525056  0.102717  1.233651       1     1.0       42   \n",
      "5126 -0.710551 -1.331394  0.127390  0.974834       0     1.0       42   \n",
      "5127 -0.737179 -1.527973  0.146886  1.304665       0     1.0       42   \n",
      "5128 -0.767738 -1.724620  0.172980  1.639489       0     1.0       42   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "4929       200.0        201.0  \n",
      "4930       200.0        201.0  \n",
      "4931       200.0        201.0  \n",
      "4932       200.0        201.0  \n",
      "4933       200.0        201.0  \n",
      "...          ...          ...  \n",
      "5124       200.0        201.0  \n",
      "5125       200.0        201.0  \n",
      "5126       200.0        201.0  \n",
      "5127       200.0        201.0  \n",
      "5128       200.0        201.0  \n",
      "\n",
      "[200 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "5129  0.044714 -0.003692  0.012286  0.035099       1     1.0       43   \n",
      "5130  0.044640  0.191252  0.012988 -0.253682       0     1.0       43   \n",
      "5131  0.048465 -0.004053  0.007914  0.043069       1     1.0       43   \n",
      "5132  0.048384  0.190954  0.008776 -0.247106       0     1.0       43   \n",
      "5133  0.052203 -0.004292  0.003834  0.048332       1     1.0       43   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "5222  0.588282  1.331802 -0.030249 -1.344311       1     1.0       43   \n",
      "5223  0.614918  1.527291 -0.057135 -1.646302       1     1.0       43   \n",
      "5224  0.645464  1.723033 -0.090061 -1.956224       1     1.0       43   \n",
      "5225  0.679925  1.918988 -0.129186 -2.275408       1     1.0       43   \n",
      "5226  0.718305  2.115053 -0.174694 -2.604930       1     1.0       43   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "5129        98.0         99.0  \n",
      "5130        98.0         99.0  \n",
      "5131        98.0         99.0  \n",
      "5132        98.0         99.0  \n",
      "5133        98.0         99.0  \n",
      "...          ...          ...  \n",
      "5222        98.0         99.0  \n",
      "5223        98.0         99.0  \n",
      "5224        98.0         99.0  \n",
      "5225        98.0         99.0  \n",
      "5226        98.0         99.0  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "5227 -0.032191  0.011321  0.015230  0.037914       1     1.0       44   \n",
      "5228 -0.031964  0.206221  0.015988 -0.249925       0     1.0       44   \n",
      "5229 -0.027840  0.010875  0.010990  0.047758       1     1.0       44   \n",
      "5230 -0.027622  0.205838  0.011945 -0.241438       1     1.0       44   \n",
      "5231 -0.023506  0.400787  0.007116 -0.530329       0     1.0       44   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "5310 -0.577542 -1.309108  0.087352  1.088022       0     1.0       44   \n",
      "5311 -0.603724 -1.505266  0.109112  1.406787       1     1.0       44   \n",
      "5312 -0.633829 -1.311654  0.137248  1.150111       0     1.0       44   \n",
      "5313 -0.660062 -1.508274  0.160250  1.482492       0     1.0       44   \n",
      "5314 -0.690228 -1.704946  0.189900  1.820633       0     1.0       44   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "5227        88.0         89.0  \n",
      "5228        88.0         89.0  \n",
      "5229        88.0         89.0  \n",
      "5230        88.0         89.0  \n",
      "5231        88.0         89.0  \n",
      "...          ...          ...  \n",
      "5310        88.0         89.0  \n",
      "5311        88.0         89.0  \n",
      "5312        88.0         89.0  \n",
      "5313        88.0         89.0  \n",
      "5314        88.0         89.0  \n",
      "\n",
      "[88 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "5315  0.006962 -0.037595  0.003391 -0.045832       0     1.0       45   \n",
      "5316  0.006210 -0.232765  0.002474  0.247919       0     1.0       45   \n",
      "5317  0.001555 -0.427922  0.007432  0.541381       0     1.0       45   \n",
      "5318 -0.007004 -0.623148  0.018260  0.836397       1     1.0       45   \n",
      "5319 -0.019467 -0.428280  0.034988  0.549512       1     1.0       45   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "5425 -0.690721 -1.558654  0.070191  1.417550       1     1.0       45   \n",
      "5426 -0.721894 -1.364468  0.098542  1.147607       0     1.0       45   \n",
      "5427 -0.749183 -1.560729  0.121494  1.469495       0     1.0       45   \n",
      "5428 -0.780398 -1.757109  0.150884  1.797526       0     1.0       45   \n",
      "5429 -0.815540 -1.953564  0.186834  2.133051       0     1.0       45   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "5315       115.0        116.0  \n",
      "5316       115.0        116.0  \n",
      "5317       115.0        116.0  \n",
      "5318       115.0        116.0  \n",
      "5319       115.0        116.0  \n",
      "...          ...          ...  \n",
      "5425       115.0        116.0  \n",
      "5426       115.0        116.0  \n",
      "5427       115.0        116.0  \n",
      "5428       115.0        116.0  \n",
      "5429       115.0        116.0  \n",
      "\n",
      "[115 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "5430  0.037428  0.045640 -0.034551 -0.024295       1     1.0       46   \n",
      "5431  0.038341  0.241240 -0.035037 -0.327676       0     1.0       46   \n",
      "5432  0.043165  0.046634 -0.041590 -0.046245       0     1.0       46   \n",
      "5433  0.044098 -0.147868 -0.042515  0.233031       0     1.0       46   \n",
      "5434  0.041141 -0.342357 -0.037855  0.512006       0     1.0       46   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "5548 -0.593288 -1.460696  0.071275  1.114122       0     1.0       46   \n",
      "5549 -0.622502 -1.656678  0.093557  1.428286       1     1.0       46   \n",
      "5550 -0.655635 -1.462828  0.122123  1.166248       0     1.0       46   \n",
      "5551 -0.684892 -1.659309  0.145448  1.494589       0     1.0       46   \n",
      "5552 -0.718078 -1.855869  0.175340  1.828928       0     1.0       46   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "5430       123.0        124.0  \n",
      "5431       123.0        124.0  \n",
      "5432       123.0        124.0  \n",
      "5433       123.0        124.0  \n",
      "5434       123.0        124.0  \n",
      "...          ...          ...  \n",
      "5548       123.0        124.0  \n",
      "5549       123.0        124.0  \n",
      "5550       123.0        124.0  \n",
      "5551       123.0        124.0  \n",
      "5552       123.0        124.0  \n",
      "\n",
      "[123 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "5553 -0.006921  0.041438  0.035217  0.025255       1     1.0       47   \n",
      "5554 -0.006092  0.236038  0.035722 -0.256112       0     1.0       47   \n",
      "5555 -0.001371  0.040424  0.030600  0.047621       1     1.0       47   \n",
      "5556 -0.000563  0.235094  0.031553 -0.235252       1     1.0       47   \n",
      "5557  0.004139  0.429752  0.026847 -0.517818       0     1.0       47   \n",
      "5558  0.012734  0.234262  0.016491 -0.216797       0     1.0       47   \n",
      "5559  0.017420  0.038909  0.012155  0.081042       0     1.0       47   \n",
      "5560  0.018198 -0.156386  0.013776  0.377535       1     1.0       47   \n",
      "5561  0.015070  0.038538  0.021327  0.089227       1     1.0       47   \n",
      "5562  0.015841  0.233348  0.023111 -0.196652       1     1.0       47   \n",
      "5563  0.020508  0.428132  0.019178 -0.481955       0     1.0       47   \n",
      "5564  0.029070  0.232744  0.009539 -0.183290       0     1.0       47   \n",
      "5565  0.033725  0.037487  0.005873  0.112387       0     1.0       47   \n",
      "5566  0.034475 -0.157718  0.008121  0.406917       1     1.0       47   \n",
      "5567  0.031321  0.037288  0.016259  0.116805       0     1.0       47   \n",
      "5568  0.032066 -0.158063  0.018595  0.414573       1     1.0       47   \n",
      "5569  0.028905  0.036790  0.026887  0.127810       0     1.0       47   \n",
      "5570  0.029641 -0.158707  0.029443  0.428853       1     1.0       47   \n",
      "5571  0.026467  0.035986  0.038020  0.145595       1     1.0       47   \n",
      "5572  0.027187  0.230544  0.040932 -0.134855       1     1.0       47   \n",
      "5573  0.031797  0.425056  0.038235 -0.414349       1     1.0       47   \n",
      "5574  0.040299  0.619616  0.029948 -0.694737       0     1.0       47   \n",
      "5575  0.052691  0.424092  0.016053 -0.392778       1     1.0       47   \n",
      "5576  0.061173  0.618982  0.008198 -0.680357       1     1.0       47   \n",
      "5577  0.073552  0.813989 -0.005409 -0.970448       1     1.0       47   \n",
      "5578  0.089832  1.009183 -0.024818 -1.264825       0     1.0       47   \n",
      "5579  0.110016  0.814387 -0.050115 -0.980017       1     1.0       47   \n",
      "5580  0.126304  1.010144 -0.069715 -1.288011       0     1.0       47   \n",
      "5581  0.146506  0.815975 -0.095475 -1.017944       1     1.0       47   \n",
      "5582  0.162826  1.012231 -0.115834 -1.339014       1     1.0       47   \n",
      "5583  0.183071  1.208605 -0.142615 -1.665581       1     1.0       47   \n",
      "5584  0.207243  1.405070 -0.175926 -1.999073       1     1.0       47   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "5553        32.0         33.0  \n",
      "5554        32.0         33.0  \n",
      "5555        32.0         33.0  \n",
      "5556        32.0         33.0  \n",
      "5557        32.0         33.0  \n",
      "5558        32.0         33.0  \n",
      "5559        32.0         33.0  \n",
      "5560        32.0         33.0  \n",
      "5561        32.0         33.0  \n",
      "5562        32.0         33.0  \n",
      "5563        32.0         33.0  \n",
      "5564        32.0         33.0  \n",
      "5565        32.0         33.0  \n",
      "5566        32.0         33.0  \n",
      "5567        32.0         33.0  \n",
      "5568        32.0         33.0  \n",
      "5569        32.0         33.0  \n",
      "5570        32.0         33.0  \n",
      "5571        32.0         33.0  \n",
      "5572        32.0         33.0  \n",
      "5573        32.0         33.0  \n",
      "5574        32.0         33.0  \n",
      "5575        32.0         33.0  \n",
      "5576        32.0         33.0  \n",
      "5577        32.0         33.0  \n",
      "5578        32.0         33.0  \n",
      "5579        32.0         33.0  \n",
      "5580        32.0         33.0  \n",
      "5581        32.0         33.0  \n",
      "5582        32.0         33.0  \n",
      "5583        32.0         33.0  \n",
      "5584        32.0         33.0  \n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "5585  0.021925 -0.012389 -0.005156  0.042600       1     1.0       48   \n",
      "5586  0.021677  0.182807 -0.004304 -0.251705       0     1.0       48   \n",
      "5587  0.025333 -0.012253 -0.009338  0.039617       1     1.0       48   \n",
      "5588  0.025088  0.183001 -0.008546 -0.255998       0     1.0       48   \n",
      "5589  0.028748 -0.011998 -0.013666  0.033978       1     1.0       48   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "5721  0.621030  1.511907 -0.048818 -1.490695       1     1.0       48   \n",
      "5722  0.651268  1.707588 -0.078632 -1.798214       1     1.0       48   \n",
      "5723  0.685420  1.903497 -0.114597 -2.114263       1     1.0       48   \n",
      "5724  0.723490  2.099561 -0.156882 -2.440049       1     1.0       48   \n",
      "5725  0.765481  2.295639 -0.205683 -2.776487       1     1.0       48   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "5585       141.0        142.0  \n",
      "5586       141.0        142.0  \n",
      "5587       141.0        142.0  \n",
      "5588       141.0        142.0  \n",
      "5589       141.0        142.0  \n",
      "...          ...          ...  \n",
      "5721       141.0        142.0  \n",
      "5722       141.0        142.0  \n",
      "5723       141.0        142.0  \n",
      "5724       141.0        142.0  \n",
      "5725       141.0        142.0  \n",
      "\n",
      "[141 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "5726  0.043313 -0.023314  0.007863  0.022773       0     1.0       49   \n",
      "5727  0.042846 -0.218547  0.008319  0.317926       1     1.0       49   \n",
      "5728  0.038475 -0.023545  0.014677  0.027878       1     1.0       49   \n",
      "5729  0.038005  0.171363  0.015235 -0.260138       1     1.0       49   \n",
      "5730  0.041432  0.366265  0.010032 -0.547977       0     1.0       49   \n",
      "5731  0.048757  0.171003 -0.000928 -0.252150       0     1.0       49   \n",
      "5732  0.052177 -0.024106 -0.005971  0.040240       0     1.0       49   \n",
      "5733  0.051695 -0.219141 -0.005166  0.331033       0     1.0       49   \n",
      "5734  0.047312 -0.414189  0.001455  0.622083       0     1.0       49   \n",
      "5735  0.039028 -0.609332  0.013896  0.915223       0     1.0       49   \n",
      "5736  0.026842 -0.804639  0.032201  1.212241       1     1.0       49   \n",
      "5737  0.010749 -0.609947  0.056446  0.929820       1     1.0       49   \n",
      "5738 -0.001450 -0.415630  0.075042  0.655396       1     1.0       49   \n",
      "5739 -0.009762 -0.221629  0.088150  0.387254       1     1.0       49   \n",
      "5740 -0.014195 -0.027862  0.095895  0.123615       1     1.0       49   \n",
      "5741 -0.014752  0.165765  0.098367 -0.137341       0     1.0       49   \n",
      "5742 -0.011437 -0.030618  0.095621  0.184683       1     1.0       49   \n",
      "5743 -0.012049  0.163015  0.099314 -0.076370       0     1.0       49   \n",
      "5744 -0.008789 -0.033380  0.097787  0.245922       1     1.0       49   \n",
      "5745 -0.009457  0.160219  0.102705 -0.014386       0     1.0       49   \n",
      "5746 -0.006252 -0.036215  0.102418  0.308854       1     1.0       49   \n",
      "5747 -0.006977  0.157310  0.108595  0.050146       1     1.0       49   \n",
      "5748 -0.003830  0.350721  0.109598 -0.206397       0     1.0       49   \n",
      "5749  0.003184  0.154216  0.105470  0.118748       1     1.0       49   \n",
      "5750  0.006268  0.347682  0.107845 -0.138886       0     1.0       49   \n",
      "5751  0.013222  0.151193  0.105067  0.185778       1     1.0       49   \n",
      "5752  0.016246  0.344668  0.108782 -0.071999       1     1.0       49   \n",
      "5753  0.023139  0.538075  0.107343 -0.328477       1     1.0       49   \n",
      "5754  0.033901  0.731519  0.100773 -0.585474       0     1.0       49   \n",
      "5755  0.048531  0.535140  0.089063 -0.262824       1     1.0       49   \n",
      "5756  0.059234  0.728885  0.083807 -0.526139       0     1.0       49   \n",
      "5757  0.073812  0.532690  0.073284 -0.208269       0     1.0       49   \n",
      "5758  0.084465  0.336601  0.069119  0.106601       0     1.0       49   \n",
      "5759  0.091197  0.140560  0.071251  0.420265       1     1.0       49   \n",
      "5760  0.094009  0.334604  0.079656  0.150868       0     1.0       49   \n",
      "5761  0.100701  0.138437  0.082674  0.467579       1     1.0       49   \n",
      "5762  0.103469  0.332300  0.092025  0.202057       1     1.0       49   \n",
      "5763  0.110115  0.525993  0.096066 -0.060237       0     1.0       49   \n",
      "5764  0.120635  0.329635  0.094862  0.261143       1     1.0       49   \n",
      "5765  0.127228  0.523284  0.100084 -0.000177       1     1.0       49   \n",
      "5766  0.137694  0.716838  0.100081 -0.259680       0     1.0       49   \n",
      "5767  0.152030  0.520441  0.094887  0.062817       0     1.0       49   \n",
      "5768  0.162439  0.324095  0.096144  0.383865       0     1.0       49   \n",
      "5769  0.168921  0.127749  0.103821  0.705247       0     1.0       49   \n",
      "5770  0.171476 -0.068646  0.117926  1.028722       1     1.0       49   \n",
      "5771  0.170103  0.124726  0.138500  0.775269       1     1.0       49   \n",
      "5772  0.172598  0.317698  0.154006  0.529170       0     1.0       49   \n",
      "5773  0.178952  0.120784  0.164589  0.866146       1     1.0       49   \n",
      "5774  0.181367  0.313329  0.181912  0.629402       1     1.0       49   \n",
      "5775  0.187634  0.505509  0.194500  0.399076       0     1.0       49   \n",
      "5776  0.197744  0.308237  0.202482  0.746228       1     1.0       49   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "5726        51.0         52.0  \n",
      "5727        51.0         52.0  \n",
      "5728        51.0         52.0  \n",
      "5729        51.0         52.0  \n",
      "5730        51.0         52.0  \n",
      "5731        51.0         52.0  \n",
      "5732        51.0         52.0  \n",
      "5733        51.0         52.0  \n",
      "5734        51.0         52.0  \n",
      "5735        51.0         52.0  \n",
      "5736        51.0         52.0  \n",
      "5737        51.0         52.0  \n",
      "5738        51.0         52.0  \n",
      "5739        51.0         52.0  \n",
      "5740        51.0         52.0  \n",
      "5741        51.0         52.0  \n",
      "5742        51.0         52.0  \n",
      "5743        51.0         52.0  \n",
      "5744        51.0         52.0  \n",
      "5745        51.0         52.0  \n",
      "5746        51.0         52.0  \n",
      "5747        51.0         52.0  \n",
      "5748        51.0         52.0  \n",
      "5749        51.0         52.0  \n",
      "5750        51.0         52.0  \n",
      "5751        51.0         52.0  \n",
      "5752        51.0         52.0  \n",
      "5753        51.0         52.0  \n",
      "5754        51.0         52.0  \n",
      "5755        51.0         52.0  \n",
      "5756        51.0         52.0  \n",
      "5757        51.0         52.0  \n",
      "5758        51.0         52.0  \n",
      "5759        51.0         52.0  \n",
      "5760        51.0         52.0  \n",
      "5761        51.0         52.0  \n",
      "5762        51.0         52.0  \n",
      "5763        51.0         52.0  \n",
      "5764        51.0         52.0  \n",
      "5765        51.0         52.0  \n",
      "5766        51.0         52.0  \n",
      "5767        51.0         52.0  \n",
      "5768        51.0         52.0  \n",
      "5769        51.0         52.0  \n",
      "5770        51.0         52.0  \n",
      "5771        51.0         52.0  \n",
      "5772        51.0         52.0  \n",
      "5773        51.0         52.0  \n",
      "5774        51.0         52.0  \n",
      "5775        51.0         52.0  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5776        51.0         52.0  \n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "5777  0.022076  0.009062 -0.017992 -0.049172       0     1.0       50   \n",
      "5778  0.022257 -0.185797 -0.018975  0.237781       1     1.0       50   \n",
      "5779  0.018541  0.009591 -0.014220 -0.060826       0     1.0       50   \n",
      "5780  0.018733 -0.185324 -0.015436  0.227336       1     1.0       50   \n",
      "5781  0.015026  0.010015 -0.010890 -0.070176       0     1.0       50   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "5892  0.750358  2.069133 -0.092745 -1.370727       0     1.0       50   \n",
      "5893  0.791741  1.875285 -0.120160 -1.108433       1     1.0       50   \n",
      "5894  0.829247  2.071764 -0.142328 -1.436268       1     1.0       50   \n",
      "5895  0.870682  2.268324 -0.171054 -1.769831       1     1.0       50   \n",
      "5896  0.916048  2.464915 -0.206450 -2.110458       1     1.0       50   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "5777       120.0        121.0  \n",
      "5778       120.0        121.0  \n",
      "5779       120.0        121.0  \n",
      "5780       120.0        121.0  \n",
      "5781       120.0        121.0  \n",
      "...          ...          ...  \n",
      "5892       120.0        121.0  \n",
      "5893       120.0        121.0  \n",
      "5894       120.0        121.0  \n",
      "5895       120.0        121.0  \n",
      "5896       120.0        121.0  \n",
      "\n",
      "[120 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "5897 -0.011826  0.001414 -0.045457 -0.028997       1     1.0       51   \n",
      "5898 -0.011798  0.197157 -0.046037 -0.335668       0     1.0       51   \n",
      "5899 -0.007855  0.002720 -0.052750 -0.057851       1     1.0       51   \n",
      "5900 -0.007800  0.198557 -0.053907 -0.366699       0     1.0       51   \n",
      "5901 -0.003829  0.004240 -0.061241 -0.091490       0     1.0       51   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "5969 -0.599828 -1.515646  0.091947  1.348063       1     1.0       51   \n",
      "5970 -0.630141 -1.321792  0.118908  1.085505       0     1.0       51   \n",
      "5971 -0.656577 -1.518264  0.140618  1.413009       0     1.0       51   \n",
      "5972 -0.686942 -1.714821  0.168879  1.746140       0     1.0       51   \n",
      "5973 -0.721238 -1.911413  0.203801  2.086247       0     1.0       51   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "5897        77.0         78.0  \n",
      "5898        77.0         78.0  \n",
      "5899        77.0         78.0  \n",
      "5900        77.0         78.0  \n",
      "5901        77.0         78.0  \n",
      "...          ...          ...  \n",
      "5969        77.0         78.0  \n",
      "5970        77.0         78.0  \n",
      "5971        77.0         78.0  \n",
      "5972        77.0         78.0  \n",
      "5973        77.0         78.0  \n",
      "\n",
      "[77 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "5974 -0.034691 -0.030920 -0.000241  0.047526       1     1.0       52   \n",
      "5975 -0.035310  0.164206  0.000709 -0.245233       1     1.0       52   \n",
      "5976 -0.032026  0.359317 -0.004195 -0.537692       0     1.0       52   \n",
      "5977 -0.024839  0.164255 -0.014949 -0.246334       1     1.0       52   \n",
      "5978 -0.021554  0.359587 -0.019876 -0.543695       1     1.0       52   \n",
      "5979 -0.014362  0.554983 -0.030750 -0.842573       0     1.0       52   \n",
      "5980 -0.003263  0.360293 -0.047601 -0.559717       1     1.0       52   \n",
      "5981  0.003943  0.556050 -0.058796 -0.867008       0     1.0       52   \n",
      "5982  0.015064  0.361775 -0.076136 -0.593376       0     1.0       52   \n",
      "5983  0.022300  0.167797 -0.088003 -0.325614       0     1.0       52   \n",
      "5984  0.025656 -0.025969 -0.094515 -0.061929       0     1.0       52   \n",
      "5985  0.025136 -0.219618 -0.095754  0.199501       0     1.0       52   \n",
      "5986  0.020744 -0.413249 -0.091764  0.460509       1     1.0       52   \n",
      "5987  0.012479 -0.216958 -0.082554  0.140371       0     1.0       52   \n",
      "5988  0.008140 -0.410806 -0.079746  0.405910       1     1.0       52   \n",
      "5989 -0.000076 -0.214649 -0.071628  0.089189       0     1.0       52   \n",
      "5990 -0.004369 -0.408675 -0.069844  0.358441       0     1.0       52   \n",
      "5991 -0.012543 -0.602739 -0.062676  0.628309       0     1.0       52   \n",
      "5992 -0.024598 -0.796932 -0.050109  0.900613       0     1.0       52   \n",
      "5993 -0.040536 -0.991341 -0.032097  1.177133       1     1.0       52   \n",
      "5994 -0.060363 -0.795817 -0.008555  0.874564       1     1.0       52   \n",
      "5995 -0.076280 -0.600580  0.008937  0.579204       1     1.0       52   \n",
      "5996 -0.088291 -0.405584  0.020521  0.289349       0     1.0       52   \n",
      "5997 -0.096403 -0.600993  0.026308  0.588433       1     1.0       52   \n",
      "5998 -0.108423 -0.406249  0.038076  0.304152       0     1.0       52   \n",
      "5999 -0.116548 -0.601892  0.044160  0.608596       1     1.0       52   \n",
      "6000 -0.128585 -0.407414  0.056331  0.330143       0     1.0       52   \n",
      "6001 -0.136734 -0.603291  0.062934  0.640044       1     1.0       52   \n",
      "6002 -0.148800 -0.409100  0.075735  0.367825       0     1.0       52   \n",
      "6003 -0.156982 -0.605212  0.083092  0.683395       1     1.0       52   \n",
      "6004 -0.169086 -0.411336  0.096760  0.417985       0     1.0       52   \n",
      "6005 -0.177313 -0.607687  0.105119  0.739536       1     1.0       52   \n",
      "6006 -0.189466 -0.414161  0.119910  0.481698       0     1.0       52   \n",
      "6007 -0.197750 -0.610754  0.129544  0.809638       0     1.0       52   \n",
      "6008 -0.209965 -0.807390  0.145737  1.140101       1     1.0       52   \n",
      "6009 -0.226112 -0.614442  0.168539  0.896442       1     1.0       52   \n",
      "6010 -0.238401 -0.421957  0.186468  0.661121       1     1.0       52   \n",
      "6011 -0.246840 -0.229851  0.199690  0.432463       1     1.0       52   \n",
      "6012 -0.251437 -0.038034  0.208339  0.208774       1     1.0       52   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "5974        39.0         40.0  \n",
      "5975        39.0         40.0  \n",
      "5976        39.0         40.0  \n",
      "5977        39.0         40.0  \n",
      "5978        39.0         40.0  \n",
      "5979        39.0         40.0  \n",
      "5980        39.0         40.0  \n",
      "5981        39.0         40.0  \n",
      "5982        39.0         40.0  \n",
      "5983        39.0         40.0  \n",
      "5984        39.0         40.0  \n",
      "5985        39.0         40.0  \n",
      "5986        39.0         40.0  \n",
      "5987        39.0         40.0  \n",
      "5988        39.0         40.0  \n",
      "5989        39.0         40.0  \n",
      "5990        39.0         40.0  \n",
      "5991        39.0         40.0  \n",
      "5992        39.0         40.0  \n",
      "5993        39.0         40.0  \n",
      "5994        39.0         40.0  \n",
      "5995        39.0         40.0  \n",
      "5996        39.0         40.0  \n",
      "5997        39.0         40.0  \n",
      "5998        39.0         40.0  \n",
      "5999        39.0         40.0  \n",
      "6000        39.0         40.0  \n",
      "6001        39.0         40.0  \n",
      "6002        39.0         40.0  \n",
      "6003        39.0         40.0  \n",
      "6004        39.0         40.0  \n",
      "6005        39.0         40.0  \n",
      "6006        39.0         40.0  \n",
      "6007        39.0         40.0  \n",
      "6008        39.0         40.0  \n",
      "6009        39.0         40.0  \n",
      "6010        39.0         40.0  \n",
      "6011        39.0         40.0  \n",
      "6012        39.0         40.0  \n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "6013  0.001974  0.025052 -0.000662 -0.028886       0     1.0       53   \n",
      "6014  0.002475 -0.170061 -0.001239  0.263588       1     1.0       53   \n",
      "6015 -0.000926  0.025079  0.004032 -0.029485       0     1.0       53   \n",
      "6016 -0.000425 -0.170101  0.003443  0.264467       1     1.0       53   \n",
      "6017 -0.003827  0.024972  0.008732 -0.027128       0     1.0       53   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "6114 -0.542860 -1.296799  0.078850  1.051874       0     1.0       53   \n",
      "6115 -0.568796 -1.492873  0.099887  1.368229       1     1.0       53   \n",
      "6116 -0.598653 -1.299133  0.127252  1.108386       0     1.0       53   \n",
      "6117 -0.624636 -1.495677  0.149419  1.438128       0     1.0       53   \n",
      "6118 -0.654550 -1.692291  0.178182  1.773529       0     1.0       53   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "6013       106.0        107.0  \n",
      "6014       106.0        107.0  \n",
      "6015       106.0        107.0  \n",
      "6016       106.0        107.0  \n",
      "6017       106.0        107.0  \n",
      "...          ...          ...  \n",
      "6114       106.0        107.0  \n",
      "6115       106.0        107.0  \n",
      "6116       106.0        107.0  \n",
      "6117       106.0        107.0  \n",
      "6118       106.0        107.0  \n",
      "\n",
      "[106 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "6119  0.030531  0.022239 -0.036830 -0.028878       1     1.0       54   \n",
      "6120  0.030975  0.217869 -0.037408 -0.332950       0     1.0       54   \n",
      "6121  0.035333  0.023299 -0.044067 -0.052294       0     1.0       54   \n",
      "6122  0.035799 -0.171164 -0.045112  0.226167       0     1.0       54   \n",
      "6123  0.032375 -0.365614 -0.040589  0.504285       0     1.0       54   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "6227 -0.606716 -1.492043  0.095086  1.287129       1     1.0       54   \n",
      "6228 -0.636556 -1.298251  0.120828  1.025667       0     1.0       54   \n",
      "6229 -0.662521 -1.494756  0.141342  1.353713       0     1.0       54   \n",
      "6230 -0.692417 -1.691341  0.168416  1.687066       0     1.0       54   \n",
      "6231 -0.726243 -1.887963  0.202157  2.027107       0     1.0       54   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "6119       113.0        114.0  \n",
      "6120       113.0        114.0  \n",
      "6121       113.0        114.0  \n",
      "6122       113.0        114.0  \n",
      "6123       113.0        114.0  \n",
      "...          ...          ...  \n",
      "6227       113.0        114.0  \n",
      "6228       113.0        114.0  \n",
      "6229       113.0        114.0  \n",
      "6230       113.0        114.0  \n",
      "6231       113.0        114.0  \n",
      "\n",
      "[113 rows x 9 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "6232 -0.032723  0.017031 -0.044400  0.019595       0     1.0       55   \n",
      "6233 -0.032382 -0.177427 -0.044008  0.297945       1     1.0       55   \n",
      "6234 -0.035930  0.018294 -0.038049 -0.008286       0     1.0       55   \n",
      "6235 -0.035565 -0.176262 -0.038215  0.272154       0     1.0       55   \n",
      "6236 -0.039090 -0.370819 -0.032772  0.552543       1     1.0       55   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "6359 -0.666544 -1.675209  0.098938  1.250017       1     1.0       55   \n",
      "6360 -0.700048 -1.481484  0.123939  0.989892       0     1.0       55   \n",
      "6361 -0.729678 -1.678027  0.143736  1.318790       0     1.0       55   \n",
      "6362 -0.763239 -1.874644  0.170112  1.652787       0     1.0       55   \n",
      "6363 -0.800732 -2.071295  0.203168  1.993279       1     1.0       55   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "6232       132.0        133.0  \n",
      "6233       132.0        133.0  \n",
      "6234       132.0        133.0  \n",
      "6235       132.0        133.0  \n",
      "6236       132.0        133.0  \n",
      "...          ...          ...  \n",
      "6359       132.0        133.0  \n",
      "6360       132.0        133.0  \n",
      "6361       132.0        133.0  \n",
      "6362       132.0        133.0  \n",
      "6363       132.0        133.0  \n",
      "\n",
      "[132 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "6364  0.024601  0.012784  0.034654 -0.033230       1     1.0       56   \n",
      "6365  0.024857  0.207392  0.033990 -0.314780       0     1.0       56   \n",
      "6366  0.029004  0.011803  0.027694 -0.011575       1     1.0       56   \n",
      "6367  0.029240  0.206517  0.027463 -0.295393       0     1.0       56   \n",
      "6368  0.033371  0.011014  0.021555  0.005823       1     1.0       56   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "6553 -0.661931 -1.683754  0.073701  1.289714       1     1.0       56   \n",
      "6554 -0.695606 -1.489642  0.099495  1.020986       0     1.0       56   \n",
      "6555 -0.725399 -1.685939  0.119915  1.343178       0     1.0       56   \n",
      "6556 -0.759118 -1.882348  0.146778  1.670846       0     1.0       56   \n",
      "6557 -0.796765 -2.078839  0.180195  2.005412       1     1.0       56   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "6364       194.0        195.0  \n",
      "6365       194.0        195.0  \n",
      "6366       194.0        195.0  \n",
      "6367       194.0        195.0  \n",
      "6368       194.0        195.0  \n",
      "...          ...          ...  \n",
      "6553       194.0        195.0  \n",
      "6554       194.0        195.0  \n",
      "6555       194.0        195.0  \n",
      "6556       194.0        195.0  \n",
      "6557       194.0        195.0  \n",
      "\n",
      "[194 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "6558  0.020551 -0.020078 -0.025061 -0.003482       0     1.0       57   \n",
      "6559  0.020149 -0.214832 -0.025131  0.281189       1     1.0       57   \n",
      "6560  0.015853 -0.019361 -0.019507 -0.019313       0     1.0       57   \n",
      "6561  0.015465 -0.214198 -0.019893  0.267152       0     1.0       57   \n",
      "6562  0.011181 -0.409030 -0.014550  0.553495       1     1.0       57   \n",
      "6563  0.003001 -0.213707 -0.003480  0.256264       0     1.0       57   \n",
      "6564 -0.001273 -0.408779  0.001645  0.547847       1     1.0       57   \n",
      "6565 -0.009449 -0.213680  0.012602  0.255683       1     1.0       57   \n",
      "6566 -0.013723 -0.018741  0.017716 -0.032999       1     1.0       57   \n",
      "6567 -0.014097  0.176123  0.017056 -0.320040       0     1.0       57   \n",
      "6568 -0.010575 -0.019238  0.010655 -0.022027       1     1.0       57   \n",
      "6569 -0.010960  0.175730  0.010214 -0.311330       1     1.0       57   \n",
      "6570 -0.007445  0.370705  0.003988 -0.600774       0     1.0       57   \n",
      "6571 -0.000031  0.175527 -0.008028 -0.306837       0     1.0       57   \n",
      "6572  0.003480 -0.019479 -0.014164 -0.016697       1     1.0       57   \n",
      "6573  0.003090  0.175843 -0.014498 -0.313815       0     1.0       57   \n",
      "6574  0.006607 -0.019070 -0.020775 -0.025740       0     1.0       57   \n",
      "6575  0.006225 -0.213888 -0.021289  0.260317       1     1.0       57   \n",
      "6576  0.001948 -0.018468 -0.016083 -0.039004       1     1.0       57   \n",
      "6577  0.001578  0.176881 -0.016863 -0.336718       0     1.0       57   \n",
      "6578  0.005116 -0.017997 -0.023598 -0.049400       1     1.0       57   \n",
      "6579  0.004756  0.177455 -0.024586 -0.349434       0     1.0       57   \n",
      "6580  0.008305 -0.017309 -0.031574 -0.064604       0     1.0       57   \n",
      "6581  0.007959 -0.211964 -0.032866  0.217953       1     1.0       57   \n",
      "6582  0.003720 -0.016388 -0.028507 -0.084914       1     1.0       57   \n",
      "6583  0.003392  0.179130 -0.030206 -0.386453       0     1.0       57   \n",
      "6584  0.006974 -0.015550 -0.037935 -0.103444       0     1.0       57   \n",
      "6585  0.006663 -0.210108 -0.040003  0.177033       0     1.0       57   \n",
      "6586  0.002461 -0.404636 -0.036463  0.456833       1     1.0       57   \n",
      "6587 -0.005631 -0.209018 -0.027326  0.152883       1     1.0       57   \n",
      "6588 -0.009812 -0.013515 -0.024268 -0.148294       0     1.0       57   \n",
      "6589 -0.010082 -0.208282 -0.027234  0.136635       0     1.0       57   \n",
      "6590 -0.014248 -0.403003 -0.024502  0.420603       0     1.0       57   \n",
      "6591 -0.022308 -0.597769 -0.016090  0.705462       1     1.0       57   \n",
      "6592 -0.034263 -0.402428 -0.001980  0.407758       1     1.0       57   \n",
      "6593 -0.042312 -0.207278  0.006175  0.114452       0     1.0       57   \n",
      "6594 -0.046457 -0.402488  0.008464  0.409076       1     1.0       57   \n",
      "6595 -0.054507 -0.207487  0.016645  0.119074       0     1.0       57   \n",
      "6596 -0.058657 -0.402844  0.019027  0.416961       0     1.0       57   \n",
      "6597 -0.066714 -0.598230  0.027366  0.715581       1     1.0       57   \n",
      "6598 -0.078678 -0.403497  0.041678  0.431636       0     1.0       57   \n",
      "6599 -0.086748 -0.599184  0.050310  0.737161       1     1.0       57   \n",
      "6600 -0.098732 -0.404792  0.065054  0.460727       1     1.0       57   \n",
      "6601 -0.106828 -0.210647  0.074268  0.189237       0     1.0       57   \n",
      "6602 -0.111041 -0.406748  0.078053  0.504393       1     1.0       57   \n",
      "6603 -0.119176 -0.212808  0.088141  0.237293       1     1.0       57   \n",
      "6604 -0.123432 -0.019049  0.092887 -0.026338       0     1.0       57   \n",
      "6605 -0.123813 -0.215371  0.092360  0.294146       0     1.0       57   \n",
      "6606 -0.128120 -0.411680  0.098243  0.614470       0     1.0       57   \n",
      "6607 -0.136354 -0.608028  0.110532  0.936408       0     1.0       57   \n",
      "6608 -0.148514 -0.804453  0.129260  1.261678       1     1.0       57   \n",
      "6609 -0.164603 -0.611199  0.154494  1.012112       1     1.0       57   \n",
      "6610 -0.176827 -0.418438  0.174736  0.771655       0     1.0       57   \n",
      "6611 -0.185196 -0.615478  0.190169  1.113826       0     1.0       57   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "6558        54.0         55.0  \n",
      "6559        54.0         55.0  \n",
      "6560        54.0         55.0  \n",
      "6561        54.0         55.0  \n",
      "6562        54.0         55.0  \n",
      "6563        54.0         55.0  \n",
      "6564        54.0         55.0  \n",
      "6565        54.0         55.0  \n",
      "6566        54.0         55.0  \n",
      "6567        54.0         55.0  \n",
      "6568        54.0         55.0  \n",
      "6569        54.0         55.0  \n",
      "6570        54.0         55.0  \n",
      "6571        54.0         55.0  \n",
      "6572        54.0         55.0  \n",
      "6573        54.0         55.0  \n",
      "6574        54.0         55.0  \n",
      "6575        54.0         55.0  \n",
      "6576        54.0         55.0  \n",
      "6577        54.0         55.0  \n",
      "6578        54.0         55.0  \n",
      "6579        54.0         55.0  \n",
      "6580        54.0         55.0  \n",
      "6581        54.0         55.0  \n",
      "6582        54.0         55.0  \n",
      "6583        54.0         55.0  \n",
      "6584        54.0         55.0  \n",
      "6585        54.0         55.0  \n",
      "6586        54.0         55.0  \n",
      "6587        54.0         55.0  \n",
      "6588        54.0         55.0  \n",
      "6589        54.0         55.0  \n",
      "6590        54.0         55.0  \n",
      "6591        54.0         55.0  \n",
      "6592        54.0         55.0  \n",
      "6593        54.0         55.0  \n",
      "6594        54.0         55.0  \n",
      "6595        54.0         55.0  \n",
      "6596        54.0         55.0  \n",
      "6597        54.0         55.0  \n",
      "6598        54.0         55.0  \n",
      "6599        54.0         55.0  \n",
      "6600        54.0         55.0  \n",
      "6601        54.0         55.0  \n",
      "6602        54.0         55.0  \n",
      "6603        54.0         55.0  \n",
      "6604        54.0         55.0  \n",
      "6605        54.0         55.0  \n",
      "6606        54.0         55.0  \n",
      "6607        54.0         55.0  \n",
      "6608        54.0         55.0  \n",
      "6609        54.0         55.0  \n",
      "6610        54.0         55.0  \n",
      "6611        54.0         55.0  \n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "6612 -0.012975 -0.006626 -0.009451  0.015024       0     1.0       58   \n",
      "6613 -0.013108 -0.201611 -0.009151  0.304710       1     1.0       58   \n",
      "6614 -0.017140 -0.006360 -0.003056  0.009156       0     1.0       58   \n",
      "6615 -0.017267 -0.201438 -0.002873  0.300873       0     1.0       58   \n",
      "6616 -0.021296 -0.396519  0.003144  0.592648       1     1.0       58   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "6671  0.655201  1.669676 -0.061695 -0.860667       1     1.0       58   \n",
      "6672  0.688595  1.865582 -0.078909 -1.172093       1     1.0       58   \n",
      "6673  0.725906  2.061636 -0.102351 -1.488434       1     1.0       58   \n",
      "6674  0.767139  2.257845 -0.132119 -1.811246       1     1.0       58   \n",
      "6675  0.812296  2.454168 -0.168344 -2.141895       1     1.0       58   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "6612        64.0         65.0  \n",
      "6613        64.0         65.0  \n",
      "6614        64.0         65.0  \n",
      "6615        64.0         65.0  \n",
      "6616        64.0         65.0  \n",
      "...          ...          ...  \n",
      "6671        64.0         65.0  \n",
      "6672        64.0         65.0  \n",
      "6673        64.0         65.0  \n",
      "6674        64.0         65.0  \n",
      "6675        64.0         65.0  \n",
      "\n",
      "[64 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "6676 -0.041184  0.010529  0.043901  0.032563       1     1.0       59   \n",
      "6677 -0.040973  0.204995  0.044552 -0.245952       1     1.0       59   \n",
      "6678 -0.036873  0.399453  0.039633 -0.524256       1     1.0       59   \n",
      "6679 -0.028884  0.593996  0.029148 -0.804191       0     1.0       59   \n",
      "6680 -0.017004  0.398487  0.013064 -0.502484       0     1.0       59   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "6775 -0.755686 -1.684422  0.043097  1.318680       0     1.0       59   \n",
      "6776 -0.789375 -1.880062  0.069471  1.624534       0     1.0       59   \n",
      "6777 -0.826976 -2.075929  0.101961  1.938034       1     1.0       59   \n",
      "6778 -0.868494 -1.882033  0.140722  1.678625       0     1.0       59   \n",
      "6779 -0.906135 -2.078478  0.174294  2.011616       1     1.0       59   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "6676       104.0        105.0  \n",
      "6677       104.0        105.0  \n",
      "6678       104.0        105.0  \n",
      "6679       104.0        105.0  \n",
      "6680       104.0        105.0  \n",
      "...          ...          ...  \n",
      "6775       104.0        105.0  \n",
      "6776       104.0        105.0  \n",
      "6777       104.0        105.0  \n",
      "6778       104.0        105.0  \n",
      "6779       104.0        105.0  \n",
      "\n",
      "[104 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "6780  0.000212  0.046813  0.026873 -0.003866       0     1.0       60   \n",
      "6781  0.001148 -0.148684  0.026795  0.297173       1     1.0       60   \n",
      "6782 -0.001825  0.046046  0.032739  0.013059       1     1.0       60   \n",
      "6783 -0.000905  0.240684  0.033000 -0.269117       0     1.0       60   \n",
      "6784  0.003909  0.045107  0.027618  0.033789       1     1.0       60   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "6858  0.167596  0.835519 -0.054829 -1.357078       1     1.0       60   \n",
      "6859  0.184307  1.031284 -0.081970 -1.666396       1     1.0       60   \n",
      "6860  0.204932  1.227258 -0.115298 -1.983443       1     1.0       60   \n",
      "6861  0.229478  1.423388 -0.154967 -2.309506       1     1.0       60   \n",
      "6862  0.257945  1.619551 -0.201157 -2.645604       1     1.0       60   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "6780        83.0         84.0  \n",
      "6781        83.0         84.0  \n",
      "6782        83.0         84.0  \n",
      "6783        83.0         84.0  \n",
      "6784        83.0         84.0  \n",
      "...          ...          ...  \n",
      "6858        83.0         84.0  \n",
      "6859        83.0         84.0  \n",
      "6860        83.0         84.0  \n",
      "6861        83.0         84.0  \n",
      "6862        83.0         84.0  \n",
      "\n",
      "[83 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "6863  0.018137 -0.048067  0.010614 -0.031612       1     1.0       61   \n",
      "6864  0.017175  0.146901  0.009982 -0.320927       1     1.0       61   \n",
      "6865  0.020113  0.341880  0.003564 -0.610445       0     1.0       61   \n",
      "6866  0.026951  0.146708 -0.008645 -0.316642       0     1.0       61   \n",
      "6867  0.029885 -0.048290 -0.014978 -0.026698       0     1.0       61   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "6956 -0.660234 -1.369512  0.107430  1.042648       0     1.0       61   \n",
      "6957 -0.687625 -1.565884  0.128283  1.367032       1     1.0       61   \n",
      "6958 -0.718942 -1.372580  0.155623  1.117070       0     1.0       61   \n",
      "6959 -0.746394 -1.569364  0.177965  1.454247       0     1.0       61   \n",
      "6960 -0.777781 -1.766168  0.207050  1.796836       0     1.0       61   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "6863        98.0         99.0  \n",
      "6864        98.0         99.0  \n",
      "6865        98.0         99.0  \n",
      "6866        98.0         99.0  \n",
      "6867        98.0         99.0  \n",
      "...          ...          ...  \n",
      "6956        98.0         99.0  \n",
      "6957        98.0         99.0  \n",
      "6958        98.0         99.0  \n",
      "6959        98.0         99.0  \n",
      "6960        98.0         99.0  \n",
      "\n",
      "[98 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "6961 -0.009863 -0.043612  0.036098 -0.037916       0     1.0       62   \n",
      "6962 -0.010735 -0.239232  0.035340  0.265935       0     1.0       62   \n",
      "6963 -0.015520 -0.434840  0.040659  0.569551       1     1.0       62   \n",
      "6964 -0.024216 -0.240312  0.052050  0.289950       1     1.0       62   \n",
      "6965 -0.029023 -0.045969  0.057849  0.014126       1     1.0       62   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "7073  0.627248  1.474810 -0.051652 -1.441902       1     1.0       62   \n",
      "7074  0.656744  1.670529 -0.080490 -1.750267       1     1.0       62   \n",
      "7075  0.690155  1.866467 -0.115495 -2.066861       1     1.0       62   \n",
      "7076  0.727484  2.062560 -0.156832 -2.392921       1     1.0       62   \n",
      "7077  0.768735  2.258672 -0.204691 -2.729399       1     1.0       62   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "6961       117.0        118.0  \n",
      "6962       117.0        118.0  \n",
      "6963       117.0        118.0  \n",
      "6964       117.0        118.0  \n",
      "6965       117.0        118.0  \n",
      "...          ...          ...  \n",
      "7073       117.0        118.0  \n",
      "7074       117.0        118.0  \n",
      "7075       117.0        118.0  \n",
      "7076       117.0        118.0  \n",
      "7077       117.0        118.0  \n",
      "\n",
      "[117 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "7078  0.000230  0.020220  0.025992  0.024068       1     1.0       63   \n",
      "7079  0.000634  0.214959  0.026473 -0.260302       1     1.0       63   \n",
      "7080  0.004933  0.409694  0.021267 -0.544518       0     1.0       63   \n",
      "7081  0.013127  0.214279  0.010377 -0.245211       0     1.0       63   \n",
      "7082  0.017413  0.019011  0.005473  0.050727       0     1.0       63   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "7187 -0.661470 -1.675488  0.083260  1.329717       1     1.0       63   \n",
      "7188 -0.694979 -1.481509  0.109855  1.064207       0     1.0       63   \n",
      "7189 -0.724610 -1.677900  0.131139  1.389250       0     1.0       63   \n",
      "7190 -0.758168 -1.874389  0.158924  1.719897       0     1.0       63   \n",
      "7191 -0.795655 -2.070935  0.193322  2.057528       1     1.0       63   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "7078       114.0        115.0  \n",
      "7079       114.0        115.0  \n",
      "7080       114.0        115.0  \n",
      "7081       114.0        115.0  \n",
      "7082       114.0        115.0  \n",
      "...          ...          ...  \n",
      "7187       114.0        115.0  \n",
      "7188       114.0        115.0  \n",
      "7189       114.0        115.0  \n",
      "7190       114.0        115.0  \n",
      "7191       114.0        115.0  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[114 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "7192  0.009179  0.025572  0.041008 -0.016774       1     1.0       64   \n",
      "7193  0.009690  0.220083  0.040673 -0.296241       0     1.0       64   \n",
      "7194  0.014092  0.024406  0.034748  0.008986       1     1.0       64   \n",
      "7195  0.014580  0.219012  0.034928 -0.272534       1     1.0       64   \n",
      "7196  0.018960  0.413619  0.029477 -0.553999       0     1.0       64   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "7324  0.667936  1.549375 -0.048380 -1.539159       1     1.0       64   \n",
      "7325  0.698923  1.745044 -0.079163 -1.846538       1     1.0       64   \n",
      "7326  0.733824  1.940944 -0.116094 -2.162717       1     1.0       64   \n",
      "7327  0.772643  2.136995 -0.159348 -2.488869       1     1.0       64   \n",
      "7328  0.815383  2.333044 -0.209125 -2.825866       1     1.0       64   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "7192       137.0        138.0  \n",
      "7193       137.0        138.0  \n",
      "7194       137.0        138.0  \n",
      "7195       137.0        138.0  \n",
      "7196       137.0        138.0  \n",
      "...          ...          ...  \n",
      "7324       137.0        138.0  \n",
      "7325       137.0        138.0  \n",
      "7326       137.0        138.0  \n",
      "7327       137.0        138.0  \n",
      "7328       137.0        138.0  \n",
      "\n",
      "[137 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "7329 -0.048630 -0.013592  0.030633  0.049522       0     1.0       65   \n",
      "7330 -0.048902 -0.209140  0.031623  0.351710       1     1.0       65   \n",
      "7331 -0.053085 -0.014482  0.038657  0.069164       0     1.0       65   \n",
      "7332 -0.053375 -0.210136  0.040041  0.373789       1     1.0       65   \n",
      "7333 -0.057577 -0.015605  0.047516  0.093995       1     1.0       65   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "7524  0.117956 -0.202129 -0.047188  0.197186       1     1.0       65   \n",
      "7525  0.113913 -0.006365 -0.043245 -0.110001       0     1.0       65   \n",
      "7526  0.113786 -0.200841 -0.045445  0.168731       1     1.0       65   \n",
      "7527  0.109769 -0.005100 -0.042070 -0.137935       1     1.0       65   \n",
      "7528  0.109667  0.190599 -0.044829 -0.443588       0     1.0       65   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "7329       200.0        201.0  \n",
      "7330       200.0        201.0  \n",
      "7331       200.0        201.0  \n",
      "7332       200.0        201.0  \n",
      "7333       200.0        201.0  \n",
      "...          ...          ...  \n",
      "7524       200.0        201.0  \n",
      "7525       200.0        201.0  \n",
      "7526       200.0        201.0  \n",
      "7527       200.0        201.0  \n",
      "7528       200.0        201.0  \n",
      "\n",
      "[200 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "7529  0.018588 -0.013510 -0.018366  0.031029       0     1.0       66   \n",
      "7530  0.018318 -0.208363 -0.017746  0.317861       0     1.0       66   \n",
      "7531  0.014150 -0.403228 -0.011388  0.604895       1     1.0       66   \n",
      "7532  0.006086 -0.207949  0.000709  0.308647       0     1.0       66   \n",
      "7533  0.001927 -0.403081  0.006882  0.601554       1     1.0       66   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "7698  0.153567  0.584501 -0.047064 -1.126648       1     1.0       66   \n",
      "7699  0.165257  0.780207 -0.069597 -1.433714       1     1.0       66   \n",
      "7700  0.180861  0.976115 -0.098272 -1.747310       1     1.0       66   \n",
      "7701  0.200383  1.172207 -0.133218 -2.068874       1     1.0       66   \n",
      "7702  0.223827  1.368409 -0.174595 -2.399620       1     1.0       66   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "7529       174.0        175.0  \n",
      "7530       174.0        175.0  \n",
      "7531       174.0        175.0  \n",
      "7532       174.0        175.0  \n",
      "7533       174.0        175.0  \n",
      "...          ...          ...  \n",
      "7698       174.0        175.0  \n",
      "7699       174.0        175.0  \n",
      "7700       174.0        175.0  \n",
      "7701       174.0        175.0  \n",
      "7702       174.0        175.0  \n",
      "\n",
      "[174 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "7703 -0.007221  0.013176  0.026628 -0.007296       1     1.0       67   \n",
      "7704 -0.006957  0.207906  0.026482 -0.291460       1     1.0       67   \n",
      "7705 -0.002799  0.402640  0.020653 -0.575675       0     1.0       67   \n",
      "7706  0.005254  0.207235  0.009139 -0.276558       0     1.0       67   \n",
      "7707  0.009399  0.011984  0.003608  0.018994       1     1.0       67   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "7889  0.580209  1.141507 -0.083830 -0.830557       1     1.0       67   \n",
      "7890  0.603040  1.337669 -0.100441 -1.148383       1     1.0       67   \n",
      "7891  0.629793  1.533948 -0.123409 -1.470798       1     1.0       67   \n",
      "7892  0.660472  1.730344 -0.152825 -1.799343       1     1.0       67   \n",
      "7893  0.695079  1.926810 -0.188812 -2.135362       1     1.0       67   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "7703       191.0        192.0  \n",
      "7704       191.0        192.0  \n",
      "7705       191.0        192.0  \n",
      "7706       191.0        192.0  \n",
      "7707       191.0        192.0  \n",
      "...          ...          ...  \n",
      "7889       191.0        192.0  \n",
      "7890       191.0        192.0  \n",
      "7891       191.0        192.0  \n",
      "7892       191.0        192.0  \n",
      "7893       191.0        192.0  \n",
      "\n",
      "[191 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "7894  0.045537  0.011518  0.005307 -0.016900       1     1.0       68   \n",
      "7895  0.045768  0.206563  0.004969 -0.307904       0     1.0       68   \n",
      "7896  0.049899  0.011371 -0.001189 -0.013658       0     1.0       68   \n",
      "7897  0.050126 -0.183734 -0.001462  0.278650       1     1.0       68   \n",
      "7898  0.046452  0.011409  0.004111 -0.014494       1     1.0       68   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "7989 -0.544519 -1.310431  0.073804  1.065634       0     1.0       68   \n",
      "7990 -0.570728 -1.506448  0.095117  1.380538       1     1.0       68   \n",
      "7991 -0.600857 -1.312633  0.122728  1.119052       0     1.0       68   \n",
      "7992 -0.627110 -1.509133  0.145109  1.447575       0     1.0       68   \n",
      "7993 -0.657292 -1.705710  0.174060  1.781855       0     1.0       68   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "7894       100.0        101.0  \n",
      "7895       100.0        101.0  \n",
      "7896       100.0        101.0  \n",
      "7897       100.0        101.0  \n",
      "7898       100.0        101.0  \n",
      "...          ...          ...  \n",
      "7989       100.0        101.0  \n",
      "7990       100.0        101.0  \n",
      "7991       100.0        101.0  \n",
      "7992       100.0        101.0  \n",
      "7993       100.0        101.0  \n",
      "\n",
      "[100 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "7994 -0.043750 -0.017941  0.015019 -0.008883       0     1.0       69   \n",
      "7995 -0.044109 -0.213276  0.014842  0.288501       0     1.0       69   \n",
      "7996 -0.048374 -0.408606  0.020612  0.585827       1     1.0       69   \n",
      "7997 -0.056546 -0.213779  0.032328  0.299708       1     1.0       69   \n",
      "7998 -0.060822 -0.019132  0.038322  0.017394       1     1.0       69   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "8156 -0.705396 -1.901858  0.061527  1.435108       0     1.0       69   \n",
      "8157 -0.743433 -2.097683  0.090229  1.746366       1     1.0       69   \n",
      "8158 -0.785387 -1.903695  0.125157  1.483060       0     1.0       69   \n",
      "8159 -0.823461 -2.100101  0.154818  1.812065       1     1.0       69   \n",
      "8160 -0.865463 -1.907006  0.191059  1.571221       0     1.0       69   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "7994       167.0        168.0  \n",
      "7995       167.0        168.0  \n",
      "7996       167.0        168.0  \n",
      "7997       167.0        168.0  \n",
      "7998       167.0        168.0  \n",
      "...          ...          ...  \n",
      "8156       167.0        168.0  \n",
      "8157       167.0        168.0  \n",
      "8158       167.0        168.0  \n",
      "8159       167.0        168.0  \n",
      "8160       167.0        168.0  \n",
      "\n",
      "[167 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "8161 -0.000088 -0.032745 -0.049549  0.014617       1     1.0       70   \n",
      "8162 -0.000743  0.163051 -0.049256 -0.293278       0     1.0       70   \n",
      "8163  0.002518 -0.031335 -0.055122 -0.016528       1     1.0       70   \n",
      "8164  0.001891  0.164532 -0.055452 -0.326080       0     1.0       70   \n",
      "8165  0.005182 -0.029758 -0.061974 -0.051387       0     1.0       70   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "8245 -0.649720 -1.547815  0.094764  1.348063       1     1.0       70   \n",
      "8246 -0.680676 -1.354003  0.121725  1.086469       0     1.0       70   \n",
      "8247 -0.707756 -1.550502  0.143455  1.414735       0     1.0       70   \n",
      "8248 -0.738766 -1.747080  0.171750  1.748604       0     1.0       70   \n",
      "8249 -0.773708 -1.943687  0.206722  2.089422       0     1.0       70   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "8161        89.0         90.0  \n",
      "8162        89.0         90.0  \n",
      "8163        89.0         90.0  \n",
      "8164        89.0         90.0  \n",
      "8165        89.0         90.0  \n",
      "...          ...          ...  \n",
      "8245        89.0         90.0  \n",
      "8246        89.0         90.0  \n",
      "8247        89.0         90.0  \n",
      "8248        89.0         90.0  \n",
      "8249        89.0         90.0  \n",
      "\n",
      "[89 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "8250  0.007190  0.024321  0.017688 -0.017705       1     1.0       71   \n",
      "8251  0.007677  0.219185  0.017334 -0.304755       0     1.0       71   \n",
      "8252  0.012060  0.023820  0.011239 -0.006656       1     1.0       71   \n",
      "8253  0.012537  0.218779  0.011106 -0.295772       0     1.0       71   \n",
      "8254  0.016912  0.023501  0.005190  0.000392       1     1.0       71   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "8355  0.663157  1.359724 -0.045155 -1.395683       1     1.0       71   \n",
      "8356  0.690351  1.555377 -0.073069 -1.702135       1     1.0       71   \n",
      "8357  0.721459  1.751261 -0.107112 -2.016639       1     1.0       71   \n",
      "8358  0.756484  1.947319 -0.147444 -2.340472       1     1.0       71   \n",
      "8359  0.795430  2.143430 -0.194254 -2.674639       1     1.0       71   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "8250       110.0        111.0  \n",
      "8251       110.0        111.0  \n",
      "8252       110.0        111.0  \n",
      "8253       110.0        111.0  \n",
      "8254       110.0        111.0  \n",
      "...          ...          ...  \n",
      "8355       110.0        111.0  \n",
      "8356       110.0        111.0  \n",
      "8357       110.0        111.0  \n",
      "8358       110.0        111.0  \n",
      "8359       110.0        111.0  \n",
      "\n",
      "[110 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "8360 -0.046217  0.011287 -0.042691 -0.005484       1     1.0       72   \n",
      "8361 -0.045992  0.206995 -0.042800 -0.311325       0     1.0       72   \n",
      "8362 -0.041852  0.012508 -0.049027 -0.032441       0     1.0       72   \n",
      "8363 -0.041602 -0.181878 -0.049676  0.244379       1     1.0       72   \n",
      "8364 -0.045239  0.013917 -0.044788 -0.063550       1     1.0       72   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "8442 -0.561473 -1.510749  0.089605  1.481336       1     1.0       72   \n",
      "8443 -0.591688 -1.316827  0.119231  1.217929       1     1.0       72   \n",
      "8444 -0.618024 -1.123427  0.143590  0.964859       0     1.0       72   \n",
      "8445 -0.640493 -1.320155  0.162887  1.298986       0     1.0       72   \n",
      "8446 -0.666896 -1.516927  0.188867  1.637913       0     1.0       72   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "8360        87.0         88.0  \n",
      "8361        87.0         88.0  \n",
      "8362        87.0         88.0  \n",
      "8363        87.0         88.0  \n",
      "8364        87.0         88.0  \n",
      "...          ...          ...  \n",
      "8442        87.0         88.0  \n",
      "8443        87.0         88.0  \n",
      "8444        87.0         88.0  \n",
      "8445        87.0         88.0  \n",
      "8446        87.0         88.0  \n",
      "\n",
      "[87 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "8447  0.003367  0.037962 -0.011189 -0.027837       0     1.0       73   \n",
      "8448  0.004126 -0.156998 -0.011746  0.261294       0     1.0       73   \n",
      "8449  0.000986 -0.351950 -0.006520  0.550249       1     1.0       73   \n",
      "8450 -0.006053 -0.156737  0.004485  0.255519       1     1.0       73   \n",
      "8451 -0.009188  0.038320  0.009595 -0.035746       0     1.0       73   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "8601 -0.611625 -1.466674  0.082797  1.073731       0     1.0       73   \n",
      "8602 -0.640958 -1.662787  0.104272  1.391207       1     1.0       73   \n",
      "8603 -0.674214 -1.469106  0.132096  1.132865       0     1.0       73   \n",
      "8604 -0.703596 -1.665686  0.154753  1.463889       0     1.0       73   \n",
      "8605 -0.736910 -1.862328  0.184031  1.800644       0     1.0       73   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "8447       159.0        160.0  \n",
      "8448       159.0        160.0  \n",
      "8449       159.0        160.0  \n",
      "8450       159.0        160.0  \n",
      "8451       159.0        160.0  \n",
      "...          ...          ...  \n",
      "8601       159.0        160.0  \n",
      "8602       159.0        160.0  \n",
      "8603       159.0        160.0  \n",
      "8604       159.0        160.0  \n",
      "8605       159.0        160.0  \n",
      "\n",
      "[159 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "8606 -0.018119 -0.030917 -0.030613  0.033797       1     1.0       74   \n",
      "8607 -0.018737  0.164631 -0.029937 -0.268385       0     1.0       74   \n",
      "8608 -0.015444 -0.030051 -0.035305  0.014707       1     1.0       74   \n",
      "8609 -0.016045  0.165559 -0.035010 -0.288903       0     1.0       74   \n",
      "8610 -0.012734 -0.029047 -0.040788 -0.007464       0     1.0       74   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "8690 -0.647749 -1.543627  0.093393  1.314969       1     1.0       74   \n",
      "8691 -0.678621 -1.349802  0.119692  1.052918       0     1.0       74   \n",
      "8692 -0.705617 -1.546290  0.140750  1.380646       0     1.0       74   \n",
      "8693 -0.736543 -1.742860  0.168363  1.713830       0     1.0       74   \n",
      "8694 -0.771400 -1.939467  0.202640  2.053836       0     1.0       74   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "8606        89.0         90.0  \n",
      "8607        89.0         90.0  \n",
      "8608        89.0         90.0  \n",
      "8609        89.0         90.0  \n",
      "8610        89.0         90.0  \n",
      "...          ...          ...  \n",
      "8690        89.0         90.0  \n",
      "8691        89.0         90.0  \n",
      "8692        89.0         90.0  \n",
      "8693        89.0         90.0  \n",
      "8694        89.0         90.0  \n",
      "\n",
      "[89 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "8695 -0.034139 -0.000211  0.049849 -0.000601       0     1.0       75   \n",
      "8696 -0.034143 -0.196011  0.049837  0.307384       1     1.0       75   \n",
      "8697 -0.038063 -0.001633  0.055985  0.030826       0     1.0       75   \n",
      "8698 -0.038096 -0.197512  0.056601  0.340634       1     1.0       75   \n",
      "8699 -0.042046 -0.003239  0.063414  0.066323       1     1.0       75   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "8754  0.695155  2.062646 -0.078992 -1.382124       1     1.0       75   \n",
      "8755  0.736408  2.258659 -0.106634 -1.698427       0     1.0       75   \n",
      "8756  0.781582  2.064916 -0.140603 -1.440754       1     1.0       75   \n",
      "8757  0.822880  2.261462 -0.169418 -1.773865       1     1.0       75   \n",
      "8758  0.868109  2.458041 -0.204895 -2.114083       1     1.0       75   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "8695        64.0         65.0  \n",
      "8696        64.0         65.0  \n",
      "8697        64.0         65.0  \n",
      "8698        64.0         65.0  \n",
      "8699        64.0         65.0  \n",
      "...          ...          ...  \n",
      "8754        64.0         65.0  \n",
      "8755        64.0         65.0  \n",
      "8756        64.0         65.0  \n",
      "8757        64.0         65.0  \n",
      "8758        64.0         65.0  \n",
      "\n",
      "[64 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "8759  0.037093  0.049294  0.023290  0.023809       0     1.0       76   \n",
      "8760  0.038078 -0.146154  0.023767  0.323748       1     1.0       76   \n",
      "8761  0.035155  0.048622  0.030242  0.038654       1     1.0       76   \n",
      "8762  0.036128  0.243297  0.031015 -0.244336       1     1.0       76   \n",
      "8763  0.040994  0.437963  0.026128 -0.527077       0     1.0       76   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "8854  0.614969  0.993809 -0.102856 -0.757171       1     1.0       76   \n",
      "8855  0.634845  1.190187 -0.118000 -1.080367       1     1.0       76   \n",
      "8856  0.658649  1.386652 -0.139607 -1.407627       1     1.0       76   \n",
      "8857  0.686382  1.583203 -0.167760 -1.740496       1     1.0       76   \n",
      "8858  0.718046  1.779791 -0.202570 -2.080329       1     1.0       76   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "8759       100.0        101.0  \n",
      "8760       100.0        101.0  \n",
      "8761       100.0        101.0  \n",
      "8762       100.0        101.0  \n",
      "8763       100.0        101.0  \n",
      "...          ...          ...  \n",
      "8854       100.0        101.0  \n",
      "8855       100.0        101.0  \n",
      "8856       100.0        101.0  \n",
      "8857       100.0        101.0  \n",
      "8858       100.0        101.0  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "8859  0.005589  0.028147 -0.030174  0.000101       0     1.0       77   \n",
      "8860  0.006152 -0.166530 -0.030172  0.283113       1     1.0       77   \n",
      "8861  0.002822  0.029009 -0.024509 -0.018931       1     1.0       77   \n",
      "8862  0.003402  0.224474 -0.024888 -0.319245       0     1.0       77   \n",
      "8863  0.007891  0.029715 -0.031273 -0.034514       1     1.0       77   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "8944 -0.693955 -1.289452  0.090229  0.987791       0     1.0       77   \n",
      "8945 -0.719744 -1.485658  0.109985  1.307395       1     1.0       77   \n",
      "8946 -0.749457 -1.292089  0.136132  1.051065       0     1.0       77   \n",
      "8947 -0.775299 -1.488728  0.157154  1.383194       0     1.0       77   \n",
      "8948 -0.805073 -1.685422  0.184818  1.720613       0     1.0       77   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "8859        90.0         91.0  \n",
      "8860        90.0         91.0  \n",
      "8861        90.0         91.0  \n",
      "8862        90.0         91.0  \n",
      "8863        90.0         91.0  \n",
      "...          ...          ...  \n",
      "8944        90.0         91.0  \n",
      "8945        90.0         91.0  \n",
      "8946        90.0         91.0  \n",
      "8947        90.0         91.0  \n",
      "8948        90.0         91.0  \n",
      "\n",
      "[90 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "8949 -0.000328  0.004447 -0.036594  0.007784       0     1.0       78   \n",
      "8950 -0.000239 -0.190132 -0.036438  0.288700       0     1.0       78   \n",
      "8951 -0.004042 -0.384715 -0.030664  0.569672       1     1.0       78   \n",
      "8952 -0.011736 -0.189177 -0.019271  0.267489       0     1.0       78   \n",
      "8953 -0.015520 -0.384019 -0.013921  0.554032       0     1.0       78   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "9141  0.572724  1.134374 -0.076142 -0.850227       1     1.0       78   \n",
      "9142  0.595411  1.330447 -0.093147 -1.165848       1     1.0       78   \n",
      "9143  0.622020  1.526649 -0.116464 -1.486222       1     1.0       78   \n",
      "9144  0.652553  1.722982 -0.146188 -1.812889       1     1.0       78   \n",
      "9145  0.687013  1.919399 -0.182446 -2.147198       1     1.0       78   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "8949       197.0        198.0  \n",
      "8950       197.0        198.0  \n",
      "8951       197.0        198.0  \n",
      "8952       197.0        198.0  \n",
      "8953       197.0        198.0  \n",
      "...          ...          ...  \n",
      "9141       197.0        198.0  \n",
      "9142       197.0        198.0  \n",
      "9143       197.0        198.0  \n",
      "9144       197.0        198.0  \n",
      "9145       197.0        198.0  \n",
      "\n",
      "[197 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "9146 -0.009510  0.002796  0.022698  0.005256       0     1.0       79   \n",
      "9147 -0.009455 -0.192644  0.022803  0.305013       1     1.0       79   \n",
      "9148 -0.013307  0.002145  0.028903  0.019608       1     1.0       79   \n",
      "9149 -0.013265  0.196841  0.029295 -0.263817       1     1.0       79   \n",
      "9150 -0.009328  0.391533  0.024019 -0.547118       0     1.0       79   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "9242 -0.704287 -1.492643  0.073543  0.903162       0     1.0       79   \n",
      "9243 -0.734140 -1.688680  0.091606  1.218025       0     1.0       79   \n",
      "9244 -0.767914 -1.884856  0.115967  1.537949       0     1.0       79   \n",
      "9245 -0.805611 -2.081167  0.146726  1.864456       1     1.0       79   \n",
      "9246 -0.847234 -1.887925  0.184015  1.620691       0     1.0       79   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "9146       101.0        102.0  \n",
      "9147       101.0        102.0  \n",
      "9148       101.0        102.0  \n",
      "9149       101.0        102.0  \n",
      "9150       101.0        102.0  \n",
      "...          ...          ...  \n",
      "9242       101.0        102.0  \n",
      "9243       101.0        102.0  \n",
      "9244       101.0        102.0  \n",
      "9245       101.0        102.0  \n",
      "9246       101.0        102.0  \n",
      "\n",
      "[101 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "9247 -0.034852 -0.044878  0.026779 -0.010287       0     1.0       80   \n",
      "9248 -0.035749 -0.240373  0.026573  0.290723       1     1.0       80   \n",
      "9249 -0.040557 -0.045640  0.032388  0.006538       0     1.0       80   \n",
      "9250 -0.041469 -0.241211  0.032519  0.309261       1     1.0       80   \n",
      "9251 -0.046294 -0.046567  0.038704  0.027008       1     1.0       80   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "9416 -0.882135 -2.111866  0.093095  1.463632       1     1.0       80   \n",
      "9417 -0.924373 -1.918000  0.122368  1.201423       1     1.0       80   \n",
      "9418 -0.962733 -1.724654  0.146396  0.949459       0     1.0       80   \n",
      "9419 -0.997226 -1.921411  0.165385  1.284324       0     1.0       80   \n",
      "9420 -1.035654 -2.118207  0.191072  1.623892       1     1.0       80   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "9247       174.0        175.0  \n",
      "9248       174.0        175.0  \n",
      "9249       174.0        175.0  \n",
      "9250       174.0        175.0  \n",
      "9251       174.0        175.0  \n",
      "...          ...          ...  \n",
      "9416       174.0        175.0  \n",
      "9417       174.0        175.0  \n",
      "9418       174.0        175.0  \n",
      "9419       174.0        175.0  \n",
      "9420       174.0        175.0  \n",
      "\n",
      "[174 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "9421  0.033607  0.019696 -0.044759 -0.029426       0     1.0       81   \n",
      "9422  0.034001 -0.174757 -0.045347  0.248806       1     1.0       81   \n",
      "9423  0.030506  0.020982 -0.040371 -0.057829       0     1.0       81   \n",
      "9424  0.030925 -0.173538 -0.041528  0.221848       1     1.0       81   \n",
      "9425  0.027454  0.022152 -0.037091 -0.083640       0     1.0       81   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "9488 -0.635629 -1.676620  0.097701  1.290966       1     1.0       81   \n",
      "9489 -0.669161 -1.482867  0.123520  1.030400       0     1.0       81   \n",
      "9490 -0.698818 -1.679396  0.144128  1.359171       0     1.0       81   \n",
      "9491 -0.732406 -1.876001  0.171312  1.693248       0     1.0       81   \n",
      "9492 -0.769926 -2.072637  0.205177  2.034004       1     1.0       81   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "9421        72.0         73.0  \n",
      "9422        72.0         73.0  \n",
      "9423        72.0         73.0  \n",
      "9424        72.0         73.0  \n",
      "9425        72.0         73.0  \n",
      "...          ...          ...  \n",
      "9488        72.0         73.0  \n",
      "9489        72.0         73.0  \n",
      "9490        72.0         73.0  \n",
      "9491        72.0         73.0  \n",
      "9492        72.0         73.0  \n",
      "\n",
      "[72 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "9493 -0.035378 -0.038824 -0.041253 -0.015437       0     1.0       82   \n",
      "9494 -0.036155 -0.233330 -0.041562  0.263950       1     1.0       82   \n",
      "9495 -0.040821 -0.037641 -0.036283 -0.041547       0     1.0       82   \n",
      "9496 -0.041574 -0.232224 -0.037114  0.239471       1     1.0       82   \n",
      "9497 -0.046218 -0.036592 -0.032325 -0.064684       0     1.0       82   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "9579 -0.504752 -1.181505  0.068271  1.123888       0     1.0       82   \n",
      "9580 -0.528382 -1.377453  0.090748  1.437180       0     1.0       82   \n",
      "9581 -0.555931 -1.573568  0.119492  1.756787       1     1.0       82   \n",
      "9582 -0.587402 -1.379986  0.154628  1.503531       1     1.0       82   \n",
      "9583 -0.615002 -1.187042  0.184698  1.262848       0     1.0       82   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "9493        91.0         92.0  \n",
      "9494        91.0         92.0  \n",
      "9495        91.0         92.0  \n",
      "9496        91.0         92.0  \n",
      "9497        91.0         92.0  \n",
      "...          ...          ...  \n",
      "9579        91.0         92.0  \n",
      "9580        91.0         92.0  \n",
      "9581        91.0         92.0  \n",
      "9582        91.0         92.0  \n",
      "9583        91.0         92.0  \n",
      "\n",
      "[91 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "9584  0.015738  0.041512  0.049109 -0.029150       1     1.0       83   \n",
      "9585  0.016568  0.235896  0.048526 -0.305943       0     1.0       83   \n",
      "9586  0.021286  0.040118  0.042407  0.001640       1     1.0       83   \n",
      "9587  0.022089  0.234607  0.042440 -0.277367       1     1.0       83   \n",
      "9588  0.026781  0.429098  0.036893 -0.556368       0     1.0       83   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "9779  0.227668  0.214932  0.035204  0.156993       0     1.0       83   \n",
      "9780  0.231966  0.019324  0.038344  0.460571       1     1.0       83   \n",
      "9781  0.232353  0.213883  0.047555  0.180216       1     1.0       83   \n",
      "9782  0.236630  0.408294  0.051160 -0.097094       1     1.0       83   \n",
      "9783  0.244796  0.602647  0.049218 -0.373207       0     1.0       83   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "9584       200.0        201.0  \n",
      "9585       200.0        201.0  \n",
      "9586       200.0        201.0  \n",
      "9587       200.0        201.0  \n",
      "9588       200.0        201.0  \n",
      "...          ...          ...  \n",
      "9779       200.0        201.0  \n",
      "9780       200.0        201.0  \n",
      "9781       200.0        201.0  \n",
      "9782       200.0        201.0  \n",
      "9783       200.0        201.0  \n",
      "\n",
      "[200 rows x 9 columns]\n",
      "          obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "9784  0.021259 -0.019674  0.038360  0.028641       1     1.0       84   \n",
      "9785  0.020866  0.174878  0.038933 -0.251696       1     1.0       84   \n",
      "9786  0.024363  0.369423  0.033899 -0.531849       1     1.0       84   \n",
      "9787  0.031752  0.564052  0.023262 -0.813661       0     1.0       84   \n",
      "9788  0.043033  0.368619  0.006989 -0.513753       0     1.0       84   \n",
      "...        ...       ...       ...       ...     ...     ...      ...   \n",
      "9937 -0.132439 -0.988994  0.102485  1.358752       1     1.0       84   \n",
      "9938 -0.152219 -0.795296  0.129660  1.099807       1     1.0       84   \n",
      "9939 -0.168125 -0.602096  0.151656  0.850453       0     1.0       84   \n",
      "9940 -0.180166 -0.798925  0.168665  1.186723       0     1.0       84   \n",
      "9941 -0.196145 -0.995783  0.192400  1.527174       1     1.0       84   \n",
      "\n",
      "      tot_reward  comb_reward  \n",
      "9784       158.0        159.0  \n",
      "9785       158.0        159.0  \n",
      "9786       158.0        159.0  \n",
      "9787       158.0        159.0  \n",
      "9788       158.0        159.0  \n",
      "...          ...          ...  \n",
      "9937       158.0        159.0  \n",
      "9938       158.0        159.0  \n",
      "9939       158.0        159.0  \n",
      "9940       158.0        159.0  \n",
      "9941       158.0        159.0  \n",
      "\n",
      "[158 rows x 9 columns]\n",
      "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "9942   0.042371  0.013662 -0.040961 -0.031184       0     1.0       85   \n",
      "9943   0.042644 -0.180849 -0.041585  0.248299       1     1.0       85   \n",
      "9944   0.039027  0.014842 -0.036619 -0.057205       0     1.0       85   \n",
      "9945   0.039324 -0.179737 -0.037763  0.223703       0     1.0       85   \n",
      "9946   0.035729 -0.374299 -0.033289  0.504239       0     1.0       85   \n",
      "...         ...       ...       ...       ...     ...     ...      ...   \n",
      "10061 -0.722771 -1.675819  0.070918  1.135776       0     1.0       85   \n",
      "10062 -0.756287 -1.871794  0.093633  1.449831       0     1.0       85   \n",
      "10063 -0.793723 -2.067934  0.122630  1.770240       1     1.0       85   \n",
      "10064 -0.835082 -1.874391  0.158035  1.518069       0     1.0       85   \n",
      "10065 -0.872570 -2.071031  0.188396  1.855623       1     1.0       85   \n",
      "\n",
      "       tot_reward  comb_reward  \n",
      "9942        124.0        125.0  \n",
      "9943        124.0        125.0  \n",
      "9944        124.0        125.0  \n",
      "9945        124.0        125.0  \n",
      "9946        124.0        125.0  \n",
      "...           ...          ...  \n",
      "10061       124.0        125.0  \n",
      "10062       124.0        125.0  \n",
      "10063       124.0        125.0  \n",
      "10064       124.0        125.0  \n",
      "10065       124.0        125.0  \n",
      "\n",
      "[124 rows x 9 columns]\n",
      "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "10066 -0.018243 -0.030493  0.014815 -0.000298       1     1.0       86   \n",
      "10067 -0.018853  0.164413  0.014809 -0.288270       0     1.0       86   \n",
      "10068 -0.015565 -0.030917  0.009044  0.009046       1     1.0       86   \n",
      "10069 -0.016183  0.164074  0.009225 -0.280770       0     1.0       86   \n",
      "10070 -0.012902 -0.031178  0.003609  0.014808       0     1.0       86   \n",
      "...         ...       ...       ...       ...     ...     ...      ...   \n",
      "10126  0.180840  1.122098 -0.049610 -1.357155       1     1.0       86   \n",
      "10127  0.203281  1.317806 -0.076753 -1.664935       1     1.0       86   \n",
      "10128  0.229638  1.513732 -0.110052 -1.980503       1     1.0       86   \n",
      "10129  0.259912  1.709826 -0.149662 -2.305155       0     1.0       86   \n",
      "10130  0.294109  1.516361 -0.195765 -2.062037       1     1.0       86   \n",
      "\n",
      "       tot_reward  comb_reward  \n",
      "10066        65.0         66.0  \n",
      "10067        65.0         66.0  \n",
      "10068        65.0         66.0  \n",
      "10069        65.0         66.0  \n",
      "10070        65.0         66.0  \n",
      "...           ...          ...  \n",
      "10126        65.0         66.0  \n",
      "10127        65.0         66.0  \n",
      "10128        65.0         66.0  \n",
      "10129        65.0         66.0  \n",
      "10130        65.0         66.0  \n",
      "\n",
      "[65 rows x 9 columns]\n",
      "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "10131  0.037861 -0.020960  0.032085 -0.009854       1     1.0       87   \n",
      "10132  0.037442  0.173688  0.031888 -0.292243       0     1.0       87   \n",
      "10133  0.040916 -0.021874  0.026043  0.010324       1     1.0       87   \n",
      "10134  0.040478  0.172865  0.026249 -0.274030       0     1.0       87   \n",
      "10135  0.043936 -0.022622  0.020769  0.026815       1     1.0       87   \n",
      "...         ...       ...       ...       ...     ...     ...      ...   \n",
      "10309  0.602069  1.124790 -0.054611 -1.215978       1     1.0       87   \n",
      "10310  0.624565  1.320573 -0.078931 -1.525261       1     1.0       87   \n",
      "10311  0.650976  1.516554 -0.109436 -1.841499       1     1.0       87   \n",
      "10312  0.681307  1.712700 -0.146266 -2.166069       1     1.0       87   \n",
      "10313  0.715561  1.908918 -0.189587 -2.500102       1     1.0       87   \n",
      "\n",
      "       tot_reward  comb_reward  \n",
      "10131       183.0        184.0  \n",
      "10132       183.0        184.0  \n",
      "10133       183.0        184.0  \n",
      "10134       183.0        184.0  \n",
      "10135       183.0        184.0  \n",
      "...           ...          ...  \n",
      "10309       183.0        184.0  \n",
      "10310       183.0        184.0  \n",
      "10311       183.0        184.0  \n",
      "10312       183.0        184.0  \n",
      "10313       183.0        184.0  \n",
      "\n",
      "[183 rows x 9 columns]\n",
      "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "10314 -0.015132  0.042924 -0.029484  0.025458       0     1.0       88   \n",
      "10315 -0.014273 -0.151763 -0.028975  0.308694       1     1.0       88   \n",
      "10316 -0.017309  0.043759 -0.022801  0.007016       1     1.0       88   \n",
      "10317 -0.016433  0.239201 -0.022661 -0.292773       0     1.0       88   \n",
      "10318 -0.011649  0.044409 -0.028516 -0.007322       1     1.0       88   \n",
      "...         ...       ...       ...       ...     ...     ...      ...   \n",
      "10405 -0.649095 -1.656793  0.080352  1.419282       1     1.0       88   \n",
      "10406 -0.682231 -1.462752  0.108738  1.152758       0     1.0       88   \n",
      "10407 -0.711486 -1.659111  0.131793  1.477463       0     1.0       88   \n",
      "10408 -0.744668 -1.855573  0.161342  1.808236       0     1.0       88   \n",
      "10409 -0.781780 -2.052086  0.197507  2.146405       1     1.0       88   \n",
      "\n",
      "       tot_reward  comb_reward  \n",
      "10314        96.0         97.0  \n",
      "10315        96.0         97.0  \n",
      "10316        96.0         97.0  \n",
      "10317        96.0         97.0  \n",
      "10318        96.0         97.0  \n",
      "...           ...          ...  \n",
      "10405        96.0         97.0  \n",
      "10406        96.0         97.0  \n",
      "10407        96.0         97.0  \n",
      "10408        96.0         97.0  \n",
      "10409        96.0         97.0  \n",
      "\n",
      "[96 rows x 9 columns]\n",
      "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "10410 -0.004439  0.013898 -0.002520  0.009338       0     1.0       89   \n",
      "10411 -0.004161 -0.181187 -0.002333  0.301224       1     1.0       89   \n",
      "10412 -0.007784  0.013968  0.003691  0.007807       1     1.0       89   \n",
      "10413 -0.007505  0.209037  0.003847 -0.283709       0     1.0       89   \n",
      "10414 -0.003324  0.013860 -0.001827  0.010185       0     1.0       89   \n",
      "...         ...       ...       ...       ...     ...     ...      ...   \n",
      "10507 -0.772862 -2.057440  0.071318  1.577124       1     1.0       89   \n",
      "10508 -0.814010 -1.863237  0.102860  1.307509       0     1.0       89   \n",
      "10509 -0.851275 -2.059501  0.129010  1.630536       1     1.0       89   \n",
      "10510 -0.892465 -1.866109  0.161621  1.380683       0     1.0       89   \n",
      "10511 -0.929787 -2.062837  0.189235  1.719239       1     1.0       89   \n",
      "\n",
      "       tot_reward  comb_reward  \n",
      "10410       102.0        103.0  \n",
      "10411       102.0        103.0  \n",
      "10412       102.0        103.0  \n",
      "10413       102.0        103.0  \n",
      "10414       102.0        103.0  \n",
      "...           ...          ...  \n",
      "10507       102.0        103.0  \n",
      "10508       102.0        103.0  \n",
      "10509       102.0        103.0  \n",
      "10510       102.0        103.0  \n",
      "10511       102.0        103.0  \n",
      "\n",
      "[102 rows x 9 columns]\n",
      "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "10512  0.045610 -0.021136 -0.020926 -0.002822       0     1.0       90   \n",
      "10513  0.045187 -0.215952 -0.020983  0.283186       0     1.0       90   \n",
      "10514  0.040868 -0.410768 -0.015319  0.569178       0     1.0       90   \n",
      "10515  0.032653 -0.605672 -0.003935  0.856996       0     1.0       90   \n",
      "10516  0.020539 -0.800740  0.013205  1.148439       0     1.0       90   \n",
      "...         ...       ...       ...       ...     ...     ...      ...   \n",
      "10574  0.608727  1.103754 -0.107937 -0.751752       1     1.0       90   \n",
      "10575  0.630802  1.300186 -0.122972 -1.076357       1     1.0       90   \n",
      "10576  0.656806  1.496699 -0.144499 -1.404963       1     1.0       90   \n",
      "10577  0.686740  1.693289 -0.172598 -1.739110       1     1.0       90   \n",
      "10578  0.720606  1.889906 -0.207381 -2.080146       1     1.0       90   \n",
      "\n",
      "       tot_reward  comb_reward  \n",
      "10512        67.0         68.0  \n",
      "10513        67.0         68.0  \n",
      "10514        67.0         68.0  \n",
      "10515        67.0         68.0  \n",
      "10516        67.0         68.0  \n",
      "...           ...          ...  \n",
      "10574        67.0         68.0  \n",
      "10575        67.0         68.0  \n",
      "10576        67.0         68.0  \n",
      "10577        67.0         68.0  \n",
      "10578        67.0         68.0  \n",
      "\n",
      "[67 rows x 9 columns]\n",
      "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "10579 -0.043863 -0.008891 -0.022491 -0.002988       0     1.0       91   \n",
      "10580 -0.044041 -0.203683 -0.022551  0.282515       0     1.0       91   \n",
      "10581 -0.048115 -0.398476 -0.016901  0.568001       0     1.0       91   \n",
      "10582 -0.056084 -0.593357 -0.005541  0.855312       1     1.0       91   \n",
      "10583 -0.067952 -0.398160  0.011566  0.560892       1     1.0       91   \n",
      "...         ...       ...       ...       ...     ...     ...      ...   \n",
      "10689 -0.654577 -1.522247  0.094588  1.292567       1     1.0       91   \n",
      "10690 -0.685022 -1.328446  0.120439  1.030933       0     1.0       91   \n",
      "10691 -0.711591 -1.524946  0.141058  1.358872       0     1.0       91   \n",
      "10692 -0.742090 -1.721527  0.168235  1.692147       0     1.0       91   \n",
      "10693 -0.776520 -1.918145  0.202078  2.032139       0     1.0       91   \n",
      "\n",
      "       tot_reward  comb_reward  \n",
      "10579       115.0        116.0  \n",
      "10580       115.0        116.0  \n",
      "10581       115.0        116.0  \n",
      "10582       115.0        116.0  \n",
      "10583       115.0        116.0  \n",
      "...           ...          ...  \n",
      "10689       115.0        116.0  \n",
      "10690       115.0        116.0  \n",
      "10691       115.0        116.0  \n",
      "10692       115.0        116.0  \n",
      "10693       115.0        116.0  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115 rows x 9 columns]\n",
      "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "10694  0.044687  0.003892  0.025017  0.022721       0     1.0       92   \n",
      "10695  0.044765 -0.191579  0.025471  0.323191       1     1.0       92   \n",
      "10696  0.040933  0.003171  0.031935  0.038648       1     1.0       92   \n",
      "10697  0.040997  0.197821  0.032708 -0.243790       1     1.0       92   \n",
      "10698  0.044953  0.392461  0.027832 -0.525979       1     1.0       92   \n",
      "...         ...       ...       ...       ...     ...     ...      ...   \n",
      "10889 -0.080212 -0.922433 -0.085771  0.400685       0     1.0       92   \n",
      "10890 -0.098660 -1.116240 -0.077757  0.665142       0     1.0       92   \n",
      "10891 -0.120985 -1.310199 -0.064454  0.932364       1     1.0       92   \n",
      "10892 -0.147189 -1.114270 -0.045807  0.620143       1     1.0       92   \n",
      "10893 -0.169475 -0.918539 -0.033404  0.313393       0     1.0       92   \n",
      "\n",
      "       tot_reward  comb_reward  \n",
      "10694       200.0        201.0  \n",
      "10695       200.0        201.0  \n",
      "10696       200.0        201.0  \n",
      "10697       200.0        201.0  \n",
      "10698       200.0        201.0  \n",
      "...           ...          ...  \n",
      "10889       200.0        201.0  \n",
      "10890       200.0        201.0  \n",
      "10891       200.0        201.0  \n",
      "10892       200.0        201.0  \n",
      "10893       200.0        201.0  \n",
      "\n",
      "[200 rows x 9 columns]\n",
      "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "10894 -0.023471 -0.026185 -0.049000 -0.018200       0     1.0       93   \n",
      "10895 -0.023995 -0.220571 -0.049364  0.258629       0     1.0       93   \n",
      "10896 -0.028406 -0.414955 -0.044192  0.535343       1     1.0       93   \n",
      "10897 -0.036705 -0.219240 -0.033485  0.229069       1     1.0       93   \n",
      "10898 -0.041090 -0.023656 -0.028903 -0.073985       0     1.0       93   \n",
      "...         ...       ...       ...       ...     ...     ...      ...   \n",
      "11000 -0.481927 -1.198184  0.055802  1.767128       0     1.0       93   \n",
      "11001 -0.505891 -1.393890  0.091144  2.076628       1     1.0       93   \n",
      "11002 -0.533769 -1.199802  0.132677  1.813464       1     1.0       93   \n",
      "11003 -0.557765 -1.006384  0.168946  1.564780       1     1.0       93   \n",
      "11004 -0.577892 -0.813636  0.200242  1.329209       1     1.0       93   \n",
      "\n",
      "       tot_reward  comb_reward  \n",
      "10894       111.0        112.0  \n",
      "10895       111.0        112.0  \n",
      "10896       111.0        112.0  \n",
      "10897       111.0        112.0  \n",
      "10898       111.0        112.0  \n",
      "...           ...          ...  \n",
      "11000       111.0        112.0  \n",
      "11001       111.0        112.0  \n",
      "11002       111.0        112.0  \n",
      "11003       111.0        112.0  \n",
      "11004       111.0        112.0  \n",
      "\n",
      "[111 rows x 9 columns]\n",
      "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "11005 -0.025715 -0.049503  0.011629 -0.011918       1     1.0       94   \n",
      "11006 -0.026705  0.145451  0.011390 -0.300909       1     1.0       94   \n",
      "11007 -0.023796  0.340408  0.005372 -0.589978       0     1.0       94   \n",
      "11008 -0.016988  0.145212 -0.006428 -0.295608       0     1.0       94   \n",
      "11009 -0.014084 -0.049818 -0.012340 -0.004959       0     1.0       94   \n",
      "...         ...       ...       ...       ...     ...     ...      ...   \n",
      "11101 -0.503056 -1.193950  0.077965  1.166990       0     1.0       94   \n",
      "11102 -0.526935 -1.389995  0.101305  1.483063       0     1.0       94   \n",
      "11103 -0.554735 -1.586196  0.130966  1.805588       1     1.0       94   \n",
      "11104 -0.586459 -1.392757  0.167078  1.556308       1     1.0       94   \n",
      "11105 -0.614314 -1.199984  0.198204  1.320068       0     1.0       94   \n",
      "\n",
      "       tot_reward  comb_reward  \n",
      "11005       101.0        102.0  \n",
      "11006       101.0        102.0  \n",
      "11007       101.0        102.0  \n",
      "11008       101.0        102.0  \n",
      "11009       101.0        102.0  \n",
      "...           ...          ...  \n",
      "11101       101.0        102.0  \n",
      "11102       101.0        102.0  \n",
      "11103       101.0        102.0  \n",
      "11104       101.0        102.0  \n",
      "11105       101.0        102.0  \n",
      "\n",
      "[101 rows x 9 columns]\n",
      "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "11106  0.035855  0.018441 -0.018490 -0.037647       0     1.0       95   \n",
      "11107  0.036224 -0.176411 -0.019243  0.249146       0     1.0       95   \n",
      "11108  0.032696 -0.371253 -0.014260  0.535697       0     1.0       95   \n",
      "11109  0.025271 -0.566171 -0.003546  0.823853       1     1.0       95   \n",
      "11110  0.013948 -0.371001  0.012931  0.530057       1     1.0       95   \n",
      "...         ...       ...       ...       ...     ...     ...      ...   \n",
      "11186 -0.625886 -1.485720  0.086786  1.053896       1     1.0       95   \n",
      "11187 -0.655601 -1.291849  0.107864  0.789667       0     1.0       95   \n",
      "11188 -0.681438 -1.488274  0.123657  1.114242       0     1.0       95   \n",
      "11189 -0.711203 -1.684783  0.145942  1.443018       0     1.0       95   \n",
      "11190 -0.744899 -1.881369  0.174802  1.777516       0     1.0       95   \n",
      "\n",
      "       tot_reward  comb_reward  \n",
      "11106        85.0         86.0  \n",
      "11107        85.0         86.0  \n",
      "11108        85.0         86.0  \n",
      "11109        85.0         86.0  \n",
      "11110        85.0         86.0  \n",
      "...           ...          ...  \n",
      "11186        85.0         86.0  \n",
      "11187        85.0         86.0  \n",
      "11188        85.0         86.0  \n",
      "11189        85.0         86.0  \n",
      "11190        85.0         86.0  \n",
      "\n",
      "[85 rows x 9 columns]\n",
      "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "11191 -0.025397  0.028082  0.020742 -0.049473       0     1.0       96   \n",
      "11192 -0.024835 -0.167331  0.019753  0.249681       1     1.0       96   \n",
      "11193 -0.028182  0.027503  0.024746 -0.036707       1     1.0       96   \n",
      "11194 -0.027632  0.222262  0.024012 -0.321480       1     1.0       96   \n",
      "11195 -0.023187  0.417034  0.017583 -0.606495       0     1.0       96   \n",
      "...         ...       ...       ...       ...     ...     ...      ...   \n",
      "11269 -0.669192 -1.471420  0.108944  0.940909       0     1.0       96   \n",
      "11270 -0.698620 -1.667828  0.127763  1.265741       1     1.0       96   \n",
      "11271 -0.731977 -1.474549  0.153077  1.015645       0     1.0       96   \n",
      "11272 -0.761468 -1.671344  0.173390  1.352215       0     1.0       96   \n",
      "11273 -0.794894 -1.868166  0.200435  1.693744       0     1.0       96   \n",
      "\n",
      "       tot_reward  comb_reward  \n",
      "11191        83.0         84.0  \n",
      "11192        83.0         84.0  \n",
      "11193        83.0         84.0  \n",
      "11194        83.0         84.0  \n",
      "11195        83.0         84.0  \n",
      "...           ...          ...  \n",
      "11269        83.0         84.0  \n",
      "11270        83.0         84.0  \n",
      "11271        83.0         84.0  \n",
      "11272        83.0         84.0  \n",
      "11273        83.0         84.0  \n",
      "\n",
      "[83 rows x 9 columns]\n",
      "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "11274  0.028685 -0.035036 -0.011948  0.045039       0     1.0       97   \n",
      "11275  0.027984 -0.229984 -0.011047  0.333928       1     1.0       97   \n",
      "11276  0.023385 -0.034707 -0.004369  0.037782       0     1.0       97   \n",
      "11277  0.022691 -0.229766 -0.003613  0.329083       1     1.0       97   \n",
      "11278  0.018095 -0.034593  0.002968  0.035263       0     1.0       97   \n",
      "...         ...       ...       ...       ...     ...     ...      ...   \n",
      "11398  0.603254  1.102800 -0.050011 -0.986225       1     1.0       97   \n",
      "11399  0.625310  1.298554 -0.069736 -1.294187       1     1.0       97   \n",
      "11400  0.651281  1.494490 -0.095620 -1.607861       1     1.0       97   \n",
      "11401  0.681171  1.690603 -0.127777 -1.928757       1     1.0       97   \n",
      "11402  0.714983  1.886842 -0.166352 -2.258180       1     1.0       97   \n",
      "\n",
      "       tot_reward  comb_reward  \n",
      "11274       129.0        130.0  \n",
      "11275       129.0        130.0  \n",
      "11276       129.0        130.0  \n",
      "11277       129.0        130.0  \n",
      "11278       129.0        130.0  \n",
      "...           ...          ...  \n",
      "11398       129.0        130.0  \n",
      "11399       129.0        130.0  \n",
      "11400       129.0        130.0  \n",
      "11401       129.0        130.0  \n",
      "11402       129.0        130.0  \n",
      "\n",
      "[129 rows x 9 columns]\n",
      "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "11403 -0.010854 -0.003894  0.010121  0.018439       0     1.0       98   \n",
      "11404 -0.010932 -0.199159  0.010490  0.314298       0     1.0       98   \n",
      "11405 -0.014915 -0.394429  0.016776  0.610271       1     1.0       98   \n",
      "11406 -0.022803 -0.199545  0.028982  0.322919       1     1.0       98   \n",
      "11407 -0.026794 -0.004848  0.035440  0.039515       0     1.0       98   \n",
      "...         ...       ...       ...       ...     ...     ...      ...   \n",
      "11538 -0.608311 -1.321941  0.090479  1.016031       0     1.0       98   \n",
      "11539 -0.634750 -1.518145  0.110800  1.335698       1     1.0       98   \n",
      "11540 -0.665113 -1.324580  0.137514  1.079639       0     1.0       98   \n",
      "11541 -0.691605 -1.521223  0.159107  1.412121       0     1.0       98   \n",
      "11542 -0.722029 -1.717919  0.187349  1.750019       0     1.0       98   \n",
      "\n",
      "       tot_reward  comb_reward  \n",
      "11403       140.0        141.0  \n",
      "11404       140.0        141.0  \n",
      "11405       140.0        141.0  \n",
      "11406       140.0        141.0  \n",
      "11407       140.0        141.0  \n",
      "...           ...          ...  \n",
      "11538       140.0        141.0  \n",
      "11539       140.0        141.0  \n",
      "11540       140.0        141.0  \n",
      "11541       140.0        141.0  \n",
      "11542       140.0        141.0  \n",
      "\n",
      "[140 rows x 9 columns]\n",
      "           obs0      obs1      obs2      obs3  action  reward  episode  \\\n",
      "11543 -0.001872 -0.031831 -0.014651 -0.029975       1     1.0       99   \n",
      "11544 -0.002509  0.163498 -0.015250 -0.327244       0     1.0       99   \n",
      "11545  0.000761 -0.031403 -0.021795 -0.039409       1     1.0       99   \n",
      "11546  0.000133  0.164024 -0.022583 -0.338888       0     1.0       99   \n",
      "11547  0.003413 -0.030769 -0.029361 -0.053411       1     1.0       99   \n",
      "...         ...       ...       ...       ...     ...     ...      ...   \n",
      "11609 -0.730055 -1.531049  0.079357  0.951753       0     1.0       99   \n",
      "11610 -0.760676 -1.727144  0.098392  1.268276       0     1.0       99   \n",
      "11611 -0.795219 -1.923375  0.123757  1.590080       0     1.0       99   \n",
      "11612 -0.833686 -2.119730  0.155559  1.918652       1     1.0       99   \n",
      "11613 -0.876081 -1.926586  0.193932  1.677984       0     1.0       99   \n",
      "\n",
      "       tot_reward  comb_reward  \n",
      "11543        71.0         72.0  \n",
      "11544        71.0         72.0  \n",
      "11545        71.0         72.0  \n",
      "11546        71.0         72.0  \n",
      "11547        71.0         72.0  \n",
      "...           ...          ...  \n",
      "11609        71.0         72.0  \n",
      "11610        71.0         72.0  \n",
      "11611        71.0         72.0  \n",
      "11612        71.0         72.0  \n",
      "11613        71.0         72.0  \n",
      "\n",
      "[71 rows x 9 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_df2.groupby(\"episode\").apply(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116.14"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_df2.groupby(\"episode\").reward.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    90\n",
       "True     10\n",
       "Name: reward, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(memory_df2.groupby(\"episode\").reward.sum() >= 200).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
