{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91bb8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551da496",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 10000\n",
    "\n",
    "life_memory = []\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    old_observation = env.reset()\n",
    "    done = False\n",
    "    tot_reward = 0\n",
    "    ep_memory = []\n",
    "    while not done:\n",
    "        new_action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(new_action)\n",
    "        tot_reward += reward\n",
    "        \n",
    "        ep_memory.append({\n",
    "            \"obs0\": old_observation[0],\n",
    "            \"obs1\": old_observation[1],\n",
    "            \"obs2\": old_observation[2],\n",
    "            \"obs3\": old_observation[3],\n",
    "            \"action\": new_action,\n",
    "            \"reward\": reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        old_observation = observation\n",
    "        \n",
    "    for ep_mem in ep_memory:\n",
    "        ep_mem[\"tot_reward\"] = tot_reward\n",
    "        \n",
    "    life_memory.extend(ep_memory)\n",
    "    \n",
    "memory_df = pandas.DataFrame(life_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c053fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_df.groupby(\"episode\").reward.sum().mean()\n",
    "memory_df[\"comb_reward\"] = .5*memory_df.reward + 1.2 * memory_df.tot_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "271c0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mat = memory_df[[\"obs0\", \"obs1\", \"obs2\", \"obs3\", \"action\"]].to_numpy()\n",
    "y = memory_df['comb_reward'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266a64f",
   "metadata": {},
   "source": [
    "### Two hiden layers Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "968d53fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "# optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "def build_model2():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation = 'relu', input_shape=(x_mat.shape[1], )))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='relu'))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ff1daf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6944/6944 [==============================] - 6s 869us/step - loss: 280.4310 - mae: 12.4106\n",
      "Epoch 2/100\n",
      "6944/6944 [==============================] - 6s 866us/step - loss: 218.5285 - mae: 10.81840s - loss: 218.7545 - \n",
      "Epoch 3/100\n",
      "6944/6944 [==============================] - 7s 947us/step - loss: 208.3697 - mae: 10.5419\n",
      "Epoch 4/100\n",
      "6944/6944 [==============================] - 6s 916us/step - loss: 203.1162 - mae: 10.4027\n",
      "Epoch 5/100\n",
      "6944/6944 [==============================] - 6s 852us/step - loss: 201.3332 - mae: 10.3487\n",
      "Epoch 6/100\n",
      "6944/6944 [==============================] - 6s 834us/step - loss: 200.3968 - mae: 10.3203\n",
      "Epoch 7/100\n",
      "6944/6944 [==============================] - 6s 857us/step - loss: 199.3587 - mae: 10.2989\n",
      "Epoch 8/100\n",
      "6944/6944 [==============================] - 6s 844us/step - loss: 198.3084 - mae: 10.2708\n",
      "Epoch 9/100\n",
      "6944/6944 [==============================] - 6s 835us/step - loss: 197.6679 - mae: 10.2532\n",
      "Epoch 10/100\n",
      "6944/6944 [==============================] - 6s 827us/step - loss: 197.0221 - mae: 10.2353\n",
      "Epoch 11/100\n",
      "6944/6944 [==============================] - 6s 863us/step - loss: 196.6346 - mae: 10.2250\n",
      "Epoch 12/100\n",
      "6944/6944 [==============================] - 6s 897us/step - loss: 196.2098 - mae: 10.2123\n",
      "Epoch 13/100\n",
      "6944/6944 [==============================] - 6s 907us/step - loss: 196.0204 - mae: 10.2060\n",
      "Epoch 14/100\n",
      "6944/6944 [==============================] - 6s 883us/step - loss: 195.8079 - mae: 10.2043\n",
      "Epoch 15/100\n",
      "6944/6944 [==============================] - 6s 905us/step - loss: 195.5928 - mae: 10.1998\n",
      "Epoch 16/100\n",
      "6944/6944 [==============================] - 6s 900us/step - loss: 195.5330 - mae: 10.1969\n",
      "Epoch 17/100\n",
      "6944/6944 [==============================] - 6s 877us/step - loss: 195.2821 - mae: 10.1929\n",
      "Epoch 18/100\n",
      "6944/6944 [==============================] - 6s 874us/step - loss: 195.0206 - mae: 10.1823\n",
      "Epoch 19/100\n",
      "6944/6944 [==============================] - 7s 976us/step - loss: 194.7852 - mae: 10.1734\n",
      "Epoch 20/100\n",
      "6944/6944 [==============================] - 7s 936us/step - loss: 194.6048 - mae: 10.1664\n",
      "Epoch 21/100\n",
      "6944/6944 [==============================] - 6s 880us/step - loss: 194.5482 - mae: 10.1656\n",
      "Epoch 22/100\n",
      "6944/6944 [==============================] - 6s 832us/step - loss: 194.3198 - mae: 10.1598\n",
      "Epoch 23/100\n",
      "6944/6944 [==============================] - 6s 832us/step - loss: 194.3023 - mae: 10.1545\n",
      "Epoch 24/100\n",
      "6944/6944 [==============================] - 6s 905us/step - loss: 194.2052 - mae: 10.1535\n",
      "Epoch 25/100\n",
      "6944/6944 [==============================] - 6s 852us/step - loss: 194.1979 - mae: 10.1503\n",
      "Epoch 26/100\n",
      "6944/6944 [==============================] - 6s 880us/step - loss: 194.1346 - mae: 10.1546\n",
      "Epoch 27/100\n",
      "6944/6944 [==============================] - 6s 876us/step - loss: 194.2121 - mae: 10.1558\n",
      "Epoch 28/100\n",
      "6944/6944 [==============================] - 6s 844us/step - loss: 194.1832 - mae: 10.1521\n",
      "Epoch 29/100\n",
      "6944/6944 [==============================] - 6s 857us/step - loss: 194.0791 - mae: 10.1442\n",
      "Epoch 30/100\n",
      "6944/6944 [==============================] - 6s 849us/step - loss: 193.9951 - mae: 10.1466\n",
      "Epoch 31/100\n",
      "6944/6944 [==============================] - 6s 836us/step - loss: 193.9380 - mae: 10.1462\n",
      "Epoch 32/100\n",
      "6944/6944 [==============================] - 6s 848us/step - loss: 194.0566 - mae: 10.1458\n",
      "Epoch 33/100\n",
      "6944/6944 [==============================] - 6s 846us/step - loss: 193.9525 - mae: 10.1472\n",
      "Epoch 34/100\n",
      "6944/6944 [==============================] - 6s 882us/step - loss: 193.8842 - mae: 10.1463\n",
      "Epoch 35/100\n",
      "6944/6944 [==============================] - 6s 883us/step - loss: 194.0147 - mae: 10.1481\n",
      "Epoch 36/100\n",
      "6944/6944 [==============================] - 6s 883us/step - loss: 193.9911 - mae: 10.1452\n",
      "Epoch 37/100\n",
      "6944/6944 [==============================] - 6s 852us/step - loss: 194.0034 - mae: 10.1437\n",
      "Epoch 38/100\n",
      "6944/6944 [==============================] - 6s 852us/step - loss: 193.8294 - mae: 10.1431\n",
      "Epoch 39/100\n",
      "6944/6944 [==============================] - 6s 860us/step - loss: 193.8656 - mae: 10.1445\n",
      "Epoch 40/100\n",
      "6944/6944 [==============================] - 6s 893us/step - loss: 193.9095 - mae: 10.1459\n",
      "Epoch 41/100\n",
      "6944/6944 [==============================] - 6s 866us/step - loss: 193.8924 - mae: 10.1397\n",
      "Epoch 42/100\n",
      "6944/6944 [==============================] - 6s 848us/step - loss: 193.8630 - mae: 10.1451\n",
      "Epoch 43/100\n",
      "6944/6944 [==============================] - 6s 850us/step - loss: 193.8574 - mae: 10.1424\n",
      "Epoch 44/100\n",
      "6944/6944 [==============================] - 6s 834us/step - loss: 193.7863 - mae: 10.1424\n",
      "Epoch 45/100\n",
      "6944/6944 [==============================] - 6s 896us/step - loss: 193.8129 - mae: 10.1387\n",
      "Epoch 46/100\n",
      "6944/6944 [==============================] - 6s 911us/step - loss: 193.9616 - mae: 10.1487\n",
      "Epoch 47/100\n",
      "6944/6944 [==============================] - 7s 945us/step - loss: 193.8277 - mae: 10.1445\n",
      "Epoch 48/100\n",
      "6944/6944 [==============================] - 7s 952us/step - loss: 193.7728 - mae: 10.1394\n",
      "Epoch 49/100\n",
      "6944/6944 [==============================] - 6s 839us/step - loss: 193.8338 - mae: 10.1377\n",
      "Epoch 50/100\n",
      "6944/6944 [==============================] - 6s 883us/step - loss: 193.8124 - mae: 10.1361\n",
      "Epoch 51/100\n",
      "6944/6944 [==============================] - 6s 846us/step - loss: 193.8656 - mae: 10.1401\n",
      "Epoch 52/100\n",
      "6944/6944 [==============================] - 6s 840us/step - loss: 193.8634 - mae: 10.1400\n",
      "Epoch 53/100\n",
      "6944/6944 [==============================] - 6s 840us/step - loss: 193.8919 - mae: 10.1403\n",
      "Epoch 54/100\n",
      "6944/6944 [==============================] - 6s 835us/step - loss: 193.8146 - mae: 10.1427\n",
      "Epoch 55/100\n",
      "6944/6944 [==============================] - 6s 834us/step - loss: 193.8194 - mae: 10.1384\n",
      "Epoch 56/100\n",
      "6944/6944 [==============================] - 6s 831us/step - loss: 193.7259 - mae: 10.1351\n",
      "Epoch 57/100\n",
      "6944/6944 [==============================] - 6s 853us/step - loss: 193.8057 - mae: 10.1368\n",
      "Epoch 58/100\n",
      "6944/6944 [==============================] - 6s 858us/step - loss: 193.8293 - mae: 10.1371\n",
      "Epoch 59/100\n",
      "6944/6944 [==============================] - 6s 854us/step - loss: 193.7686 - mae: 10.1388\n",
      "Epoch 60/100\n",
      "6944/6944 [==============================] - 6s 821us/step - loss: 193.8447 - mae: 10.1338\n",
      "Epoch 61/100\n",
      "6944/6944 [==============================] - 6s 838us/step - loss: 193.7628 - mae: 10.1333\n",
      "Epoch 62/100\n",
      "6944/6944 [==============================] - 6s 827us/step - loss: 193.7020 - mae: 10.1300\n",
      "Epoch 63/100\n",
      "6944/6944 [==============================] - 6s 839us/step - loss: 193.7447 - mae: 10.1358\n",
      "Epoch 64/100\n",
      "6944/6944 [==============================] - 6s 846us/step - loss: 193.6519 - mae: 10.1346\n",
      "Epoch 65/100\n",
      "6944/6944 [==============================] - 6s 833us/step - loss: 193.6275 - mae: 10.1337\n",
      "Epoch 66/100\n",
      "6944/6944 [==============================] - 6s 909us/step - loss: 193.6962 - mae: 10.1362\n",
      "Epoch 67/100\n",
      "6944/6944 [==============================] - 6s 884us/step - loss: 193.6945 - mae: 10.1300\n",
      "Epoch 68/100\n",
      "6944/6944 [==============================] - 6s 876us/step - loss: 193.6762 - mae: 10.1329\n",
      "Epoch 69/100\n",
      "6944/6944 [==============================] - 6s 916us/step - loss: 193.6821 - mae: 10.1311\n",
      "Epoch 70/100\n",
      "6944/6944 [==============================] - 6s 891us/step - loss: 193.5882 - mae: 10.1266\n",
      "Epoch 71/100\n",
      "6944/6944 [==============================] - 7s 967us/step - loss: 193.4908 - mae: 10.1277\n",
      "Epoch 72/100\n",
      "6944/6944 [==============================] - 6s 898us/step - loss: 193.5611 - mae: 10.1318\n",
      "Epoch 73/100\n",
      "6944/6944 [==============================] - 7s 963us/step - loss: 193.4386 - mae: 10.1249\n",
      "Epoch 74/100\n",
      "6944/6944 [==============================] - 7s 1ms/step - loss: 193.4030 - mae: 10.1286\n",
      "Epoch 75/100\n",
      "6944/6944 [==============================] - 7s 967us/step - loss: 193.4017 - mae: 10.1233\n",
      "Epoch 76/100\n",
      "6944/6944 [==============================] - 7s 953us/step - loss: 193.3587 - mae: 10.1252\n",
      "Epoch 77/100\n",
      "6944/6944 [==============================] - 7s 965us/step - loss: 193.4715 - mae: 10.1299\n",
      "Epoch 78/100\n",
      "6944/6944 [==============================] - 7s 998us/step - loss: 193.3377 - mae: 10.1256\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6944/6944 [==============================] - 6s 887us/step - loss: 193.3936 - mae: 10.1246\n",
      "Epoch 80/100\n",
      "6944/6944 [==============================] - 6s 845us/step - loss: 193.3840 - mae: 10.1285\n",
      "Epoch 81/100\n",
      "6944/6944 [==============================] - 6s 901us/step - loss: 193.2666 - mae: 10.1236\n",
      "Epoch 82/100\n",
      "6944/6944 [==============================] - 6s 871us/step - loss: 193.2042 - mae: 10.1169\n",
      "Epoch 83/100\n",
      "6944/6944 [==============================] - 6s 857us/step - loss: 193.1539 - mae: 10.1191\n",
      "Epoch 84/100\n",
      "6944/6944 [==============================] - 6s 870us/step - loss: 193.1528 - mae: 10.1210\n",
      "Epoch 85/100\n",
      "6944/6944 [==============================] - 6s 902us/step - loss: 193.1635 - mae: 10.1170\n",
      "Epoch 86/100\n",
      "6944/6944 [==============================] - 6s 838us/step - loss: 193.1681 - mae: 10.1150\n",
      "Epoch 87/100\n",
      "6944/6944 [==============================] - 6s 882us/step - loss: 193.0849 - mae: 10.1163\n",
      "Epoch 88/100\n",
      "6944/6944 [==============================] - 6s 883us/step - loss: 193.2191 - mae: 10.1215\n",
      "Epoch 89/100\n",
      "6944/6944 [==============================] - 6s 882us/step - loss: 192.9868 - mae: 10.1089\n",
      "Epoch 90/100\n",
      "6944/6944 [==============================] - 6s 830us/step - loss: 193.0851 - mae: 10.1114\n",
      "Epoch 91/100\n",
      "6944/6944 [==============================] - 6s 846us/step - loss: 193.0862 - mae: 10.1113\n",
      "Epoch 92/100\n",
      "6944/6944 [==============================] - 6s 877us/step - loss: 193.0132 - mae: 10.1101\n",
      "Epoch 93/100\n",
      "6944/6944 [==============================] - 6s 862us/step - loss: 192.9373 - mae: 10.1108\n",
      "Epoch 94/100\n",
      "6944/6944 [==============================] - 6s 871us/step - loss: 193.0219 - mae: 10.1153\n",
      "Epoch 95/100\n",
      "6944/6944 [==============================] - 6s 902us/step - loss: 192.8872 - mae: 10.1091\n",
      "Epoch 96/100\n",
      "6944/6944 [==============================] - 6s 869us/step - loss: 192.8398 - mae: 10.1085\n",
      "Epoch 97/100\n",
      "6944/6944 [==============================] - 6s 867us/step - loss: 192.8657 - mae: 10.1074\n",
      "Epoch 98/100\n",
      "6944/6944 [==============================] - 6s 849us/step - loss: 192.8953 - mae: 10.1074\n",
      "Epoch 99/100\n",
      "6944/6944 [==============================] - 6s 884us/step - loss: 192.9608 - mae: 10.1099\n",
      "Epoch 100/100\n",
      "6944/6944 [==============================] - 6s 867us/step - loss: 192.9780 - mae: 10.1142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19e64e281f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = build_model2()\n",
    "model2.fit(x_mat, y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f29abb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "n = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb1576e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:10:12.948610s\n"
     ]
    }
   ],
   "source": [
    "t = n()\n",
    "num_episodes = 100\n",
    "n_life_memory2 = []\n",
    "n_env = gym.make('CartPole-v0')\n",
    "for i in range(num_episodes):\n",
    "    n_old_observation = n_env.reset()\n",
    "    n_done = False\n",
    "    n_tot_reward = 0\n",
    "    n_em_memory2 = []\n",
    "    while not n_done:\n",
    "        pred_in = [list(n_old_observation) + [i] for i in range(2)]\n",
    "        n_new_action = np.argmax([model2.predict(pred_in)])\n",
    "        n_observation, n_reward, n_done, n_info = n_env.step(n_new_action)\n",
    "        n_tot_reward += n_reward\n",
    "        n_em_memory2.append({\n",
    "            \"obs0\": n_old_observation[0],\n",
    "            \"obs1\": n_old_observation[1],\n",
    "            \"obs2\": n_old_observation[2],\n",
    "            \"obs3\": n_old_observation[3],\n",
    "            \"action\": n_new_action,\n",
    "            \"reward\": n_reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        \n",
    "        n_old_observation = n_observation\n",
    "\n",
    "    for n_em in n_em_memory2:\n",
    "        n_em[\"tot_reward\"] = n_tot_reward\n",
    "    n_life_memory2.extend(n_em_memory2)\n",
    "n_memory_df2 = pandas.DataFrame(n_life_memory2)\n",
    "print(f\"Training time: {n() - t}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ece621c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166.88"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_memory_df2.groupby('episode').reward.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cf8519b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    61\n",
       "True     39\n",
       "Name: reward, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(n_memory_df2.groupby('episode').reward.sum() >= 200).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106f5b48",
   "metadata": {},
   "source": [
    "### Three hiden layers Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0a2d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def build_model3():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation = 'relu', input_shape=(x_mat.shape[1], )))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f949816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "710/710 [==============================] - 1s 895us/step - loss: 408.7547 - mae: 14.7005\n",
      "Epoch 2/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 233.1066 - mae: 11.1831\n",
      "Epoch 3/100\n",
      "710/710 [==============================] - 1s 922us/step - loss: 225.9711 - mae: 10.9368\n",
      "Epoch 4/100\n",
      "710/710 [==============================] - 1s 900us/step - loss: 222.1545 - mae: 10.8156\n",
      "Epoch 5/100\n",
      "710/710 [==============================] - 1s 897us/step - loss: 219.3632 - mae: 10.7486\n",
      "Epoch 6/100\n",
      "710/710 [==============================] - 1s 948us/step - loss: 216.1697 - mae: 10.6611\n",
      "Epoch 7/100\n",
      "710/710 [==============================] - 1s 916us/step - loss: 214.0153 - mae: 10.6128\n",
      "Epoch 8/100\n",
      "710/710 [==============================] - 1s 942us/step - loss: 211.7704 - mae: 10.5367\n",
      "Epoch 9/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 209.7602 - mae: 10.4793\n",
      "Epoch 10/100\n",
      "710/710 [==============================] - 1s 905us/step - loss: 208.2997 - mae: 10.4237\n",
      "Epoch 11/100\n",
      "710/710 [==============================] - 1s 938us/step - loss: 206.6147 - mae: 10.3775\n",
      "Epoch 12/100\n",
      "710/710 [==============================] - 1s 886us/step - loss: 205.3137 - mae: 10.3569\n",
      "Epoch 13/100\n",
      "710/710 [==============================] - 1s 966us/step - loss: 203.6013 - mae: 10.3196\n",
      "Epoch 14/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 203.0955 - mae: 10.2931\n",
      "Epoch 15/100\n",
      "710/710 [==============================] - 1s 970us/step - loss: 201.8968 - mae: 10.2633\n",
      "Epoch 16/100\n",
      "710/710 [==============================] - 1s 863us/step - loss: 200.5798 - mae: 10.2219\n",
      "Epoch 17/100\n",
      "710/710 [==============================] - 1s 864us/step - loss: 199.9611 - mae: 10.2350\n",
      "Epoch 18/100\n",
      "710/710 [==============================] - 1s 943us/step - loss: 199.3378 - mae: 10.2050\n",
      "Epoch 19/100\n",
      "710/710 [==============================] - 1s 934us/step - loss: 199.0868 - mae: 10.2011\n",
      "Epoch 20/100\n",
      "710/710 [==============================] - 1s 951us/step - loss: 198.6833 - mae: 10.1940\n",
      "Epoch 21/100\n",
      "710/710 [==============================] - 1s 970us/step - loss: 197.9962 - mae: 10.1746\n",
      "Epoch 22/100\n",
      "710/710 [==============================] - 1s 990us/step - loss: 197.5607 - mae: 10.1711\n",
      "Epoch 23/100\n",
      "710/710 [==============================] - 1s 918us/step - loss: 197.0130 - mae: 10.1517\n",
      "Epoch 24/100\n",
      "710/710 [==============================] - 1s 877us/step - loss: 196.8917 - mae: 10.1499\n",
      "Epoch 25/100\n",
      "710/710 [==============================] - 1s 864us/step - loss: 196.7700 - mae: 10.1265\n",
      "Epoch 26/100\n",
      "710/710 [==============================] - 1s 875us/step - loss: 196.0324 - mae: 10.1221\n",
      "Epoch 27/100\n",
      "710/710 [==============================] - 1s 893us/step - loss: 195.2866 - mae: 10.1182\n",
      "Epoch 28/100\n",
      "710/710 [==============================] - 1s 912us/step - loss: 195.4209 - mae: 10.1049\n",
      "Epoch 29/100\n",
      "710/710 [==============================] - 1s 890us/step - loss: 194.9199 - mae: 10.0997\n",
      "Epoch 30/100\n",
      "710/710 [==============================] - 1s 881us/step - loss: 195.0527 - mae: 10.0778\n",
      "Epoch 31/100\n",
      "710/710 [==============================] - 1s 868us/step - loss: 194.1870 - mae: 10.0761\n",
      "Epoch 32/100\n",
      "710/710 [==============================] - 1s 880us/step - loss: 194.2897 - mae: 10.0659\n",
      "Epoch 33/100\n",
      "710/710 [==============================] - 1s 918us/step - loss: 194.0199 - mae: 10.0665\n",
      "Epoch 34/100\n",
      "710/710 [==============================] - 1s 910us/step - loss: 193.8374 - mae: 10.0640\n",
      "Epoch 35/100\n",
      "710/710 [==============================] - 1s 918us/step - loss: 193.5599 - mae: 10.0691\n",
      "Epoch 36/100\n",
      "710/710 [==============================] - 1s 867us/step - loss: 193.4919 - mae: 10.0433\n",
      "Epoch 37/100\n",
      "710/710 [==============================] - 1s 862us/step - loss: 192.6532 - mae: 10.0356\n",
      "Epoch 38/100\n",
      "710/710 [==============================] - 1s 894us/step - loss: 192.7816 - mae: 10.0396\n",
      "Epoch 39/100\n",
      "710/710 [==============================] - 1s 878us/step - loss: 192.5920 - mae: 10.0278\n",
      "Epoch 40/100\n",
      "710/710 [==============================] - 1s 900us/step - loss: 192.5309 - mae: 10.0247\n",
      "Epoch 41/100\n",
      "710/710 [==============================] - 1s 916us/step - loss: 191.9346 - mae: 10.0150\n",
      "Epoch 42/100\n",
      "710/710 [==============================] - 1s 876us/step - loss: 191.9180 - mae: 10.0112\n",
      "Epoch 43/100\n",
      "710/710 [==============================] - 1s 866us/step - loss: 191.9201 - mae: 9.9876\n",
      "Epoch 44/100\n",
      "710/710 [==============================] - 1s 870us/step - loss: 191.4474 - mae: 9.9926\n",
      "Epoch 45/100\n",
      "710/710 [==============================] - 1s 877us/step - loss: 191.4823 - mae: 9.9796\n",
      "Epoch 46/100\n",
      "710/710 [==============================] - 1s 864us/step - loss: 191.3636 - mae: 9.9850\n",
      "Epoch 47/100\n",
      "710/710 [==============================] - 1s 880us/step - loss: 190.5041 - mae: 9.9647\n",
      "Epoch 48/100\n",
      "710/710 [==============================] - 1s 872us/step - loss: 190.3525 - mae: 9.9670\n",
      "Epoch 49/100\n",
      "710/710 [==============================] - 1s 874us/step - loss: 190.5163 - mae: 9.9572\n",
      "Epoch 50/100\n",
      "710/710 [==============================] - 1s 873us/step - loss: 190.1596 - mae: 9.9484\n",
      "Epoch 51/100\n",
      "710/710 [==============================] - 1s 910us/step - loss: 190.2079 - mae: 9.9607\n",
      "Epoch 52/100\n",
      "710/710 [==============================] - 1s 885us/step - loss: 190.0410 - mae: 9.9622\n",
      "Epoch 53/100\n",
      "710/710 [==============================] - 1s 879us/step - loss: 190.0402 - mae: 9.9447\n",
      "Epoch 54/100\n",
      "710/710 [==============================] - 1s 867us/step - loss: 189.3082 - mae: 9.9440\n",
      "Epoch 55/100\n",
      "710/710 [==============================] - 1s 868us/step - loss: 189.1082 - mae: 9.9210\n",
      "Epoch 56/100\n",
      "710/710 [==============================] - 1s 872us/step - loss: 189.0809 - mae: 9.9319\n",
      "Epoch 57/100\n",
      "710/710 [==============================] - 1s 865us/step - loss: 188.4731 - mae: 9.9053\n",
      "Epoch 58/100\n",
      "710/710 [==============================] - 1s 898us/step - loss: 188.6090 - mae: 9.9012\n",
      "Epoch 59/100\n",
      "710/710 [==============================] - 1s 872us/step - loss: 188.4812 - mae: 9.9147\n",
      "Epoch 60/100\n",
      "710/710 [==============================] - 1s 858us/step - loss: 188.4691 - mae: 9.9092\n",
      "Epoch 61/100\n",
      "710/710 [==============================] - 1s 857us/step - loss: 187.5803 - mae: 9.8801\n",
      "Epoch 62/100\n",
      "710/710 [==============================] - 1s 866us/step - loss: 187.8370 - mae: 9.9097\n",
      "Epoch 63/100\n",
      "710/710 [==============================] - 1s 867us/step - loss: 187.5700 - mae: 9.8748\n",
      "Epoch 64/100\n",
      "710/710 [==============================] - 1s 867us/step - loss: 187.3572 - mae: 9.8741 0s - loss: 186.6971 - mae: 9.8\n",
      "Epoch 65/100\n",
      "710/710 [==============================] - 1s 868us/step - loss: 187.3757 - mae: 9.8879\n",
      "Epoch 66/100\n",
      "710/710 [==============================] - 1s 903us/step - loss: 186.9819 - mae: 9.8701\n",
      "Epoch 67/100\n",
      "710/710 [==============================] - 1s 872us/step - loss: 187.1828 - mae: 9.8914\n",
      "Epoch 68/100\n",
      "710/710 [==============================] - 1s 863us/step - loss: 186.5003 - mae: 9.8683\n",
      "Epoch 69/100\n",
      "710/710 [==============================] - 1s 875us/step - loss: 186.6141 - mae: 9.8790\n",
      "Epoch 70/100\n",
      "710/710 [==============================] - 1s 870us/step - loss: 186.3591 - mae: 9.8472\n",
      "Epoch 71/100\n",
      "710/710 [==============================] - 1s 895us/step - loss: 186.3466 - mae: 9.8630\n",
      "Epoch 72/100\n",
      "710/710 [==============================] - 1s 866us/step - loss: 186.0444 - mae: 9.8416\n",
      "Epoch 73/100\n",
      "710/710 [==============================] - 1s 896us/step - loss: 186.0240 - mae: 9.8356\n",
      "Epoch 74/100\n",
      "710/710 [==============================] - 1s 861us/step - loss: 185.8250 - mae: 9.8468\n",
      "Epoch 75/100\n",
      "710/710 [==============================] - 1s 874us/step - loss: 186.2176 - mae: 9.8532\n",
      "Epoch 76/100\n",
      "710/710 [==============================] - 1s 882us/step - loss: 185.5269 - mae: 9.8387\n",
      "Epoch 77/100\n",
      "710/710 [==============================] - 1s 909us/step - loss: 185.8392 - mae: 9.8390\n",
      "Epoch 78/100\n",
      "710/710 [==============================] - 1s 864us/step - loss: 185.6379 - mae: 9.8336\n",
      "Epoch 79/100\n",
      "710/710 [==============================] - 1s 869us/step - loss: 185.3321 - mae: 9.8396\n",
      "Epoch 80/100\n",
      "710/710 [==============================] - 1s 869us/step - loss: 185.2566 - mae: 9.8312\n",
      "Epoch 81/100\n",
      "710/710 [==============================] - 1s 871us/step - loss: 184.8263 - mae: 9.8178\n",
      "Epoch 82/100\n",
      "710/710 [==============================] - 1s 870us/step - loss: 184.9765 - mae: 9.8247\n",
      "Epoch 83/100\n",
      "710/710 [==============================] - 1s 893us/step - loss: 184.8413 - mae: 9.8278\n",
      "Epoch 84/100\n",
      "710/710 [==============================] - 1s 871us/step - loss: 184.9348 - mae: 9.8204\n",
      "Epoch 85/100\n",
      "710/710 [==============================] - 1s 865us/step - loss: 184.8525 - mae: 9.8153\n",
      "Epoch 86/100\n",
      "710/710 [==============================] - 1s 857us/step - loss: 184.6653 - mae: 9.8219\n",
      "Epoch 87/100\n",
      "710/710 [==============================] - 1s 866us/step - loss: 184.5392 - mae: 9.8038\n",
      "Epoch 88/100\n",
      "710/710 [==============================] - 1s 859us/step - loss: 184.5386 - mae: 9.8127\n",
      "Epoch 89/100\n",
      "710/710 [==============================] - 1s 868us/step - loss: 184.4135 - mae: 9.8259\n",
      "Epoch 90/100\n",
      "710/710 [==============================] - 1s 862us/step - loss: 184.5904 - mae: 9.8239\n",
      "Epoch 91/100\n",
      "710/710 [==============================] - 1s 908us/step - loss: 184.0938 - mae: 9.7900\n",
      "Epoch 92/100\n",
      "710/710 [==============================] - 1s 859us/step - loss: 184.1639 - mae: 9.8068\n",
      "Epoch 93/100\n",
      "710/710 [==============================] - 1s 863us/step - loss: 183.8240 - mae: 9.7918\n",
      "Epoch 94/100\n",
      "710/710 [==============================] - 1s 872us/step - loss: 183.5567 - mae: 9.7960\n",
      "Epoch 95/100\n",
      "710/710 [==============================] - 1s 870us/step - loss: 183.6218 - mae: 9.7926\n",
      "Epoch 96/100\n",
      "710/710 [==============================] - 1s 859us/step - loss: 183.7306 - mae: 9.8022\n",
      "Epoch 97/100\n",
      "710/710 [==============================] - 1s 866us/step - loss: 183.8050 - mae: 9.7974\n",
      "Epoch 98/100\n",
      "710/710 [==============================] - 1s 884us/step - loss: 183.7740 - mae: 9.7840\n",
      "Epoch 99/100\n",
      "710/710 [==============================] - 1s 868us/step - loss: 183.5152 - mae: 9.7764\n",
      "Epoch 100/100\n",
      "710/710 [==============================] - 1s 897us/step - loss: 183.3241 - mae: 9.7709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20408c75b20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = build_model3()\n",
    "model3.fit(x_mat, y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f50ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "n = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd4029ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:09:58.996290s\n"
     ]
    }
   ],
   "source": [
    "t = n()\n",
    "num_episodes = 100\n",
    "n_life_memory3 = []\n",
    "n_env = gym.make('CartPole-v0')\n",
    "for i in range(num_episodes):\n",
    "    n_old_observation = n_env.reset()\n",
    "    n_done = False\n",
    "    n_tot_reward = 0\n",
    "    n_em_memory3 = []\n",
    "    while not n_done:\n",
    "        pred_in = [list(n_old_observation) + [i] for i in range(2)]\n",
    "        n_new_action = np.argmax([model3.predict(pred_in)])\n",
    "        n_observation, n_reward, n_done, n_info = n_env.step(n_new_action)\n",
    "        n_tot_reward += n_reward\n",
    "        n_em_memory3.append({\n",
    "            \"obs0\": n_old_observation[0],\n",
    "            \"obs1\": n_old_observation[1],\n",
    "            \"obs2\": n_old_observation[2],\n",
    "            \"obs3\": n_old_observation[3],\n",
    "            \"action\": n_new_action,\n",
    "            \"reward\": n_reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        \n",
    "        n_old_observation = n_observation\n",
    "\n",
    "    for n_em in n_em_memory3:\n",
    "        n_em[\"tot_reward\"] = n_tot_reward\n",
    "    n_life_memory3.extend(n_em_memory3)\n",
    "n_memory_df3 = pandas.DataFrame(n_life_memory3)\n",
    "print(f\"Training time: {n() - t}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81c9e0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154.55"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_memory_df3.groupby('episode').reward.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89b3a68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    62\n",
       "True     38\n",
       "Name: reward, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(n_memory_df3.groupby('episode').reward.sum() >= 200).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee83399",
   "metadata": {},
   "source": [
    "### Neural Network from scratch\n",
    "https://www.youtube.com/watch?v=Wo5dMEP_BbI&list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3&index=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "672872eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mat = memory_df[[\"obs0\", \"obs1\", \"obs2\", \"obs3\", \"action\"]].to_numpy()\n",
    "y = memory_df['comb_reward'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2f6e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# def loss_fn(y_true, y_pred, eps=1e-16):\n",
    "#     \"\"\"\n",
    "#     Loss function we would like to optimize (minimize)\n",
    "#     We are using Logarithmic Loss\n",
    "#     http://scikit-learn.org/stable/modules/model_evaluation.html#log-loss\n",
    "#     \"\"\"\n",
    "#     y_pred = np.maximum(y_pred,eps)\n",
    "#     y_pred = np.minimum(y_pred,(1-eps))\n",
    "#     return -(np.sum(y_true * np.log(y_pred)) + np.sum((1-y_true)*np.log(1-y_pred)))/len(y_true)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def deri_relu(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "def forward_pass(W_1, W_2):\n",
    "    global x_mat\n",
    "    global y\n",
    "    global num_\n",
    "\n",
    "    z_2 = np.dot(x_mat, W_1)   # (input_size , 5) x (5, 64) = (input_size , 64)\n",
    "    a_2 = sigmoid(z_2)          # (input_size , 64)\n",
    "    z_3 = np.dot(a_2, W_2)      # (input_size , 64) x (64, ) = (221input_size191 , )\n",
    "    y_pred = sigmoid(z_3).reshape((len(x_mat),))      # (input_size , )\n",
    "    J_z_3_grad = -y + y_pred      # (input_size , )\n",
    "    J_W_2_grad = np.dot(J_z_3_grad, a_2)      # (input_size , ) x (input_size , 64) = (64, )\n",
    "    a_2_z_2_grad = sigmoid(z_2)*(1 - sigmoid(z_2))  # (input_size , 64) * (input_size , 64) = (input_size , 64)\n",
    "                                                    #     J_W_1_grad = a_1 * a_2_z_2_grad * W_2 * J_z_3_grad\n",
    "                                                    #     J_W_1_grad = np.dot(x_mat, a_2_z_2_grad).dot(W_2).dot(J_z_3_grad)\n",
    "    J_W_1_grad = (np.dot((J_z_3_grad).reshape(-1,1), W_2.reshape(-1,1).T)*a_2_z_2_grad).T.dot(x_mat).T\n",
    "                        # (input_size , )->(input_size , 1) x (64 x 1).T\n",
    "                                                   # = (input_size , 64) * (input_size , 64)\n",
    "                                                                  # = (input_size , 64).T = (64, input_size ) x (input_size , 5)\n",
    "                                                                  # = (64, 5).T = (5, 64)\n",
    "    gradient = (J_W_1_grad, J_W_2_grad)\n",
    "    \n",
    "    return y_pred, gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59d02b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to update bias??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "885ef2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_1 = np.random.uniform(-1,1,size=(5,64))\n",
    "W_2 = np.random.uniform(-1,1,size=(64))\n",
    "bias = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "612700e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moon\\AppData\\Local\\Temp/ipykernel_28008/916779298.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:10.780250s\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "n = datetime.datetime.now\n",
    "t = n()\n",
    "\n",
    "np.random.seed(1241)\n",
    "\n",
    "num_iter = 50\n",
    "learning_rate = .001\n",
    "# x_mat = x_mat_full\n",
    "\n",
    "total_pred = []\n",
    "for i in range(num_iter):\n",
    "    y_pred, (J_W_1_grad, J_W_2_grad) = forward_pass(W_1, W_2)\n",
    "    \n",
    "    W_1 = W_1 - learning_rate * J_W_1_grad\n",
    "    W_2 = W_2 - learning_rate * J_W_2_grad\n",
    "    \n",
    "    total_pred.append(y_pred)\n",
    "print(f\"Training time: {n() - t}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "98c1e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_predict(pred_in):\n",
    "    z_2 = np.dot(pred_in[0], W_1)\n",
    "    a_2 = sigmoid(z_2)\n",
    "    z_3 = np.dot(a_2, W_2)\n",
    "    y_pred1 = sigmoid(z_3)\n",
    "    \n",
    "    z2_2 = np.dot(pred_in[1], W_1)\n",
    "    a2_2 = sigmoid(z2_2)\n",
    "    z2_3 = np.dot(a2_2, W_2)\n",
    "    y_pred2 = sigmoid(z2_3)\n",
    "    \n",
    "    return y_pred1, y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9baa6698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moon\\AppData\\Local\\Temp/ipykernel_28008/916779298.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:01.298666s\n"
     ]
    }
   ],
   "source": [
    "t = n()\n",
    "num_episodes = 1000\n",
    "n_life_memory = []\n",
    "n_env = gym.make('CartPole-v0')\n",
    "for i in range(num_episodes):\n",
    "    n_old_observation = n_env.reset()\n",
    "    n_done = False\n",
    "    n_tot_reward = 0\n",
    "    n_em_memory = []\n",
    "    while not n_done:\n",
    "        pred_in = [list(n_old_observation) + [i] for i in range(2)]\n",
    "        n_new_action = np.argmax([nn_predict(pred_in)])\n",
    "        n_observation, n_reward, n_done, n_info = n_env.step(n_new_action)\n",
    "        n_tot_reward += n_reward\n",
    "        n_em_memory.append({\n",
    "            \"obs0\": n_old_observation[0],\n",
    "            \"obs1\": n_old_observation[1],\n",
    "            \"obs2\": n_old_observation[2],\n",
    "            \"obs3\": n_old_observation[3],\n",
    "            \"action\": n_new_action,\n",
    "            \"reward\": n_reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        \n",
    "        n_old_observation = n_observation\n",
    "\n",
    "    for n_em in n_em_memory:\n",
    "        n_em[\"tot_reward\"] = n_tot_reward\n",
    "    n_life_memory.extend(n_em_memory)\n",
    "n_memory_df = pandas.DataFrame(n_life_memory)\n",
    "print(f\"Training time: {n() - t}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "aacb0dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.07"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_memory_df.groupby('episode').reward.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1fa6b72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    998\n",
       "True       2\n",
       "Name: reward, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(n_memory_df.groupby('episode').reward.sum() >= 200).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4ebca4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:00.365990s\n"
     ]
    }
   ],
   "source": [
    "t = n()\n",
    "num_episodes = 1000\n",
    "n_life_memory = []\n",
    "n_env = gym.make('CartPole-v0')\n",
    "for i in range(num_episodes):\n",
    "    n_old_observation = n_env.reset()\n",
    "    n_done = False\n",
    "    n_tot_reward = 0\n",
    "    n_em_memory = []\n",
    "    while not n_done:\n",
    "        n_new_action = env.action_space.sample()\n",
    "        n_observation, n_reward, n_done, n_info = n_env.step(n_new_action)\n",
    "        n_tot_reward += n_reward\n",
    "        n_em_memory.append({\n",
    "            \"obs0\": n_old_observation[0],\n",
    "            \"obs1\": n_old_observation[1],\n",
    "            \"obs2\": n_old_observation[2],\n",
    "            \"obs3\": n_old_observation[3],\n",
    "            \"action\": n_new_action,\n",
    "            \"reward\": n_reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        \n",
    "        n_old_observation = n_observation\n",
    "\n",
    "    for n_em in n_em_memory:\n",
    "        n_em[\"tot_reward\"] = n_tot_reward\n",
    "    n_life_memory.extend(n_em_memory)\n",
    "ran_memory_df = pandas.DataFrame(n_life_memory)\n",
    "print(f\"Training time: {n() - t}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "05e440d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.907"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran_memory_df.groupby('episode').reward.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "06cc91cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1000\n",
       "Name: reward, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ran_memory_df.groupby('episode').reward.sum() >= 200).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f814faad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
