{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91bb8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551da496",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 1000\n",
    "\n",
    "life_memory = []\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    old_observation = env.reset()\n",
    "    done = False\n",
    "    tot_reward = 0\n",
    "    ep_memory = []\n",
    "    while not done:\n",
    "        new_action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(new_action)\n",
    "        tot_reward += reward\n",
    "        \n",
    "        ep_memory.append({\n",
    "            \"obs0\": old_observation[0],\n",
    "            \"obs1\": old_observation[1],\n",
    "            \"obs2\": old_observation[2],\n",
    "            \"obs3\": old_observation[3],\n",
    "            \"action\": new_action,\n",
    "            \"reward\": reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        old_observation = observation\n",
    "        \n",
    "    for ep_mem in ep_memory:\n",
    "        ep_mem[\"tot_reward\"] = tot_reward\n",
    "        \n",
    "    life_memory.extend(ep_memory)\n",
    "    \n",
    "memory_df = pandas.DataFrame(life_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c053fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_df.groupby(\"episode\").reward.sum().mean()\n",
    "memory_df[\"comb_reward\"] = .5*memory_df.reward + 1.2 * memory_df.tot_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "271c0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mat = memory_df[[\"obs0\", \"obs1\", \"obs2\", \"obs3\", \"action\"]].to_numpy()\n",
    "y = memory_df['comb_reward'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266a64f",
   "metadata": {},
   "source": [
    "### Two hiden layers Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "968d53fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "# optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "def build_model2():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation = 'relu', input_shape=(x_mat.shape[1], )))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='relu'))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0ff1daf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "710/710 [==============================] - 1s 799us/step - loss: 540.0498 - mae: 16.9274\n",
      "Epoch 2/100\n",
      "710/710 [==============================] - 1s 857us/step - loss: 303.0374 - mae: 13.1556\n",
      "Epoch 3/100\n",
      "710/710 [==============================] - 1s 812us/step - loss: 263.2734 - mae: 12.1933\n",
      "Epoch 4/100\n",
      "710/710 [==============================] - 1s 821us/step - loss: 251.6363 - mae: 11.7914\n",
      "Epoch 5/100\n",
      "710/710 [==============================] - 1s 912us/step - loss: 234.7662 - mae: 11.2390\n",
      "Epoch 6/100\n",
      "710/710 [==============================] - 1s 814us/step - loss: 224.1332 - mae: 10.8882\n",
      "Epoch 7/100\n",
      "710/710 [==============================] - 1s 821us/step - loss: 221.2112 - mae: 10.7813\n",
      "Epoch 8/100\n",
      "710/710 [==============================] - 1s 805us/step - loss: 218.7506 - mae: 10.7061\n",
      "Epoch 9/100\n",
      "710/710 [==============================] - 1s 800us/step - loss: 216.7789 - mae: 10.6465\n",
      "Epoch 10/100\n",
      "710/710 [==============================] - 1s 790us/step - loss: 214.8075 - mae: 10.6091\n",
      "Epoch 11/100\n",
      "710/710 [==============================] - 1s 807us/step - loss: 213.4582 - mae: 10.5642\n",
      "Epoch 12/100\n",
      "710/710 [==============================] - 1s 795us/step - loss: 211.5675 - mae: 10.5380\n",
      "Epoch 13/100\n",
      "710/710 [==============================] - 1s 817us/step - loss: 210.2938 - mae: 10.4908\n",
      "Epoch 14/100\n",
      "710/710 [==============================] - 1s 877us/step - loss: 208.9287 - mae: 10.4459\n",
      "Epoch 15/100\n",
      "710/710 [==============================] - 1s 870us/step - loss: 207.4591 - mae: 10.4228\n",
      "Epoch 16/100\n",
      "710/710 [==============================] - 1s 851us/step - loss: 206.1892 - mae: 10.3796\n",
      "Epoch 17/100\n",
      "710/710 [==============================] - 1s 869us/step - loss: 205.0397 - mae: 10.3611\n",
      "Epoch 18/100\n",
      "710/710 [==============================] - 1s 828us/step - loss: 203.9451 - mae: 10.3350\n",
      "Epoch 19/100\n",
      "710/710 [==============================] - 1s 877us/step - loss: 203.1013 - mae: 10.3235\n",
      "Epoch 20/100\n",
      "710/710 [==============================] - 1s 850us/step - loss: 201.8619 - mae: 10.2734\n",
      "Epoch 21/100\n",
      "710/710 [==============================] - 1s 882us/step - loss: 201.3385 - mae: 10.2619\n",
      "Epoch 22/100\n",
      "710/710 [==============================] - 1s 892us/step - loss: 200.3936 - mae: 10.2243\n",
      "Epoch 23/100\n",
      "710/710 [==============================] - 1s 797us/step - loss: 199.6383 - mae: 10.2249\n",
      "Epoch 24/100\n",
      "710/710 [==============================] - 1s 850us/step - loss: 199.3453 - mae: 10.2105\n",
      "Epoch 25/100\n",
      "710/710 [==============================] - 1s 895us/step - loss: 198.3965 - mae: 10.1929\n",
      "Epoch 26/100\n",
      "710/710 [==============================] - 1s 848us/step - loss: 197.8523 - mae: 10.1737\n",
      "Epoch 27/100\n",
      "710/710 [==============================] - 1s 825us/step - loss: 197.7934 - mae: 10.1711\n",
      "Epoch 28/100\n",
      "710/710 [==============================] - 1s 873us/step - loss: 196.9166 - mae: 10.1475\n",
      "Epoch 29/100\n",
      "710/710 [==============================] - 1s 794us/step - loss: 197.0448 - mae: 10.1523\n",
      "Epoch 30/100\n",
      "710/710 [==============================] - 1s 809us/step - loss: 196.3889 - mae: 10.1372\n",
      "Epoch 31/100\n",
      "710/710 [==============================] - 1s 804us/step - loss: 195.8574 - mae: 10.1333\n",
      "Epoch 32/100\n",
      "710/710 [==============================] - 1s 861us/step - loss: 195.7663 - mae: 10.1331\n",
      "Epoch 33/100\n",
      "710/710 [==============================] - 1s 754us/step - loss: 195.4188 - mae: 10.1160\n",
      "Epoch 34/100\n",
      "710/710 [==============================] - 1s 950us/step - loss: 195.3432 - mae: 10.1110\n",
      "Epoch 35/100\n",
      "710/710 [==============================] - 1s 856us/step - loss: 194.9334 - mae: 10.0870\n",
      "Epoch 36/100\n",
      "710/710 [==============================] - 1s 812us/step - loss: 194.9470 - mae: 10.0942\n",
      "Epoch 37/100\n",
      "710/710 [==============================] - 1s 815us/step - loss: 194.4722 - mae: 10.0815\n",
      "Epoch 38/100\n",
      "710/710 [==============================] - 1s 821us/step - loss: 194.2912 - mae: 10.0935\n",
      "Epoch 39/100\n",
      "710/710 [==============================] - 1s 930us/step - loss: 194.1022 - mae: 10.0666\n",
      "Epoch 40/100\n",
      "710/710 [==============================] - 1s 971us/step - loss: 193.9028 - mae: 10.0676\n",
      "Epoch 41/100\n",
      "710/710 [==============================] - 1s 866us/step - loss: 193.5693 - mae: 10.0592\n",
      "Epoch 42/100\n",
      "710/710 [==============================] - 1s 927us/step - loss: 193.7072 - mae: 10.0661\n",
      "Epoch 43/100\n",
      "710/710 [==============================] - 1s 878us/step - loss: 193.3130 - mae: 10.04960s - loss: 192.7852 - mae:\n",
      "Epoch 44/100\n",
      "710/710 [==============================] - 1s 943us/step - loss: 192.9677 - mae: 10.0460\n",
      "Epoch 45/100\n",
      "710/710 [==============================] - ETA: 0s - loss: 193.1435 - mae: 10.06 - 1s 972us/step - loss: 192.8263 - mae: 10.0500\n",
      "Epoch 46/100\n",
      "710/710 [==============================] - 1s 883us/step - loss: 192.8788 - mae: 10.0369\n",
      "Epoch 47/100\n",
      "710/710 [==============================] - 1s 936us/step - loss: 192.6944 - mae: 10.0443\n",
      "Epoch 48/100\n",
      "710/710 [==============================] - 1s 873us/step - loss: 192.5435 - mae: 10.0243\n",
      "Epoch 49/100\n",
      "710/710 [==============================] - 1s 774us/step - loss: 192.4406 - mae: 10.0289\n",
      "Epoch 50/100\n",
      "710/710 [==============================] - 1s 908us/step - loss: 192.2270 - mae: 10.0325\n",
      "Epoch 51/100\n",
      "710/710 [==============================] - 1s 882us/step - loss: 192.2511 - mae: 10.0238\n",
      "Epoch 52/100\n",
      "710/710 [==============================] - 1s 894us/step - loss: 192.1496 - mae: 10.0261\n",
      "Epoch 53/100\n",
      "710/710 [==============================] - 1s 918us/step - loss: 191.6869 - mae: 10.0006\n",
      "Epoch 54/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 191.5134 - mae: 10.0151\n",
      "Epoch 55/100\n",
      "710/710 [==============================] - 1s 888us/step - loss: 191.8986 - mae: 10.0098\n",
      "Epoch 56/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 191.3495 - mae: 10.0071\n",
      "Epoch 57/100\n",
      "710/710 [==============================] - 1s 866us/step - loss: 191.6557 - mae: 10.0034\n",
      "Epoch 58/100\n",
      "710/710 [==============================] - 1s 984us/step - loss: 191.2848 - mae: 9.9918\n",
      "Epoch 59/100\n",
      "710/710 [==============================] - 1s 970us/step - loss: 191.1780 - mae: 10.0012\n",
      "Epoch 60/100\n",
      "710/710 [==============================] - 1s 906us/step - loss: 190.9497 - mae: 9.9903\n",
      "Epoch 61/100\n",
      "710/710 [==============================] - 1s 879us/step - loss: 190.8020 - mae: 9.9978\n",
      "Epoch 62/100\n",
      "710/710 [==============================] - 1s 868us/step - loss: 190.4632 - mae: 9.9708\n",
      "Epoch 63/100\n",
      "710/710 [==============================] - 1s 870us/step - loss: 190.6773 - mae: 9.9942\n",
      "Epoch 64/100\n",
      "710/710 [==============================] - 1s 879us/step - loss: 190.5285 - mae: 9.9804\n",
      "Epoch 65/100\n",
      "710/710 [==============================] - 1s 892us/step - loss: 190.7127 - mae: 9.9827\n",
      "Epoch 66/100\n",
      "710/710 [==============================] - 1s 873us/step - loss: 190.4627 - mae: 9.9756\n",
      "Epoch 67/100\n",
      "710/710 [==============================] - 1s 858us/step - loss: 190.0521 - mae: 9.9668\n",
      "Epoch 68/100\n",
      "710/710 [==============================] - 1s 860us/step - loss: 189.9149 - mae: 9.9638\n",
      "Epoch 69/100\n",
      "710/710 [==============================] - 1s 877us/step - loss: 189.5818 - mae: 9.9630\n",
      "Epoch 70/100\n",
      "710/710 [==============================] - 1s 850us/step - loss: 189.6913 - mae: 9.9552\n",
      "Epoch 71/100\n",
      "710/710 [==============================] - 1s 869us/step - loss: 189.2953 - mae: 9.9579\n",
      "Epoch 72/100\n",
      "710/710 [==============================] - 1s 972us/step - loss: 189.3105 - mae: 9.9429\n",
      "Epoch 73/100\n",
      "710/710 [==============================] - 1s 933us/step - loss: 188.8591 - mae: 9.9425\n",
      "Epoch 74/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 189.2211 - mae: 9.9561\n",
      "Epoch 75/100\n",
      "710/710 [==============================] - 1s 876us/step - loss: 188.6834 - mae: 9.9280\n",
      "Epoch 76/100\n",
      "710/710 [==============================] - 1s 872us/step - loss: 188.5775 - mae: 9.9470\n",
      "Epoch 77/100\n",
      "710/710 [==============================] - 1s 950us/step - loss: 188.5884 - mae: 9.9385\n",
      "Epoch 78/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 188.3859 - mae: 9.9268\n",
      "Epoch 79/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 188.3118 - mae: 9.9143\n",
      "Epoch 80/100\n",
      "710/710 [==============================] - 1s 951us/step - loss: 188.2492 - mae: 9.9220\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710/710 [==============================] - 1s 1ms/step - loss: 188.0951 - mae: 9.9286\n",
      "Epoch 82/100\n",
      "710/710 [==============================] - 1s 970us/step - loss: 188.0068 - mae: 9.9102\n",
      "Epoch 83/100\n",
      "710/710 [==============================] - 1s 818us/step - loss: 188.1554 - mae: 9.9194\n",
      "Epoch 84/100\n",
      "710/710 [==============================] - 1s 954us/step - loss: 187.7109 - mae: 9.9107\n",
      "Epoch 85/100\n",
      "710/710 [==============================] - 1s 918us/step - loss: 187.5760 - mae: 9.9063\n",
      "Epoch 86/100\n",
      "710/710 [==============================] - 1s 943us/step - loss: 187.5409 - mae: 9.9177\n",
      "Epoch 87/100\n",
      "710/710 [==============================] - 1s 897us/step - loss: 187.1200 - mae: 9.8932\n",
      "Epoch 88/100\n",
      "710/710 [==============================] - 1s 945us/step - loss: 187.4121 - mae: 9.9007\n",
      "Epoch 89/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 186.8506 - mae: 9.8865\n",
      "Epoch 90/100\n",
      "710/710 [==============================] - 1s 895us/step - loss: 187.2912 - mae: 9.9008\n",
      "Epoch 91/100\n",
      "710/710 [==============================] - 1s 993us/step - loss: 186.8228 - mae: 9.8944\n",
      "Epoch 92/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 187.0786 - mae: 9.8853\n",
      "Epoch 93/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 186.9786 - mae: 9.8888\n",
      "Epoch 94/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 186.6289 - mae: 9.8804\n",
      "Epoch 95/100\n",
      "710/710 [==============================] - 1s 991us/step - loss: 186.4758 - mae: 9.8733\n",
      "Epoch 96/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 186.5209 - mae: 9.8728\n",
      "Epoch 97/100\n",
      "710/710 [==============================] - 1s 951us/step - loss: 186.2574 - mae: 9.8747\n",
      "Epoch 98/100\n",
      "710/710 [==============================] - 1s 984us/step - loss: 186.1475 - mae: 9.8678\n",
      "Epoch 99/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 186.3228 - mae: 9.8756\n",
      "Epoch 100/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 185.9135 - mae: 9.8697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2041358ce50>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = build_model2()\n",
    "model2.fit(x_mat, y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cb1576e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:01:12.462982s\n"
     ]
    }
   ],
   "source": [
    "t = n()\n",
    "num_episodes = 10\n",
    "n_life_memory2 = []\n",
    "n_env = gym.make('CartPole-v0')\n",
    "for i in range(num_episodes):\n",
    "    n_old_observation = n_env.reset()\n",
    "    n_done = False\n",
    "    n_tot_reward = 0\n",
    "    n_em_memory2 = []\n",
    "    while not n_done:\n",
    "        pred_in = [list(n_old_observation) + [i] for i in range(2)]\n",
    "        n_new_action = np.argmax([model2.predict(pred_in)])\n",
    "        n_observation, n_reward, n_done, n_info = n_env.step(n_new_action)\n",
    "        n_tot_reward += n_reward\n",
    "        n_em_memory2.append({\n",
    "            \"obs0\": n_old_observation[0],\n",
    "            \"obs1\": n_old_observation[1],\n",
    "            \"obs2\": n_old_observation[2],\n",
    "            \"obs3\": n_old_observation[3],\n",
    "            \"action\": n_new_action,\n",
    "            \"reward\": n_reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        \n",
    "        n_old_observation = n_observation\n",
    "\n",
    "    for n_em in n_em_memory2:\n",
    "        n_em[\"tot_reward\"] = n_tot_reward\n",
    "    n_life_memory2.extend(n_em_memory2)\n",
    "n_memory_df2 = pandas.DataFrame(n_life_memory2)\n",
    "print(f\"Training time: {n() - t}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0ece621c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177.2"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_memory_df2.groupby('episode').reward.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4cf8519b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     8\n",
       "False    2\n",
       "Name: reward, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(n_memory_df2.groupby('episode').reward.sum() >= 200).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106f5b48",
   "metadata": {},
   "source": [
    "### Three hiden layers Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0a2d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def build_model3():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation = 'relu', input_shape=(x_mat.shape[1], )))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f949816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "710/710 [==============================] - 1s 895us/step - loss: 408.7547 - mae: 14.7005\n",
      "Epoch 2/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 233.1066 - mae: 11.1831\n",
      "Epoch 3/100\n",
      "710/710 [==============================] - 1s 922us/step - loss: 225.9711 - mae: 10.9368\n",
      "Epoch 4/100\n",
      "710/710 [==============================] - 1s 900us/step - loss: 222.1545 - mae: 10.8156\n",
      "Epoch 5/100\n",
      "710/710 [==============================] - 1s 897us/step - loss: 219.3632 - mae: 10.7486\n",
      "Epoch 6/100\n",
      "710/710 [==============================] - 1s 948us/step - loss: 216.1697 - mae: 10.6611\n",
      "Epoch 7/100\n",
      "710/710 [==============================] - 1s 916us/step - loss: 214.0153 - mae: 10.6128\n",
      "Epoch 8/100\n",
      "710/710 [==============================] - 1s 942us/step - loss: 211.7704 - mae: 10.5367\n",
      "Epoch 9/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 209.7602 - mae: 10.4793\n",
      "Epoch 10/100\n",
      "710/710 [==============================] - 1s 905us/step - loss: 208.2997 - mae: 10.4237\n",
      "Epoch 11/100\n",
      "710/710 [==============================] - 1s 938us/step - loss: 206.6147 - mae: 10.3775\n",
      "Epoch 12/100\n",
      "710/710 [==============================] - 1s 886us/step - loss: 205.3137 - mae: 10.3569\n",
      "Epoch 13/100\n",
      "710/710 [==============================] - 1s 966us/step - loss: 203.6013 - mae: 10.3196\n",
      "Epoch 14/100\n",
      "710/710 [==============================] - 1s 1ms/step - loss: 203.0955 - mae: 10.2931\n",
      "Epoch 15/100\n",
      "710/710 [==============================] - 1s 970us/step - loss: 201.8968 - mae: 10.2633\n",
      "Epoch 16/100\n",
      "710/710 [==============================] - 1s 863us/step - loss: 200.5798 - mae: 10.2219\n",
      "Epoch 17/100\n",
      "710/710 [==============================] - 1s 864us/step - loss: 199.9611 - mae: 10.2350\n",
      "Epoch 18/100\n",
      "710/710 [==============================] - 1s 943us/step - loss: 199.3378 - mae: 10.2050\n",
      "Epoch 19/100\n",
      "710/710 [==============================] - 1s 934us/step - loss: 199.0868 - mae: 10.2011\n",
      "Epoch 20/100\n",
      "710/710 [==============================] - 1s 951us/step - loss: 198.6833 - mae: 10.1940\n",
      "Epoch 21/100\n",
      "710/710 [==============================] - 1s 970us/step - loss: 197.9962 - mae: 10.1746\n",
      "Epoch 22/100\n",
      "710/710 [==============================] - 1s 990us/step - loss: 197.5607 - mae: 10.1711\n",
      "Epoch 23/100\n",
      "710/710 [==============================] - 1s 918us/step - loss: 197.0130 - mae: 10.1517\n",
      "Epoch 24/100\n",
      "710/710 [==============================] - 1s 877us/step - loss: 196.8917 - mae: 10.1499\n",
      "Epoch 25/100\n",
      "710/710 [==============================] - 1s 864us/step - loss: 196.7700 - mae: 10.1265\n",
      "Epoch 26/100\n",
      "710/710 [==============================] - 1s 875us/step - loss: 196.0324 - mae: 10.1221\n",
      "Epoch 27/100\n",
      "710/710 [==============================] - 1s 893us/step - loss: 195.2866 - mae: 10.1182\n",
      "Epoch 28/100\n",
      "710/710 [==============================] - 1s 912us/step - loss: 195.4209 - mae: 10.1049\n",
      "Epoch 29/100\n",
      "710/710 [==============================] - 1s 890us/step - loss: 194.9199 - mae: 10.0997\n",
      "Epoch 30/100\n",
      "710/710 [==============================] - 1s 881us/step - loss: 195.0527 - mae: 10.0778\n",
      "Epoch 31/100\n",
      "710/710 [==============================] - 1s 868us/step - loss: 194.1870 - mae: 10.0761\n",
      "Epoch 32/100\n",
      "710/710 [==============================] - 1s 880us/step - loss: 194.2897 - mae: 10.0659\n",
      "Epoch 33/100\n",
      "710/710 [==============================] - 1s 918us/step - loss: 194.0199 - mae: 10.0665\n",
      "Epoch 34/100\n",
      "710/710 [==============================] - 1s 910us/step - loss: 193.8374 - mae: 10.0640\n",
      "Epoch 35/100\n",
      "710/710 [==============================] - 1s 918us/step - loss: 193.5599 - mae: 10.0691\n",
      "Epoch 36/100\n",
      "710/710 [==============================] - 1s 867us/step - loss: 193.4919 - mae: 10.0433\n",
      "Epoch 37/100\n",
      "710/710 [==============================] - 1s 862us/step - loss: 192.6532 - mae: 10.0356\n",
      "Epoch 38/100\n",
      "710/710 [==============================] - 1s 894us/step - loss: 192.7816 - mae: 10.0396\n",
      "Epoch 39/100\n",
      "710/710 [==============================] - 1s 878us/step - loss: 192.5920 - mae: 10.0278\n",
      "Epoch 40/100\n",
      "710/710 [==============================] - 1s 900us/step - loss: 192.5309 - mae: 10.0247\n",
      "Epoch 41/100\n",
      "710/710 [==============================] - 1s 916us/step - loss: 191.9346 - mae: 10.0150\n",
      "Epoch 42/100\n",
      "710/710 [==============================] - 1s 876us/step - loss: 191.9180 - mae: 10.0112\n",
      "Epoch 43/100\n",
      "710/710 [==============================] - 1s 866us/step - loss: 191.9201 - mae: 9.9876\n",
      "Epoch 44/100\n",
      "710/710 [==============================] - 1s 870us/step - loss: 191.4474 - mae: 9.9926\n",
      "Epoch 45/100\n",
      "710/710 [==============================] - 1s 877us/step - loss: 191.4823 - mae: 9.9796\n",
      "Epoch 46/100\n",
      "710/710 [==============================] - 1s 864us/step - loss: 191.3636 - mae: 9.9850\n",
      "Epoch 47/100\n",
      "710/710 [==============================] - 1s 880us/step - loss: 190.5041 - mae: 9.9647\n",
      "Epoch 48/100\n",
      "710/710 [==============================] - 1s 872us/step - loss: 190.3525 - mae: 9.9670\n",
      "Epoch 49/100\n",
      "710/710 [==============================] - 1s 874us/step - loss: 190.5163 - mae: 9.9572\n",
      "Epoch 50/100\n",
      "710/710 [==============================] - 1s 873us/step - loss: 190.1596 - mae: 9.9484\n",
      "Epoch 51/100\n",
      "710/710 [==============================] - 1s 910us/step - loss: 190.2079 - mae: 9.9607\n",
      "Epoch 52/100\n",
      "710/710 [==============================] - 1s 885us/step - loss: 190.0410 - mae: 9.9622\n",
      "Epoch 53/100\n",
      "710/710 [==============================] - 1s 879us/step - loss: 190.0402 - mae: 9.9447\n",
      "Epoch 54/100\n",
      "710/710 [==============================] - 1s 867us/step - loss: 189.3082 - mae: 9.9440\n",
      "Epoch 55/100\n",
      "710/710 [==============================] - 1s 868us/step - loss: 189.1082 - mae: 9.9210\n",
      "Epoch 56/100\n",
      "710/710 [==============================] - 1s 872us/step - loss: 189.0809 - mae: 9.9319\n",
      "Epoch 57/100\n",
      "710/710 [==============================] - 1s 865us/step - loss: 188.4731 - mae: 9.9053\n",
      "Epoch 58/100\n",
      "710/710 [==============================] - 1s 898us/step - loss: 188.6090 - mae: 9.9012\n",
      "Epoch 59/100\n",
      "710/710 [==============================] - 1s 872us/step - loss: 188.4812 - mae: 9.9147\n",
      "Epoch 60/100\n",
      "710/710 [==============================] - 1s 858us/step - loss: 188.4691 - mae: 9.9092\n",
      "Epoch 61/100\n",
      "710/710 [==============================] - 1s 857us/step - loss: 187.5803 - mae: 9.8801\n",
      "Epoch 62/100\n",
      "710/710 [==============================] - 1s 866us/step - loss: 187.8370 - mae: 9.9097\n",
      "Epoch 63/100\n",
      "710/710 [==============================] - 1s 867us/step - loss: 187.5700 - mae: 9.8748\n",
      "Epoch 64/100\n",
      "710/710 [==============================] - 1s 867us/step - loss: 187.3572 - mae: 9.8741 0s - loss: 186.6971 - mae: 9.8\n",
      "Epoch 65/100\n",
      "710/710 [==============================] - 1s 868us/step - loss: 187.3757 - mae: 9.8879\n",
      "Epoch 66/100\n",
      "710/710 [==============================] - 1s 903us/step - loss: 186.9819 - mae: 9.8701\n",
      "Epoch 67/100\n",
      "710/710 [==============================] - 1s 872us/step - loss: 187.1828 - mae: 9.8914\n",
      "Epoch 68/100\n",
      "710/710 [==============================] - 1s 863us/step - loss: 186.5003 - mae: 9.8683\n",
      "Epoch 69/100\n",
      "710/710 [==============================] - 1s 875us/step - loss: 186.6141 - mae: 9.8790\n",
      "Epoch 70/100\n",
      "710/710 [==============================] - 1s 870us/step - loss: 186.3591 - mae: 9.8472\n",
      "Epoch 71/100\n",
      "710/710 [==============================] - 1s 895us/step - loss: 186.3466 - mae: 9.8630\n",
      "Epoch 72/100\n",
      "710/710 [==============================] - 1s 866us/step - loss: 186.0444 - mae: 9.8416\n",
      "Epoch 73/100\n",
      "710/710 [==============================] - 1s 896us/step - loss: 186.0240 - mae: 9.8356\n",
      "Epoch 74/100\n",
      "710/710 [==============================] - 1s 861us/step - loss: 185.8250 - mae: 9.8468\n",
      "Epoch 75/100\n",
      "710/710 [==============================] - 1s 874us/step - loss: 186.2176 - mae: 9.8532\n",
      "Epoch 76/100\n",
      "710/710 [==============================] - 1s 882us/step - loss: 185.5269 - mae: 9.8387\n",
      "Epoch 77/100\n",
      "710/710 [==============================] - 1s 909us/step - loss: 185.8392 - mae: 9.8390\n",
      "Epoch 78/100\n",
      "710/710 [==============================] - 1s 864us/step - loss: 185.6379 - mae: 9.8336\n",
      "Epoch 79/100\n",
      "710/710 [==============================] - 1s 869us/step - loss: 185.3321 - mae: 9.8396\n",
      "Epoch 80/100\n",
      "710/710 [==============================] - 1s 869us/step - loss: 185.2566 - mae: 9.8312\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710/710 [==============================] - 1s 871us/step - loss: 184.8263 - mae: 9.8178\n",
      "Epoch 82/100\n",
      "710/710 [==============================] - 1s 870us/step - loss: 184.9765 - mae: 9.8247\n",
      "Epoch 83/100\n",
      "710/710 [==============================] - 1s 893us/step - loss: 184.8413 - mae: 9.8278\n",
      "Epoch 84/100\n",
      "710/710 [==============================] - 1s 871us/step - loss: 184.9348 - mae: 9.8204\n",
      "Epoch 85/100\n",
      "710/710 [==============================] - 1s 865us/step - loss: 184.8525 - mae: 9.8153\n",
      "Epoch 86/100\n",
      "710/710 [==============================] - 1s 857us/step - loss: 184.6653 - mae: 9.8219\n",
      "Epoch 87/100\n",
      "710/710 [==============================] - 1s 866us/step - loss: 184.5392 - mae: 9.8038\n",
      "Epoch 88/100\n",
      "710/710 [==============================] - 1s 859us/step - loss: 184.5386 - mae: 9.8127\n",
      "Epoch 89/100\n",
      "710/710 [==============================] - 1s 868us/step - loss: 184.4135 - mae: 9.8259\n",
      "Epoch 90/100\n",
      "710/710 [==============================] - 1s 862us/step - loss: 184.5904 - mae: 9.8239\n",
      "Epoch 91/100\n",
      "710/710 [==============================] - 1s 908us/step - loss: 184.0938 - mae: 9.7900\n",
      "Epoch 92/100\n",
      "710/710 [==============================] - 1s 859us/step - loss: 184.1639 - mae: 9.8068\n",
      "Epoch 93/100\n",
      "710/710 [==============================] - 1s 863us/step - loss: 183.8240 - mae: 9.7918\n",
      "Epoch 94/100\n",
      "710/710 [==============================] - 1s 872us/step - loss: 183.5567 - mae: 9.7960\n",
      "Epoch 95/100\n",
      "710/710 [==============================] - 1s 870us/step - loss: 183.6218 - mae: 9.7926\n",
      "Epoch 96/100\n",
      "710/710 [==============================] - 1s 859us/step - loss: 183.7306 - mae: 9.8022\n",
      "Epoch 97/100\n",
      "710/710 [==============================] - 1s 866us/step - loss: 183.8050 - mae: 9.7974\n",
      "Epoch 98/100\n",
      "710/710 [==============================] - 1s 884us/step - loss: 183.7740 - mae: 9.7840\n",
      "Epoch 99/100\n",
      "710/710 [==============================] - 1s 868us/step - loss: 183.5152 - mae: 9.7764\n",
      "Epoch 100/100\n",
      "710/710 [==============================] - 1s 897us/step - loss: 183.3241 - mae: 9.7709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20408c75b20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = build_model3()\n",
    "model3.fit(x_mat, y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2600f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "n = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd4029ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:09:58.996290s\n"
     ]
    }
   ],
   "source": [
    "t = n()\n",
    "num_episodes = 100\n",
    "n_life_memory3 = []\n",
    "n_env = gym.make('CartPole-v0')\n",
    "for i in range(num_episodes):\n",
    "    n_old_observation = n_env.reset()\n",
    "    n_done = False\n",
    "    n_tot_reward = 0\n",
    "    n_em_memory3 = []\n",
    "    while not n_done:\n",
    "        pred_in = [list(n_old_observation) + [i] for i in range(2)]\n",
    "        n_new_action = np.argmax([model3.predict(pred_in)])\n",
    "        n_observation, n_reward, n_done, n_info = n_env.step(n_new_action)\n",
    "        n_tot_reward += n_reward\n",
    "        n_em_memory3.append({\n",
    "            \"obs0\": n_old_observation[0],\n",
    "            \"obs1\": n_old_observation[1],\n",
    "            \"obs2\": n_old_observation[2],\n",
    "            \"obs3\": n_old_observation[3],\n",
    "            \"action\": n_new_action,\n",
    "            \"reward\": n_reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        \n",
    "        n_old_observation = n_observation\n",
    "\n",
    "    for n_em in n_em_memory3:\n",
    "        n_em[\"tot_reward\"] = n_tot_reward\n",
    "    n_life_memory3.extend(n_em_memory3)\n",
    "n_memory_df3 = pandas.DataFrame(n_life_memory3)\n",
    "print(f\"Training time: {n() - t}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81c9e0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154.55"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_memory_df3.groupby('episode').reward.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89b3a68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    62\n",
       "True     38\n",
       "Name: reward, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(n_memory_df3.groupby('episode').reward.sum() >= 200).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee83399",
   "metadata": {},
   "source": [
    "### Neural Network from scratch\n",
    "https://www.youtube.com/watch?v=Wo5dMEP_BbI&list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3&index=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "672872eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mat = memory_df[[\"obs0\", \"obs1\", \"obs2\", \"obs3\", \"action\"]].to_numpy()\n",
    "y = memory_df['comb_reward'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2f6e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# def loss_fn(y_true, y_pred, eps=1e-16):\n",
    "#     \"\"\"\n",
    "#     Loss function we would like to optimize (minimize)\n",
    "#     We are using Logarithmic Loss\n",
    "#     http://scikit-learn.org/stable/modules/model_evaluation.html#log-loss\n",
    "#     \"\"\"\n",
    "#     y_pred = np.maximum(y_pred,eps)\n",
    "#     y_pred = np.minimum(y_pred,(1-eps))\n",
    "#     return -(np.sum(y_true * np.log(y_pred)) + np.sum((1-y_true)*np.log(1-y_pred)))/len(y_true)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def deri_relu(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "def forward_pass(W_1, W_2):\n",
    "    global x_mat\n",
    "    global y\n",
    "    global num_\n",
    "\n",
    "    z_2 = np.dot(x_mat, W_1)   # (input_size , 5) x (5, 64) = (input_size , 64)\n",
    "    a_2 = sigmoid(z_2)          # (input_size , 64)\n",
    "    z_3 = np.dot(a_2, W_2)      # (input_size , 64) x (64, ) = (221input_size191 , )\n",
    "    y_pred = sigmoid(z_3).reshape((len(x_mat),))      # (input_size , )\n",
    "    J_z_3_grad = -y + y_pred      # (input_size , )\n",
    "    J_W_2_grad = np.dot(J_z_3_grad, a_2)      # (input_size , ) x (input_size , 64) = (64, )\n",
    "    a_2_z_2_grad = sigmoid(z_2)*(1 - sigmoid(z_2))  # (input_size , 64) * (input_size , 64) = (input_size , 64)\n",
    "                                                    #     J_W_1_grad = a_1 * a_2_z_2_grad * W_2 * J_z_3_grad\n",
    "                                                    #     J_W_1_grad = np.dot(x_mat, a_2_z_2_grad).dot(W_2).dot(J_z_3_grad)\n",
    "    J_W_1_grad = (np.dot((J_z_3_grad).reshape(-1,1), W_2.reshape(-1,1).T)*a_2_z_2_grad).T.dot(x_mat).T\n",
    "                        # (input_size , )->(input_size , 1) x (64 x 1).T\n",
    "                                                   # = (input_size , 64) * (input_size , 64)\n",
    "                                                                  # = (input_size , 64).T = (64, input_size ) x (input_size , 5)\n",
    "                                                                  # = (64, 5).T = (5, 64)\n",
    "    gradient = (J_W_1_grad, J_W_2_grad)\n",
    "    \n",
    "    return y_pred, gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59d02b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to update bias??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "885ef2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_1 = np.random.uniform(-1,1,size=(5,64))\n",
    "W_2 = np.random.uniform(-1,1,size=(64))\n",
    "bias = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "612700e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moon\\AppData\\Local\\Temp/ipykernel_28008/916779298.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:10.780250s\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "n = datetime.datetime.now\n",
    "t = n()\n",
    "\n",
    "np.random.seed(1241)\n",
    "\n",
    "num_iter = 50\n",
    "learning_rate = .001\n",
    "# x_mat = x_mat_full\n",
    "\n",
    "total_pred = []\n",
    "for i in range(num_iter):\n",
    "    y_pred, (J_W_1_grad, J_W_2_grad) = forward_pass(W_1, W_2)\n",
    "    \n",
    "    W_1 = W_1 - learning_rate * J_W_1_grad\n",
    "    W_2 = W_2 - learning_rate * J_W_2_grad\n",
    "    \n",
    "    total_pred.append(y_pred)\n",
    "print(f\"Training time: {n() - t}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "98c1e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_predict(pred_in):\n",
    "    z_2 = np.dot(pred_in[0], W_1)\n",
    "    a_2 = sigmoid(z_2)\n",
    "    z_3 = np.dot(a_2, W_2)\n",
    "    y_pred1 = sigmoid(z_3)\n",
    "    \n",
    "    z2_2 = np.dot(pred_in[1], W_1)\n",
    "    a2_2 = sigmoid(z2_2)\n",
    "    z2_3 = np.dot(a2_2, W_2)\n",
    "    y_pred2 = sigmoid(z2_3)\n",
    "    \n",
    "    return y_pred1, y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9baa6698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moon\\AppData\\Local\\Temp/ipykernel_28008/916779298.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:01.298666s\n"
     ]
    }
   ],
   "source": [
    "t = n()\n",
    "num_episodes = 1000\n",
    "n_life_memory = []\n",
    "n_env = gym.make('CartPole-v0')\n",
    "for i in range(num_episodes):\n",
    "    n_old_observation = n_env.reset()\n",
    "    n_done = False\n",
    "    n_tot_reward = 0\n",
    "    n_em_memory = []\n",
    "    while not n_done:\n",
    "        pred_in = [list(n_old_observation) + [i] for i in range(2)]\n",
    "        n_new_action = np.argmax([nn_predict(pred_in)])\n",
    "        n_observation, n_reward, n_done, n_info = n_env.step(n_new_action)\n",
    "        n_tot_reward += n_reward\n",
    "        n_em_memory.append({\n",
    "            \"obs0\": n_old_observation[0],\n",
    "            \"obs1\": n_old_observation[1],\n",
    "            \"obs2\": n_old_observation[2],\n",
    "            \"obs3\": n_old_observation[3],\n",
    "            \"action\": n_new_action,\n",
    "            \"reward\": n_reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        \n",
    "        n_old_observation = n_observation\n",
    "\n",
    "    for n_em in n_em_memory:\n",
    "        n_em[\"tot_reward\"] = n_tot_reward\n",
    "    n_life_memory.extend(n_em_memory)\n",
    "n_memory_df = pandas.DataFrame(n_life_memory)\n",
    "print(f\"Training time: {n() - t}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "aacb0dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.07"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_memory_df.groupby('episode').reward.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1fa6b72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    998\n",
       "True       2\n",
       "Name: reward, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(n_memory_df.groupby('episode').reward.sum() >= 200).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4ebca4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:00.365990s\n"
     ]
    }
   ],
   "source": [
    "t = n()\n",
    "num_episodes = 1000\n",
    "n_life_memory = []\n",
    "n_env = gym.make('CartPole-v0')\n",
    "for i in range(num_episodes):\n",
    "    n_old_observation = n_env.reset()\n",
    "    n_done = False\n",
    "    n_tot_reward = 0\n",
    "    n_em_memory = []\n",
    "    while not n_done:\n",
    "        n_new_action = env.action_space.sample()\n",
    "        n_observation, n_reward, n_done, n_info = n_env.step(n_new_action)\n",
    "        n_tot_reward += n_reward\n",
    "        n_em_memory.append({\n",
    "            \"obs0\": n_old_observation[0],\n",
    "            \"obs1\": n_old_observation[1],\n",
    "            \"obs2\": n_old_observation[2],\n",
    "            \"obs3\": n_old_observation[3],\n",
    "            \"action\": n_new_action,\n",
    "            \"reward\": n_reward,\n",
    "            \"episode\": i,\n",
    "        })\n",
    "        \n",
    "        n_old_observation = n_observation\n",
    "\n",
    "    for n_em in n_em_memory:\n",
    "        n_em[\"tot_reward\"] = n_tot_reward\n",
    "    n_life_memory.extend(n_em_memory)\n",
    "ran_memory_df = pandas.DataFrame(n_life_memory)\n",
    "print(f\"Training time: {n() - t}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "05e440d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.907"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran_memory_df.groupby('episode').reward.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "06cc91cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1000\n",
       "Name: reward, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ran_memory_df.groupby('episode').reward.sum() >= 200).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f814faad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
